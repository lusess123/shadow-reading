# ğŸ¯ æç¤ºå­¦ä¹ å·¥ä½œåŠ è‹±è¯­æ®µè½ç¿»è¯‘

æœ¬æ–‡å…± **25 ä¸ªè¯­ä¹‰å•å…ƒ**ï¼Œå°†å…¨éƒ¨ç¿»è¯‘ã€‚

---

(1) [0:21-0:34] **Hey everyone, gonna get started here. Thanks so much for joining us today. Um, I'm Sally. I'm the director of RISE. I'm going to be walking you through some of crowd prompt learning. Uh we're actually going to be building a driven optimization loop for the part of the workshop.**

å¤§å®¶å¥½ï¼Œæˆ‘ä»¬å¼€å§‹äº†ã€‚éå¸¸æ„Ÿè°¢ä»Šå¤©å‚åŠ ã€‚å—¯ï¼Œæˆ‘æ˜¯ **Sally**ï¼Œ**RISE** çš„è´Ÿè´£äººã€‚æˆ‘ä¼šå¸¦å¤§å®¶äº†è§£ä¸€äº› **crowd prompt learning**ã€‚åœ¨å·¥ä½œåŠçš„ä¸€éƒ¨åˆ†é‡Œï¼Œæˆ‘ä»¬ä¼šæ­å»ºä¸€ä¸ª **driven optimization loop**ã€‚

è§£æï¼š
* **gonna**ï¼šå£è¯­ç¼©å†™ = going to
* **walk you through** ğŸ”¥ï¼šå¸¦ä½ é€æ­¥è®²è§£ï¼ˆåŠ¨è¯çŸ­è¯­ï¼‰
* **è¯­æ³•ç‚¹**ï¼šbe going to + åŠ¨è¯ï¼Œè¡¨ç¤ºè®¡åˆ’/å³å°†å‘ç”Ÿ

---

(2) [0:34-0:51] **Um I come from a technical background and started off in data science before I made my way over to product. Uh I do like to still be touching code today. I think one of my favorite projects that I work on is building our own agent Alex into our platform. So I'm very familiar with all of the pain points um and how important it is to optimize your prompt.**

å—¯ï¼Œæˆ‘æŠ€æœ¯èƒŒæ™¯å‡ºèº«ï¼Œæœ€å¼€å§‹åš **data science**ï¼Œåæ¥è½¬åˆ° **product**ã€‚æˆ‘ç°åœ¨ä»ç„¶å–œæ¬¢æ¥è§¦ **code**ã€‚æˆ‘æœ€å–œæ¬¢çš„é¡¹ç›®ä¹‹ä¸€æ˜¯æŠŠæˆ‘ä»¬è‡ªå·±çš„ **agent Alex** é›†æˆåˆ°å¹³å°é‡Œã€‚æ‰€ä»¥æˆ‘å¾ˆç†Ÿæ‚‰å„ç§ **pain points**ï¼Œä¹ŸçŸ¥é“ä¼˜åŒ– **prompt** æœ‰å¤šé‡è¦ã€‚

è§£æï¼š
* **start off in**ï¼šèµ·æ­¥äº/æœ€åˆä»äº‹
* **make my way over to** ğŸ”¥ï¼šè½¬åˆ°/è½¬è¡Œåˆ°
* **touching code**ï¼šæŒç»­æ¥è§¦/å†™ä»£ç ï¼ˆå£è¯­è¯´æ³•ï¼‰
* **è¯­æ³•ç‚¹**ï¼šbefore å¼•å¯¼æ—¶é—´ä»å¥

---

(3) [0:51-1:03] **So I'm going to spend a little bit time on slides. I like to like just set the scene, make sure everybody here has context on what we're going to be doing and then we'll jump into the code with me. So, I'll let you do a little bit of an intro.**

æ‰€ä»¥æˆ‘ä¼šå…ˆèŠ±ä¸€ç‚¹æ—¶é—´è®² **slides**ã€‚æˆ‘å–œæ¬¢å…ˆé“ºå«åœºæ™¯ï¼Œç¡®ä¿å¤§å®¶å¯¹æˆ‘ä»¬è¦åšçš„äº‹æƒ…æœ‰ **context**ï¼Œç„¶åæˆ‘ä»¬å†ä¸€èµ·è¿›å…¥ **code**ã€‚æ‰€ä»¥å…ˆè¯·ä½ åšä¸ªç®€å•ä»‹ç»ã€‚

è§£æï¼š
* **set the scene** ğŸ”¥ï¼šé“ºå«åœºæ™¯/äº¤ä»£èƒŒæ™¯
* **jump into**ï¼šç›´æ¥è¿›å…¥/å¼€å§‹
* **è¯­æ³•ç‚¹**ï¼šmake sure + ä»å¥ï¼Œè¡¨ç¤ºâ€œç¡®ä¿â€

---

(4) [1:03-1:15] **Yeah, thank you so much, Ellen. Great to meet all of you. Excited to be walking through prompt learning with you all. I don't know if you got a chance to see a harness talk yesterday, but hopefully that gave you some good background on how powerful prompting and prompt learning can be.**

å¥½çš„ï¼Œéå¸¸æ„Ÿè°¢ä½ ï¼Œ**Ellen**ã€‚å¾ˆé«˜å…´è§åˆ°å¤§å®¶ã€‚æˆ‘å¾ˆæœŸå¾…å’Œå¤§å®¶ä¸€èµ·æ¢³ç† **prompt learning**ã€‚ä¸çŸ¥é“å¤§å®¶æ˜¨å¤©æœ‰æ²¡æœ‰æœºä¼šå¬ **harness talk**ï¼Œä½†å¸Œæœ›é‚£èƒ½è®©ä½ ä»¬äº†è§£ **prompting** å’Œ **prompt learning** æœ‰å¤šå¼ºå¤§ã€‚

è§£æï¼š
* **get a chance to** ğŸ”¥ï¼šæœ‰æœºä¼šåšâ€¦
* **walk through**ï¼šé€æ­¥è®²è§£/æ¼”ç¤º
* **è¯­æ³•ç‚¹**ï¼šI don't know if + ä»å¥ï¼Œè¡¨ç¤ºâ€œä¸ç¡®å®šæ˜¯å¦â€¦â€

---

(5) [1:15-1:32] **Uh, so my name is I'm a product manager here at Arise as well. And like Sally said, we like to stay in code. We'll be doing a few slides, then we'll walk through the code and we'll be floating around helping you guys debug and things like that. My background is also technical. So, I was a backend distributed systems engineer for a long time.**

å‘ƒï¼Œæˆ‘å«â€¦â€¦æˆ‘ä¹Ÿæ˜¯ **Arise** çš„ **product manager**ã€‚å°±åƒ **Sally** è¯´çš„ï¼Œæˆ‘ä»¬å–œæ¬¢å¾…åœ¨ **code** é‡Œã€‚æˆ‘ä»¬ä¼šåšå‡ å¼  **slides**ï¼Œç„¶åè¿‡ä¸€é **code**ï¼ŒæœŸé—´ä¼šåœ¨æ—è¾¹å¸®å¤§å®¶ **debug** ç­‰ã€‚æˆ‘çš„èƒŒæ™¯ä¹ŸåæŠ€æœ¯ï¼Œæˆ‘åš **backend distributed systems engineer** å¾ˆä¹…äº†ã€‚

è§£æï¼š
* **stay in code**ï¼šå¸¸å¾…åœ¨ä»£ç é‡Œï¼ˆå£è¯­è¡¨è¾¾ï¼‰
* **floating around**ï¼šåœ¨ç°åœºæ¥å›å¸®å¿™
* **è¯­æ³•ç‚¹**ï¼šwill be doing / will be walkingï¼Œè¡¨ç¤ºè®¡åˆ’å®‰æ’

---

(6) [1:32-1:44] **So, no stranger to how important observability infrastructure really is. Um, and I think it's an appropriate setting in AWS for that. So, yeah, excited to dive deep into front loading with you all. Thank you. Awesome.**

æ‰€ä»¥æˆ‘å¯¹ **observability infrastructure** çš„é‡è¦æ€§å¹¶ä¸é™Œç”Ÿã€‚æˆ‘è§‰å¾—åœ¨ **AWS** é‡Œåšè¿™ä»¶äº‹å¾ˆåˆé€‚ã€‚æ€»ä¹‹ï¼Œå¾ˆæœŸå¾…å’Œå¤§å®¶ä¸€èµ·æ·±å…¥ **front loading**ã€‚è°¢è°¢ã€‚å¤ªæ£’äº†ã€‚

è§£æï¼š
* **no stranger to** ğŸ”¥ï¼šå¯¹â€¦å¹¶ä¸é™Œç”Ÿ
* **dive deep into** ğŸ”¥ï¼šæ·±å…¥é’»ç ”/æ·±å…¥è®¨è®º
* **è¯­æ³•ç‚¹**ï¼šbe excited to + åŠ¨è¯åŸå½¢

---

(7) [1:44-2:08] **All right, so we're gonna get started. Just give you a little bit of an agenda of the things I'm going to be covering. Uh, so we're gonna talk about why agents fail today. what is evening prom learning? I want to go through a case study kind of show youall why this actually works. Uh and we'll talk about learning versus GA. I think everybody I had a few people come up to me over the conference about like what about GEA? Uh we have some benchmarking against that and then we'll hop into our workshop.**

å¥½ï¼Œæˆ‘ä»¬å¼€å§‹ã€‚æˆ‘å…ˆç»™å¤§å®¶ä¸€ä¸ª **agenda**ï¼Œè¯´è¯´æˆ‘è¦è¦†ç›–å“ªäº›å†…å®¹ã€‚æˆ‘ä»¬ä¼šèŠä¸ºä»€ä¹ˆ **agents** ä¼šå¤±è´¥ï¼Œä»€ä¹ˆæ˜¯ **evening prom learning**ã€‚æˆ‘æƒ³é€šè¿‡ä¸€ä¸ª **case study** ç»™å¤§å®¶çœ‹å®ƒä¸ºä»€ä¹ˆçœŸçš„æœ‰æ•ˆã€‚æˆ‘ä»¬è¿˜ä¼šèŠ **learning** versus **GA**ã€‚æœ‰å‡ ä½åœ¨ä¼šä¸Šé—®æˆ‘ **GEA** æ€ä¹ˆæ ·ï¼Œæˆ‘ä»¬æœ‰ä¸€äº› **benchmarking**ï¼Œç„¶åå°±è¿›å…¥å·¥ä½œåŠã€‚

è§£æï¼š
* **agenda**ï¼šè®®ç¨‹
* **go through**ï¼šè¿‡ä¸€é/è®²è§£
* **è¯­æ³•ç‚¹**ï¼šbe going to + åŠ¨è¯ï¼Œè¡¨ç¤ºè®¡åˆ’

---

(8) [2:08-2:21] **but with this I want to ask a question. How many people here are building agents today? Okay, that's what I expected. Um and how many people actually feel like the agents they're building are reliable? Yeah, that's what I also thought.**

ä¸è¿‡åœ¨è¿™ä¹‹å‰æˆ‘æƒ³é—®ä¸ªé—®é¢˜ï¼šç°åœºæœ‰å¤šå°‘äººåœ¨åš **agents**ï¼Ÿå¥½çš„ï¼Œè¿™æ­£å¦‚æˆ‘é¢„æ–™ã€‚é‚£æœ‰å¤šå°‘äººè§‰å¾—è‡ªå·±åšçš„ **agents** æ˜¯ **reliable** çš„ï¼Ÿå¯¹ï¼Œæˆ‘ä¹Ÿè¿™ä¹ˆæƒ³ã€‚

è§£æï¼š
* **feel like**ï¼šè§‰å¾—/æ„Ÿè§‰
* **reliable**ï¼šå¯é çš„ï¼ˆå½¢å®¹è¯ï¼‰
* **è¯­æ³•ç‚¹**ï¼šHow many people + are + V-ing

---

(9) [2:21-2:38] **let's talk a little bit about why agents fail today. So why do they fail? Well, there's a few things that we're seeing with a lot of our folks and we're seeing even internally as we build with Alex for why agents are b breaking. So um I think that a lot of times it's not because the models are weak. It's a lot of times the environment um and the instructions are weak.**

æˆ‘ä»¬èŠèŠ **agents** ä»Šå¤©ä¸ºä»€ä¹ˆä¼šå¤±è´¥ã€‚ä¸ºä»€ä¹ˆä¼šå¤±è´¥ï¼Ÿæˆ‘ä»¬åœ¨å¾ˆå¤šç”¨æˆ·é‚£é‡Œã€ä¹Ÿåœ¨å†…éƒ¨ç”¨ **Alex** æ„å»ºæ—¶çœ‹åˆ°äº†ä¸€äº›åŸå› ã€‚å¾ˆå¤šæ—¶å€™ä¸æ˜¯ **models** å¼±ï¼Œè€Œæ˜¯ **environment** å’Œ **instructions** å¼±ã€‚

è§£æï¼š
* **a lot of times** ğŸ”¥ï¼šå¾ˆå¤šæ—¶å€™
* **not because A, but because B**ï¼šå¯¹æ¯”è¯´æ˜åŸå› 
* **è¯­æ³•ç‚¹**ï¼šthat å¼•å¯¼å®šè¯­ä»å¥ï¼Œä¿®é¥° things

---

(10) [2:38-2:56] **So uh having no instructions um from their learned environment uh no planning or very static planning. I feel like a lot of agents right now don't have planning. We do have some good examples of planning like we have cloud code cursor. Those are really great examples but I'm not seeing it make its way into every agent that I come across.**

æ¯”å¦‚æ²¡æœ‰ä»å­¦ä¹ åˆ°çš„ **environment** å¾—åˆ° **instructions**ï¼Œæ²¡æœ‰ **planning** æˆ–åªæœ‰å¾ˆé™æ€çš„ **planning**ã€‚æˆ‘æ„Ÿè§‰ç°åœ¨å¾ˆå¤š **agents** æ²¡æœ‰ **planning**ã€‚æˆ‘ä»¬ç¡®å®æœ‰ä¸€äº›å¥½çš„ **planning** ä¾‹å­ï¼Œæ¯”å¦‚ **cloud code**ã€**cursor**ï¼Œä½†æˆ‘æ²¡çœ‹åˆ°å®ƒæ™®åŠåˆ°æˆ‘é‡åˆ°çš„æ¯ä¸ª **agent**ã€‚

è§£æï¼š
* **make its way into** ğŸ”¥ï¼šé€æ¸è¿›å…¥/æ™®åŠåˆ°
* **come across** ğŸ”¥ï¼šé‡åˆ°/ç¢°åˆ°
* **è¯­æ³•ç‚¹**ï¼šI'm not seeing + å®¾è¯­ + åŠ¨è¯åŸå½¢

---

(11) [2:56-3:06] **Uh missing tools big one. Sometimes you just don't have the tool sets that you need. Uh and then missing kind of tool guidance on like which of the tools we should be picking and then context engineering continues to be a big struggle for folks.**

è¿˜æœ‰ä¸€ä¸ªå¤§é—®é¢˜æ˜¯ **missing tools**ã€‚æœ‰æ—¶ä½ å°±æ˜¯æ²¡æœ‰éœ€è¦çš„ **tool sets**ã€‚å¦å¤–ä¹Ÿç¼ºå°‘ **tool guidance**ï¼Œä¸çŸ¥é“è¯¥é€‰å“ªä¸ª **tool**ï¼Œå†åŠ ä¸Š **context engineering** ä»æ˜¯å¾ˆå¤šäººçš„å¤§éš¾é¢˜ã€‚

è§£æï¼š
* **tool set**ï¼šå·¥å…·é›†åˆ
* **guidance**ï¼šæŒ‡å¯¼/æŒ‡å¼•ï¼ˆåè¯ï¼‰
* **è¯­æ³•ç‚¹**ï¼šcontinue to be + åè¯ï¼Œè¡¨ç¤ºâ€œä»ç„¶æ˜¯â€¦â€

---

(12) [3:06-3:28] **If I were to distill this out, I think it's like these three core issues. So adaptability and selfarning. Um so no system instructions learned from the environment touched on determinism versus non-determinism balance. So having the planning um or no planning versus doing like a very static planning. You want to kind of have some flexibility there.**

å¦‚æœæŠŠå®ƒæç‚¼ä¸€ä¸‹ï¼Œæˆ‘è§‰å¾—æœ‰ä¸‰å¤§æ ¸å¿ƒé—®é¢˜ï¼š**adaptability** å’Œ **selfarning**ï¼Œä»¥åŠæ²¡æœ‰ä» **environment** å­¦åˆ°çš„ **system instructions**ï¼Œè¿˜æœ‰ **determinism** ä¸ **non-determinism** çš„å¹³è¡¡ã€‚å†å°±æ˜¯ **planning** æœ‰æˆ–æ²¡æœ‰ã€å¤ªé™æ€æˆ–å¤ªå›ºå®šâ€”â€”éœ€è¦ä¸€å®š **flexibility**ã€‚

è§£æï¼š
* **distill this out** ğŸ”¥ï¼šæç‚¼/æ€»ç»“å‡ºæ¥
* **determinism vs non-determinism**ï¼šç¡®å®šæ€§ä¸éç¡®å®šæ€§
* **è¯­æ³•ç‚¹**ï¼šIf I were to..., I think...ï¼ˆè™šæ‹Ÿè¯­æ°”ï¼‰

---

(13) [3:28-3:46] **And then context engineering I think is a term that just kind of emerged in the last like you know six to eight months but it's something that's really really important that we're finding you know missing tools tool guidance just not having context or confirming your data and not giving the LM enough context. So these are um kind of the core issues to still.**

å¦å¤– **context engineering** è¿™ä¸ªè¯å¤§æ¦‚åœ¨æœ€è¿‘å…­åˆ°å…«ä¸ªæœˆæ‰å‡ºç°ï¼Œä½†å®ƒéå¸¸é‡è¦ã€‚æˆ‘ä»¬å‘ç°çš„é—®é¢˜åŒ…æ‹¬ **missing tools**ã€**tool guidance** ä¸è¶³ã€ç¼ºå°‘ **context** æˆ–æ²¡æœ‰ç¡®è®¤æ•°æ®ã€ä¸ç»™ **LM** è¶³å¤Ÿçš„ **context**ã€‚è¿™äº›ä»ç„¶æ˜¯æ ¸å¿ƒé—®é¢˜ã€‚

è§£æï¼š
* **emerged**ï¼šå‡ºç°/å…´èµ·
* **confirming your data**ï¼šæ ¸å¯¹/ç¡®è®¤æ•°æ®
* **è¯­æ³•ç‚¹**ï¼šthat å¼•å¯¼å®šè¯­ä»å¥ï¼Œä¿®é¥° term

---

(14) [3:46-4:20] **But I think there's one other pretty important thing. Um and that is kind of this distribution of who's responsible for what. So um there's these technical users, your AI engineers, your data scientists, developers, and they're really responsible for the code automation pipelines actually, you know, managing the performance and costs. But then we have our domain experts, subject matter experts, AI product managers. These are the ones that actually knew what the user experience would be. they probably are super familiar with um the principles that we're actually building to our AI applications. They're tracking our evals and they're really trying to ensure that the product success.**

ä½†æˆ‘è§‰å¾—è¿˜æœ‰ä¸€ä»¶å¾ˆé‡è¦çš„äº‹ï¼šè°è´Ÿè´£ä»€ä¹ˆçš„ **distribution**ï¼ˆèŒè´£åˆ†å·¥ï¼‰ã€‚æŠ€æœ¯ç”¨æˆ·ï¼Œæ¯”å¦‚ **AI engineers**ã€**data scientists**ã€**developers**ï¼Œè´Ÿè´£ **code automation pipelines**ï¼Œç®¡ç†æ€§èƒ½å’Œæˆæœ¬ã€‚å¦ä¸€æ–¹é¢æ˜¯ **domain experts**ã€**subject matter experts**ã€**AI product managers**ï¼Œä»–ä»¬äº†è§£ç”¨æˆ·ä½“éªŒï¼Œç†Ÿæ‚‰æˆ‘ä»¬åœ¨ **AI applications** ä¸Šçš„åŸåˆ™ï¼Œè·Ÿè¸ª **evals**ï¼Œå¹¶å°½åŠ›ä¿è¯äº§å“æˆåŠŸã€‚

è§£æï¼š
* **distribution of who's responsible for what**ï¼šèŒè´£åˆ†å·¥
* **subject matter experts**ï¼šé¢†åŸŸä¸“å®¶
* **è¯­æ³•ç‚¹**ï¼šbe responsible for + åè¯

---

(15) [4:20-4:37] **So there's this split between responsibilities but everybody is contributing but then there's this difference um in terms of like maybe technical abilities. And so with prompt learning it's going to be a combination of all these things. So everybody's going to really need to be involved and we can talk about that uh a little bit more.**

å› æ­¤èŒè´£æœ‰åˆ†å·¥ï¼Œä½†å¤§å®¶éƒ½åœ¨è´¡çŒ®ï¼ŒåŒæ—¶æŠ€æœ¯èƒ½åŠ›ä¸Šä¹Ÿæœ‰å·®å¼‚ã€‚**prompt learning** éœ€è¦æŠŠè¿™äº›å› ç´ ç»“åˆèµ·æ¥ï¼Œæ‰€ä»¥æ¯ä¸ªäººéƒ½éœ€è¦å‚ä¸ï¼Œæˆ‘ä»¬ç¨åå†å¤šèŠä¸€ç‚¹ã€‚

è§£æï¼š
* **split between**ï¼šåœ¨â€¦ä¹‹é—´çš„åˆ†å·¥/åˆ†è£‚
* **in terms of**ï¼šå°±â€¦è€Œè¨€
* **è¯­æ³•ç‚¹**ï¼šbe going to + åè¯ï¼Œè¡¨ç¤ºâ€œå°†ä¼šæ˜¯â€¦â€

---

(16) [4:37-4:56] **So what even is prompting? I'm going to first kind of go through some of the um approaches that we kind of borrowed when we came up with prompt learning. So this is something that Arise has been really really uh dedicated to doing some research. And so one of the first things we borrow from uh which is reinforcement learning. How many folks here are familiar with how reinforcement learning works? All right, cool.**

é‚£ **prompting** åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿæˆ‘å…ˆè®²è®²æˆ‘ä»¬æå‡º **prompt learning** æ—¶å€Ÿé‰´çš„ä¸€äº›æ–¹æ³•ã€‚**Arise** åœ¨è¿™æ–¹é¢æŠ•å…¥äº†å¾ˆå¤šç ”ç©¶ã€‚æˆ‘ä»¬å€Ÿé‰´çš„ç¬¬ä¸€ä¸ªæ–¹æ³•æ˜¯ **reinforcement learning**ã€‚ç°åœºæœ‰å¤šå°‘äººç†Ÿæ‚‰ **reinforcement learning** çš„å·¥ä½œæ–¹å¼ï¼Ÿå¥½ï¼Œå¾ˆæ£’ã€‚

è§£æï¼š
* **go through**ï¼šè®²è§£/æ¢³ç†
* **be dedicated to**ï¼šè‡´åŠ›äºï¼ˆåæ¥åŠ¨åè¯ï¼‰
* **è¯­æ³•ç‚¹**ï¼šHow many folks...ï¼ˆæé—®å¥å¼ï¼‰

---

(17) [4:56-5:31] **Um so if I were to give like a really like silly kind of analogy, we have a reinforcement model. Uh pretend it's like a a student brain that we're trying to kind of, you know, boost up. And so they're going to take an action uh which might be something like you're just going to take a test an exam and there's going to be a score. A teacher is going to come through and actually you know score the exam here um that's going to produce this kind of like scaler reward um and you know pretend the student has an algorithm in their brain that can just kind of take those scores and update the weights in their brain and kind of like the learning behavior there and then we kind of reprocess. So you know in this kind of reinforcement one we're updating weights based off of some scalers.**

å¦‚æœç”¨ä¸€ä¸ªæœ‰ç‚¹å‚»çš„ç±»æ¯”ï¼šæˆ‘ä»¬æœ‰ä¸€ä¸ª **reinforcement model**ï¼ŒæŠŠå®ƒå½“ä½œè¦è¢«â€œå¢å¼ºâ€çš„å­¦ç”Ÿå¤§è„‘ã€‚å®ƒä¼šé‡‡å–ä¸€ä¸ª **action**ï¼Œæ¯”å¦‚å»å‚åŠ è€ƒè¯•å¹¶å¾—åˆ° **score**ã€‚è€å¸ˆæ¥è¯„åˆ†ï¼Œäº§ç”Ÿä¸€ä¸ª **scalar reward**ï¼›å‡è®¾å­¦ç”Ÿå¤§è„‘é‡Œæœ‰ç®—æ³•ï¼Œèƒ½åˆ©ç”¨åˆ†æ•°æ›´æ–° **weights**ï¼Œè°ƒæ•´å­¦ä¹ è¡Œä¸ºï¼Œå†é‡å¤è¿™ä¸€è¿‡ç¨‹ã€‚æ‰€ä»¥åœ¨è¿™ç§ **reinforcement** é‡Œï¼Œæˆ‘ä»¬æ˜¯æ ¹æ® **scalers** æ¥æ›´æ–° **weights** çš„ã€‚

è§£æï¼š
* **analogy**ï¼šç±»æ¯”
* **take an action**ï¼šé‡‡å–è¡ŒåŠ¨
* **scalar reward / weights**ï¼šæ ‡é‡å¥–åŠ±/æƒé‡
* **è¯­æ³•ç‚¹**ï¼šwhich might be...ï¼ˆå®šè¯­ä»å¥ï¼‰

---

(18) [5:31-5:44] **Um, but it's really actually difficult to update the weights directly, especially in like the LLM world. So, reinforcement learning isn't going to quite work that well uh when we're we're doing things like prompting.**

ä½†ç›´æ¥æ›´æ–° **weights** å…¶å®å¾ˆéš¾ï¼Œå°¤å…¶åœ¨ **LLM** çš„ä¸–ç•Œé‡Œã€‚æ‰€ä»¥å½“æˆ‘ä»¬åš **prompting** è¿™ç±»äº‹æƒ…æ—¶ï¼Œ**reinforcement learning** å¹¶ä¸å¤ªå¥½ç”¨ã€‚

è§£æï¼š
* **update ... directly**ï¼šç›´æ¥æ›´æ–°â€¦
* **LLM**ï¼šå¤§è¯­è¨€æ¨¡å‹
* **è¯­æ³•ç‚¹**ï¼šisn't going to + åŠ¨è¯ï¼Œè¡¨ç¤ºâ€œä¸ä¼š/éš¾ä»¥â€

---

(19) [5:44-6:25] **So, then there's metaprompting, which is very close to what we do with uh prompt learning, but still not quite right. So, here with metal prompting, we're asking LM to improve the prompt. Uh, so again, we use that kind of like student example. We have an agent which is our student. Um, and it's going to produce some kind of output like that's a user asking a question getting an output. That's our test in this example. And then we're going to score. Eval is pretty much what you can think of there. Uh, where it's going to output a score and from there we have like the metapromp thing. So now the teacher is kind of like the metapar prompt. It's going to take the result uh from our scorer and update the prompts based off of that.**

æ¥ç€æ˜¯ **metaprompting**ï¼Œå®ƒå’Œ **prompt learning** å¾ˆæ¥è¿‘ï¼Œä½†è¿˜ä¸å¤Ÿã€‚è¿™é‡Œçš„ **metal prompting** æ˜¯è®© **LM** å»æ”¹è¿› **prompt**ã€‚è¿˜æ˜¯ç”¨å­¦ç”Ÿç±»æ¯”ï¼šæœ‰ä¸€ä¸ª **agent** ä½œä¸ºå­¦ç”Ÿï¼Œä¼šäº§å‡º **output**ï¼Œæ¯”å¦‚ç”¨æˆ·æé—®å¾—åˆ°è¾“å‡ºï¼Œè¿™å°±æ˜¯æµ‹è¯•ã€‚ç„¶åæˆ‘ä»¬ **score**ï¼Œä¹Ÿå°±æ˜¯ **Eval**ã€‚æ¥ç€â€œè€å¸ˆâ€â€”â€”**metapromp** / **metapar prompt**â€”â€”æ‹¿åˆ° **scorer** çš„ç»“æœï¼Œå¹¶æ®æ­¤æ›´æ–° **prompts**ã€‚

è§£æï¼š
* **be close to**ï¼šæ¥è¿‘/ç±»ä¼¼
* **based off of**ï¼šåŸºäºâ€¦
* **è¯­æ³•ç‚¹**ï¼šwhich å¼•å¯¼å®šè¯­ä»å¥

---

(20) [6:25-7:07] **Um, but it's still not quite what we want to do. And that's where we kind of introduce this idea of prompt learning. So prompt learning is going to take the the exam going to produce an output. Um we're going to have our enlumm evals on there. But there's also this really important piece which is the English feedback. So which answers were wrong? Why were the answers wrong? Where the student needs to actually study? Really pinpointing those issues. And then we still aren't using metapro. We still are asking an LLM uh to improve the prompt. It's just the information that we are giving that LLM uh is quite different. And so we're going to update uh the prompt there with all of this kind of feedback. So from our evals from a subject matter expert going in and labeling and use that uh to kind of boost our prompt with better instructions and sometimes exams.**

ä½†è¿™ä»ä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼Œäºæ˜¯æå‡º **prompt learning**ã€‚**prompt learning** é‡Œä¼šæœ‰ä¸€æ¬¡è€ƒè¯•äº§å‡º **output**ï¼Œå¹¶åŠ å…¥ **enlumm evals**ã€‚æ›´é‡è¦çš„æ˜¯ **English feedback**ï¼šå“ªäº›ç­”æ¡ˆé”™äº†ã€ä¸ºä»€ä¹ˆé”™ã€å­¦ç”Ÿéœ€è¦å­¦ä»€ä¹ˆï¼Œç²¾å‡†å®šä½é—®é¢˜ã€‚æˆ‘ä»¬ä»ç„¶è®© **LLM** æ”¹è¿› **prompt**ï¼Œåªæ˜¯ç»™å®ƒçš„ä¿¡æ¯ä¸åŒäº†ã€‚æˆ‘ä»¬ä¼šç”¨è¿™äº›åé¦ˆæ›´æ–° **prompt**ï¼ŒåŒ…æ‹¬æ¥è‡ª **subject matter expert** çš„æ ‡æ³¨ï¼Œç”¨æ›´å¥½çš„ **instructions**ï¼Œæœ‰æ—¶è¿˜æœ‰ **exams**ï¼Œæ¥æå‡ **prompt**ã€‚

è§£æï¼š
* **introduce this idea of**ï¼šå¼•å…¥â€¦çš„æ¦‚å¿µ
* **pinpoint** ğŸ”¥ï¼šç²¾å‡†æŒ‡å‡º
* **è¯­æ³•ç‚¹**ï¼šIt's just... that...ï¼ˆå¼ºè°ƒå·®å¼‚ï¼‰

---

(21) [7:15-7:34] **So this is kind of like the traditional prompt optimization where it's like we have we're kind of treating it like an ML where we have our data and we have the prompt. We're saying optimize this prompt and maximize our like prediction impulse. Um but that doesn't quite work uh for Allens were missing a lot of context. So what we really found um is that the human instructions of why it failed.**

è¿™æœ‰ç‚¹åƒä¼ ç»Ÿçš„ **prompt optimization**ï¼šæŠŠå®ƒå½“ä½œ **ML**ï¼Œæœ‰æ•°æ®å’Œ **prompt**ï¼Œç„¶åè¯´â€œä¼˜åŒ–è¿™ä¸ª **prompt**ï¼Œæœ€å¤§åŒ– **prediction impulse**â€ã€‚ä½†è¿™å¹¶ä¸å¤ªå¥æ•ˆï¼Œå› ä¸º **Allens** ç¼ºäº†å¾ˆå¤š **context**ã€‚æˆ‘ä»¬çœŸæ­£å‘ç°çš„æ˜¯ï¼Œäººç±»å¯¹å¤±è´¥åŸå› çš„ **instructions**ã€‚

è§£æï¼š
* **treat ... like**ï¼šæŠŠâ€¦å½“ä½œâ€¦
* **maximize**ï¼šæœ€å¤§åŒ–ï¼ˆåŠ¨è¯ï¼‰
* **è¯­æ³•ç‚¹**ï¼šwhere å¼•å¯¼å®šè¯­ä»å¥

---

(22) [7:34-8:14] **So imagine you have your application data, your traces, a data set, whatever it is. Your subject matter expert goes in and they're not only annotating correct or incorrect. They're saying this is why this is wrong. It failed to adhere to this key instruction. It didn't adhere to the context. It's missing out whatever it is. Um, and then you also have your ego explanations from Ellen as a judge, which is same kind of principle where instead of just the label, it provides the reasoning behind the label. And then we're pointing it at the exact instructions um to change. We're changing the system prompt to help it improve so that we then get, you know, prediction labels, but we also get those evals um and explanations of it. So, we're just kind of optimizing more than just um our outlet here.**

æƒ³è±¡ä½ æœ‰ **application data**ã€**traces**ã€**data set** ç­‰ã€‚**subject matter expert** è¿›å»åä¸åªæ˜¯æ ‡æ³¨å¯¹é”™ï¼Œè¿˜ä¼šè¯´ä¸ºä»€ä¹ˆé”™ï¼šæ²¡éµå¾ªæŸæ¡å…³é”® **instruction**ï¼Œæ²¡éµå¾ª **context**ï¼Œæˆ–è€…ç¼ºäº†ä»€ä¹ˆã€‚æ¥ç€è¿˜æœ‰ä½œä¸ºè¯„å®¡çš„ **Ellen** ç»™å‡ºçš„ **ego explanations**ï¼ŒåŸç†ç±»ä¼¼ï¼šä¸åªæ˜¯ç»™æ ‡ç­¾ï¼Œè¿˜ä¼šç»™å‡ºæ ‡ç­¾èƒŒåçš„ç†ç”±ã€‚ç„¶åæˆ‘ä»¬æŠŠå®ƒæŒ‡å‘éœ€è¦ä¿®æ”¹çš„å…·ä½“ **instructions**ï¼Œå»æ”¹ **system prompt**ï¼Œè®©å®ƒå˜å¥½ï¼Œäºæ˜¯æ—¢å¾—åˆ° **prediction labels**ï¼Œä¹Ÿå¾—åˆ° **evals** å’Œè§£é‡Šã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬ä¼˜åŒ–çš„ä¸åªæ˜¯ **output** æœ¬èº«ã€‚

è§£æï¼š
* **adhere to** ğŸ”¥ï¼šéµå¾ª/ç¬¦åˆ
* **instead of**ï¼šä¸æ˜¯â€¦è€Œæ˜¯â€¦
* **è¯­æ³•ç‚¹**ï¼šso that + ç»“æœ

---

(23) [8:21-8:45] **And I think a really key learning that we've had is the explanations in human instructions or through your own as a judge. That text is really really valuable. I think that's what we see not being utilized in a lot of other broad optimization approaches. Um they're either kind of optimizing for a score uh or they're just paying attention to the output. But you can think of it this way. It's like these elements are operating in the text domain. So we have all this rich text that tells us exactly what it needs to do to improve. why wouldn't we use that to actually improve our so um that's kind of the basics of prompt learning**

æˆ‘ä»¬ä¸€ä¸ªå¾ˆé‡è¦çš„ **key learning** æ˜¯ï¼šäººç±» **instructions** æˆ–â€œè¯„å®¡è§£é‡Šâ€é‡Œçš„æ–‡å­—éå¸¸æœ‰ä»·å€¼ã€‚å¾ˆå¤šå…¶ä»– **optimization approaches** æ²¡æœ‰å……åˆ†åˆ©ç”¨è¿™äº›æ–‡æœ¬â€”â€”è¦ä¹ˆåªä¼˜åŒ– **score**ï¼Œè¦ä¹ˆåªçœ‹ **output**ã€‚æ¢ä¸ªè§’åº¦æƒ³ï¼Œè¿™äº›å…ƒç´ éƒ½åœ¨ **text domain** é‡Œè¿ä½œï¼Œæˆ‘ä»¬æœ‰å¤§é‡ **rich text** æ¸…æ¥šå‘Šè¯‰æˆ‘ä»¬è¯¥æ€ä¹ˆæ”¹è¿›ï¼Œä¸ºä»€ä¹ˆä¸åˆ©ç”¨å®ƒæ¥çœŸæ­£æå‡ **prompt learning** å‘¢ï¼Ÿè¿™å°±æ˜¯ **prompt learning** çš„åŸºæœ¬æ€è·¯ã€‚

è§£æï¼š
* **not being utilized**ï¼šæœªè¢«åˆ©ç”¨
* **text domain**ï¼šæ–‡æœ¬åŸŸ
* **è¯­æ³•ç‚¹**ï¼šwhy wouldn't we...ï¼ˆåé—®å¼ºè°ƒï¼‰

---

(24) [8:53-9:12] **but everybody always comes up to me and like sounds great s but does it actually work um it does and we have some examples of when we do this so we did a little bit of a case study um I think coding agents everybody is pretty much using them at this point there's a quite a few that have been really really successful I think cloud code is a great example cursor but there's also client uh which is more of a um an open version of this and so we decided to take a look and compare to see if we could you know do anything to improve.**

ä½†å¤§å®¶æ€»ä¼šé—®æˆ‘ï¼šå¬èµ·æ¥å¾ˆå¥½ï¼Œå¯çœŸçš„æœ‰æ•ˆå—ï¼Ÿæœ‰æ•ˆï¼Œæˆ‘ä»¬æœ‰ä¸€äº›ä¾‹å­ï¼Œæ‰€ä»¥åšäº†ä¸€ä¸ªå° **case study**ã€‚ç°åœ¨å‡ ä¹äººäººéƒ½åœ¨ç”¨ **coding agents**ï¼Œå…¶ä¸­æœ‰ä¸å°‘éå¸¸æˆåŠŸï¼Œæ¯”å¦‚ **cloud code**ã€**cursor**ï¼Œè¿˜æœ‰æ›´å¼€æ”¾ç‰ˆæœ¬çš„ **client**ã€‚äºæ˜¯æˆ‘ä»¬å†³å®šå¯¹æ¯”çœ‹çœ‹èƒ½å¦åšäº›æ”¹è¿›ã€‚

è§£æï¼š
* **come up to me**ï¼šèµ°è¿‡æ¥æ‰¾æˆ‘/æ¥é—®æˆ‘
* **pretty much**ï¼šåŸºæœ¬ä¸Š/å‡ ä¹
* **è¯­æ³•ç‚¹**ï¼šdoes it actually work?ï¼ˆä¸€èˆ¬ç–‘é—®å¥å¼ºè°ƒæ•ˆæœï¼‰

---

(25) [9:19-10:04] **So these are kind of the the baseline of where we started here. Um you can see the difference between the different models. U obviously using two and throttle kind of the state-of-the-art there but we also had this opportunity where CL was using you know 45 and it was working decently well at 30% versus 40. Um and then there was kind of the conversation around. So this is where we started um and we took a pass optimizing the system prompt here. So you can see this is what the old one was looking like. It has like no rules section. So it was just very like you are a cloud agent. You're built on this model. You're you're here to do coding. Um but there was no rules and so we took a pass at updating the system.**

è¿™äº›å°±æ˜¯æˆ‘ä»¬èµ·æ­¥æ—¶çš„ **baseline**ã€‚ä½ å¯ä»¥çœ‹åˆ°ä¸åŒ **models** çš„å·®å¼‚ã€‚æ˜¾ç„¶ä½¿ç”¨ **two** å’Œ **throttle** å±äº **state-of-the-art**ï¼Œä½†æˆ‘ä»¬ä¹Ÿæœ‰æœºä¼šçœ‹åˆ° **CL** ç”¨ **45** æ—¶ï¼Œåœ¨ 30% å¯¹æ¯” 40% çš„æƒ…å†µä¸‹ä¹Ÿè¡¨ç°ä¸é”™ã€‚äºæ˜¯å¤§å®¶è®¨è®ºäº†ä¸€ä¸‹ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬å¼€å§‹çš„åœ°æ–¹ã€‚æ¥ç€æˆ‘ä»¬å°è¯•ä¼˜åŒ– **system prompt**ï¼šæ—§ç‰ˆæœ¬å‡ ä¹æ²¡æœ‰ **rules section**ï¼Œåªæ˜¯è¯´ä½ æ˜¯ä¸€ä¸ª **cloud agent**ï¼ŒåŸºäºè¿™ä¸ª **model**ï¼Œä½ çš„ä»»åŠ¡æ˜¯ **coding**ã€‚ä½†æ²¡æœ‰è§„åˆ™ï¼Œæ‰€ä»¥æˆ‘ä»¬å¼€å§‹æ›´æ–°è¿™ä¸ªç³»ç»Ÿã€‚

è§£æï¼š
* **baseline**ï¼šåŸºçº¿/èµ·ç‚¹
* **state-of-the-art**ï¼šæœ€å…ˆè¿›çš„
* **took a pass** ğŸ”¥ï¼šåšäº†ä¸€æ¬¡å°è¯•/ä¼˜åŒ–
* **è¯­æ³•ç‚¹**ï¼šYou can see...ï¼ˆæƒ…æ€åŠ¨è¯ can è¡¨ç¤ºâ€œèƒ½çœ‹åˆ°â€ï¼‰

---

## ğŸ“š æ®µè½å°ç»“

æœ¬æ®µæ˜¯å·¥ä½œåŠå¼€åœºä¸æ ¸å¿ƒå†…å®¹æ¦‚è§ˆã€‚è®²è€…è§£é‡Šäº† **agents** å¤±è´¥çš„åŸå› ã€èŒè´£åˆ†å·¥ï¼Œå¹¶æ¯”è¾ƒ **reinforcement learning**ã€**metaprompting** ä¸ **prompt learning** çš„å·®å¼‚ã€‚æœ€åç”¨æ¡ˆä¾‹å’Œ **system prompt** ä¼˜åŒ–è¯´æ˜ **prompt learning** çš„æœ‰æ•ˆæ€§ã€‚

### ğŸ”¥ æ ¸å¿ƒè¯æ±‡è¡¨

| è¯æ±‡/çŸ­è¯­ | å«ä¹‰ |
|---------|------|
| **prompt learning** | æç¤ºå­¦ä¹ æ–¹æ³• |
| **reinforcement learning** | å¼ºåŒ–å­¦ä¹  |
| **metaprompting** | å…ƒæç¤ºç”Ÿæˆ/æ”¹å†™ |
| **system prompt** | ç³»ç»Ÿæç¤ºè¯ |
| **context engineering** | è¯­å¢ƒå·¥ç¨‹ |
| **observability infrastructure** | å¯è§‚æµ‹æ€§åŸºç¡€è®¾æ–½ |
| **scalar reward** | æ ‡é‡å¥–åŠ± |
| **tool guidance** | å·¥å…·é€‰æ‹©/ä½¿ç”¨æŒ‡å¯¼ |
| **baseline** | åŸºçº¿/èµ·ç‚¹ |
| **state-of-the-art** | æœ€å…ˆè¿›çš„ |
