# è‹±è¯­æ®µè½ç¿»è¯‘å­¦ä¹  ğŸ“š

> ä¸»é¢˜ï¼šAgentic Searchã€RAG ä¸æ¨¡å‹æƒé‡å­¦ä¹ 
> æ—¶é—´ï¼š20:00 - 30:02

---

(1) [20:00-20:06] **I'm curious if you would classify agentic search as RAG as well.**

æˆ‘å¾ˆå¥½å¥‡ä½ ä¼šä¸ä¼šæŠŠ **agentic search** ä¹Ÿå½’ç±»ä¸º **RAG**ã€‚

è§£æï¼š
* **agentic search**ï¼šæ™ºèƒ½ä½“æœç´¢ï¼Œèƒ½è‡ªä¸»è¿›è¡Œå¤šæ­¥æŸ¥è¯¢çš„æœç´¢ç³»ç»Ÿï¼ˆAI é¢†åŸŸæœ¯è¯­ï¼‰
* **RAG**ï¼šRetrieval-Augmented Generationï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆAI é¢†åŸŸæœ¯è¯­ï¼‰
* **classify...as**ï¼šæŠŠâ€¦â€¦å½’ç±»ä¸ºâ€¦â€¦

---

(2) [20:06-20:17] **Yeah that's a good question. So I guess the way I think agentic search it's like a model that can grab and it makes a bunch of queries in a row and then it responds.**

æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ã€‚æˆ‘è§‰å¾—æˆ‘å¯¹ **agentic search** çš„ç†è§£æ˜¯ï¼šå®ƒå°±åƒä¸€ä¸ªå¯ä»¥æŠ“å–ä¿¡æ¯çš„æ¨¡å‹ï¼Œè¿ç»­å‘å‡ºä¸€å †æŸ¥è¯¢ï¼Œç„¶åå†å›åº”ã€‚

è§£æï¼š
* **I guess**ï¼šæˆ‘è§‰å¾—ã€æˆ‘æƒ³ï¼ˆå£è¯­åŒ–è¡¨è¾¾ï¼Œæ¯” I think æ›´éšæ„ï¼‰
* **a bunch of**ï¼šä¸€å †ã€å¾ˆå¤šï¼ˆéæ­£å¼å£è¯­ï¼‰
* **in a row**ï¼šè¿ç»­åœ°ã€ä¸€ä¸ªæ¥ä¸€ä¸ª

---

(3) [20:17-20:22] **Um yeah that's that's a really good question. I think I think I wouldn't classify it as RAG.**

å—¯ï¼Œè¿™ç¡®å®æ˜¯ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æˆ‘ä¸ä¼šæŠŠå®ƒå½’ç±»ä¸º **RAG**ã€‚

è§£æï¼š
* å£è¯­ä¸­çš„é‡å¤ "I think I think" æ˜¯è¯´è¯è€…æ€è€ƒæ—¶çš„è‡ªç„¶ç°è±¡ï¼Œç¿»è¯‘æ—¶å¯ç®€åŒ–

---

(4) [20:22-20:36] **But I think it has different fundamental limitations that are also tough to overcome. Like what you would really want is like a model that reads the entire thing and reasons about every possible relationship and then answers.**

ä½†æˆ‘è®¤ä¸ºå®ƒæœ‰ä¸åŒçš„åŸºæœ¬é™åˆ¶ï¼Œè¿™äº›é™åˆ¶åŒæ ·å¾ˆéš¾å…‹æœã€‚ä½ çœŸæ­£æƒ³è¦çš„æ˜¯ä¸€ä¸ªèƒ½è¯»å®Œæ•´ä¸ªå†…å®¹ã€æ¨ç†å‡ºæ‰€æœ‰å¯èƒ½çš„å…³ç³»ã€ç„¶åå†å›ç­”çš„æ¨¡å‹ã€‚

è§£æï¼š
* **fundamental limitations**ï¼šåŸºæœ¬é™åˆ¶ã€æ ¹æœ¬æ€§å±€é™
* **tough to overcome**ï¼šéš¾ä»¥å…‹æœï¼ˆtough = difficultï¼Œå£è¯­åŒ–ï¼‰
* **reasons about**ï¼šæ¨ç†ã€æ€è€ƒï¼ˆreason ä½œåŠ¨è¯ç”¨ï¼‰

---

(5) [20:36-20:43] **And I think in theory maybe you could build an agentic RAG system that does that, but it would be very expensive.**

ç†è®ºä¸Šä½ ä¹Ÿè®¸å¯ä»¥æ„å»ºä¸€ä¸ªè¿™æ ·çš„ **agentic RAG** ç³»ç»Ÿï¼Œä½†é‚£ä¼šéå¸¸æ˜‚è´µã€‚

è§£æï¼š
* **in theory**ï¼šç†è®ºä¸Šï¼ˆå¸¸ä¸ in practice å¯¹æ¯”ä½¿ç”¨ï¼‰
* **expensive**ï¼šè¿™é‡ŒæŒ‡è®¡ç®—æˆæœ¬é«˜ï¼Œä¸æ˜¯ä»·æ ¼è´µ

---

(6) [20:43-20:55] **Yeah. Because isn't that isn't that in the isn't deep research in the direction of that where it like goes through and it pulls like hundreds or thousands of sources but then what ends up in context is only like a small subset of those.**

æ˜¯å•Šï¼Œ**Deep Research** ä¸å°±æ˜¯æœç€é‚£ä¸ªæ–¹å‘èµ°çš„å—ï¼Ÿå®ƒä¼šéå†å¹¶æ‹‰å–æˆç™¾ä¸Šåƒä¸ªæ¥æºï¼Œä½†æœ€ç»ˆè¿›å…¥ä¸Šä¸‹æ–‡çš„åªæ˜¯å…¶ä¸­å¾ˆå°ä¸€éƒ¨åˆ†ã€‚

è§£æï¼š
* **Deep Research**ï¼šæ·±åº¦ç ”ç©¶åŠŸèƒ½ï¼ˆOpenAI äº§å“åï¼Œä¿æŒè‹±æ–‡ï¼‰
* **pulls**ï¼šæ‹‰å–ã€æŠ“å–ï¼ˆæŠ€æœ¯æœ¯è¯­ï¼‰
* **ends up in context**ï¼šæœ€ç»ˆè¿›å…¥ä¸Šä¸‹æ–‡ï¼ˆAI æœ¯è¯­ï¼Œcontext = æ¨¡å‹çš„è¾“å…¥çª—å£ï¼‰
* **a small subset of**ï¼šä¸€å°éƒ¨åˆ†ã€å­é›†
* å£è¯­ä¸­ "isn't that isn't that in the isn't" æ˜¯è¯´è¯è€…è¾¹æƒ³è¾¹è¯´çš„è‡ªæˆ‘çº æ­£

---

(7) [20:55-21:07] **Yeah. Yeah. I actually think deep research is like really in the right direction. Like they're trying to do something that's a little bit higher level and requires a lot of compute.**

æ˜¯çš„ã€‚æˆ‘ç¡®å®è§‰å¾— **Deep Research** èµ°åœ¨æ­£ç¡®çš„æ–¹å‘ä¸Šã€‚ä»–ä»¬åœ¨å°è¯•åšä¸€äº›æ›´é«˜å±‚æ¬¡çš„äº‹æƒ…ï¼Œè€Œä¸”éœ€è¦å¤§é‡ç®—åŠ›ã€‚

è§£æï¼š
* **in the right direction**ï¼šæ–¹å‘æ­£ç¡®ï¼ˆå›ºå®šæ­é…ï¼‰
* **compute**ï¼šç®—åŠ›ï¼ˆåè¯ç”¨æ³•ï¼ŒAI é¢†åŸŸå¸¸ç”¨ï¼‰
* **higher level**ï¼šæ›´é«˜å±‚æ¬¡çš„

---

(8) [21:07-21:32] **Like I think um anything that works better than RAG is going to be more expensive. And so like just the property that it takes a while and it makes a lot of searches and it thinks a lot is like good. I think that there's probably a more elegant way to train like a really big kind of researchesque system, but I think that's actually a good way of doing this and not the one that I'm talking about today, but it's very promising as well.**

æˆ‘è®¤ä¸ºä»»ä½•æ¯” **RAG** æ•ˆæœæ›´å¥½çš„æ–¹æ¡ˆéƒ½ä¼šæ›´è´µã€‚æ‰€ä»¥å®ƒéœ€è¦èŠ±ä¸€äº›æ—¶é—´ã€è¿›è¡Œå¤§é‡æœç´¢ã€åšå¾ˆå¤šæ€è€ƒï¼Œè¿™äº›ç‰¹æ€§æœ¬èº«å°±æ˜¯å¥½çš„ã€‚æˆ‘è§‰å¾—å¯èƒ½æœ‰æ›´ä¼˜é›…çš„æ–¹å¼æ¥è®­ç»ƒä¸€ä¸ªçœŸæ­£å¤§å‹çš„ã€ç±»ç ”ç©¶å‹çš„ç³»ç»Ÿï¼Œä½†é‚£ç¡®å®æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•ï¼Œè™½ç„¶ä¸æ˜¯æˆ‘ä»Šå¤©è¦è®²çš„ï¼Œä½†ä¹Ÿå¾ˆæœ‰å‰æ™¯ã€‚

è§£æï¼š
* **the property that...**ï¼šâ€¦â€¦è¿™ä¸ªç‰¹æ€§ï¼ˆproperty = å±æ€§ã€ç‰¹æ€§ï¼‰
* **elegant**ï¼šä¼˜é›…çš„ï¼ˆæŠ€æœ¯é¢†åŸŸæŒ‡æ–¹æ¡ˆç®€æ´é«˜æ•ˆï¼‰
* **researchesque**ï¼šç±»ç ”ç©¶å‹çš„ï¼ˆ-esque åç¼€è¡¨ç¤º"åƒâ€¦â€¦é£æ ¼çš„"ï¼‰
* **promising**ï¼šæœ‰å‰æ™¯çš„ã€æœ‰å¸Œæœ›çš„

---

(9) [21:32-21:57] **Like maybe the question is like are you willing to spend a lot of money at training time or at inference time and deep research is like kind of they don't spend a lot of money to train it but it's willing to wait for a long time at inference and I think the things I'm going to talk about today are more like if you're willing to spend a lot of money up front and you get a really smart model that knows all your data already um and it's really cheap to do inference. So it's like kind of different sides of the same trade-off.**

é—®é¢˜å¯èƒ½æ˜¯ï¼šä½ æ„¿æ„åœ¨è®­ç»ƒæ—¶èŠ±å¤§é’±ï¼Œè¿˜æ˜¯åœ¨æ¨ç†æ—¶èŠ±å¤§é’±ï¼Ÿ**Deep Research** çš„ç­–ç•¥æ˜¯ä¸åœ¨è®­ç»ƒä¸ŠèŠ±å¤ªå¤šé’±ï¼Œä½†æ„¿æ„åœ¨æ¨ç†æ—¶ç­‰å¾ˆé•¿æ—¶é—´ã€‚è€Œæˆ‘ä»Šå¤©è¦è®²çš„æ›´åƒæ˜¯ï¼šå¦‚æœä½ æ„¿æ„é¢„å…ˆèŠ±å¤§é’±ï¼Œä½ å°±èƒ½å¾—åˆ°ä¸€ä¸ªéå¸¸èªæ˜çš„ã€å·²ç»äº†è§£ä½ æ‰€æœ‰æ•°æ®çš„æ¨¡å‹ï¼Œç„¶åæ¨ç†æˆæœ¬å°±å¾ˆä½ã€‚è¿™å°±åƒåŒä¸€ä¸ªæƒè¡¡çš„ä¸åŒé¢ã€‚

è§£æï¼š
* **training time**ï¼šè®­ç»ƒæ—¶é—´/é˜¶æ®µï¼ˆæ¨¡å‹å­¦ä¹ é˜¶æ®µï¼‰
* **inference time**ï¼šæ¨ç†æ—¶é—´/é˜¶æ®µï¼ˆæ¨¡å‹ç”Ÿæˆå›ç­”é˜¶æ®µï¼‰
* **up front**ï¼šé¢„å…ˆã€æå‰ï¼ˆå›ºå®šæ­é…ï¼Œå¸¸ç”¨äºå•†ä¸š/æŠ€æœ¯è¯­å¢ƒï¼‰
* **trade-off**ï¼šæƒè¡¡ã€å–èˆï¼ˆéå¸¸é‡è¦çš„æ¦‚å¿µè¯ï¼‰

---

(10) [21:57-22:10] **And I think like a good way of thinking about these things is like to get better models, you're going to need to pay somewhere, you know, like you're either going to need to like generate better data and spend more time on the data, you're going to need to spend time on training, or you're going to need to spend time on inference.**

æˆ‘è§‰å¾—ä¸€ä¸ªå¥½çš„æ€è€ƒæ–¹å¼æ˜¯ï¼šè¦å¾—åˆ°æ›´å¥½çš„æ¨¡å‹ï¼Œä½ æ€»å¾—åœ¨æŸä¸ªåœ°æ–¹ä»˜å‡ºä»£ä»·ã€‚ä½ è¦ä¹ˆéœ€è¦ç”Ÿæˆæ›´å¥½çš„æ•°æ®ã€åœ¨æ•°æ®ä¸ŠèŠ±æ›´å¤šæ—¶é—´ï¼Œè¦ä¹ˆéœ€è¦åœ¨è®­ç»ƒä¸ŠèŠ±æ—¶é—´ï¼Œè¦ä¹ˆéœ€è¦åœ¨æ¨ç†ä¸ŠèŠ±æ—¶é—´ã€‚

è§£æï¼š
* **pay somewhere**ï¼šåœ¨æŸå¤„ä»˜å‡ºä»£ä»·ï¼ˆpay ä¸ä¸€å®šæŒ‡é‡‘é’±ï¼‰
* **you know**ï¼šä½ æ‡‚çš„ï¼ˆå£è¯­å¡«å……è¯ï¼Œå¼•èµ·å¬ä¼—æ³¨æ„ï¼‰

---

(11) [22:10-22:16] **And a nice thing about RAGs is it kind of just works, but anything better will cost more.**

**RAG** çš„å¥½å¤„æ˜¯å®ƒåŸºæœ¬èƒ½ç”¨ï¼Œä½†ä»»ä½•æ›´å¥½çš„æ–¹æ¡ˆéƒ½ä¼šæ›´è´µã€‚

è§£æï¼š
* **kind of just works**ï¼šåŸºæœ¬ä¸Šå°±æ˜¯èƒ½ç”¨ï¼ˆkind of å¼±åŒ–è¯­æ°”ï¼Œjust works = å¼€ç®±å³ç”¨ï¼‰
* **cost more**ï¼šæˆæœ¬æ›´é«˜ï¼ˆä¸ä»…æŒ‡é‡‘é’±ï¼Œä¹ŸæŒ‡æ—¶é—´ã€ç®—åŠ›ï¼‰

---

(12) [22:16-22:28] **Yeah. Getting back to your example of Mastercard versus V. I don't know if that's in your presentation later, but what are your thoughts on using knowledge graph for that as kind of augmenting.**

å›åˆ°ä½ ä¹‹å‰ **Mastercard** å’Œ **Visa** çš„ä¾‹å­ï¼Œæˆ‘ä¸çŸ¥é“ä½ åé¢çš„æ¼”ç¤ºä¼šä¸ä¼šè®²åˆ°ï¼Œä½†ä½ å¯¹ç”¨çŸ¥è¯†å›¾è°±æ¥å¢å¼ºè¿™ä¸ªæœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ

è§£æï¼š
* **Getting back to**ï¼šå›åˆ°â€¦â€¦ï¼ˆè¯é¢˜è½¬æ¢å¸¸ç”¨è¯­ï¼‰
* **knowledge graph**ï¼šçŸ¥è¯†å›¾è°±ï¼ˆAI/æ•°æ®é¢†åŸŸæœ¯è¯­ï¼‰
* **augmenting**ï¼šå¢å¼ºï¼ˆåŠ¨åè¯å½¢å¼ï¼‰

---

(13) [22:28-22:35] **It's a good question. Maybe ask me after. I have to think about knowledge graphs. It's been a while.**

è¿™æ˜¯ä¸ªå¥½é—®é¢˜ã€‚ä¹Ÿè®¸ä¼šåå†é—®æˆ‘å§ï¼Œæˆ‘å¾—æƒ³æƒ³çŸ¥è¯†å›¾è°±çš„äº‹ï¼Œå·²ç»å¾ˆä¹…æ²¡ç¢°äº†ã€‚

è§£æï¼š
* **It's been a while**ï¼šå·²ç»æœ‰ä¸€æ®µæ—¶é—´äº†ï¼ˆå›ºå®šè¡¨è¾¾ï¼Œè¡¨ç¤ºå¾ˆä¹…æ²¡åšæŸäº‹ï¼‰

---

(14) [22:35-22:54] **Um, so let's talk about how to learn things in weights. Um, I think like the question that we want to get at is like, okay, so say we have the example I showed earlier or like you have a small data set you collected from your own personal work and you want to teach it to the model.**

é‚£æˆ‘ä»¬æ¥èŠèŠå¦‚ä½•æŠŠä¸œè¥¿å­¦è¿›æƒé‡é‡Œã€‚æˆ‘ä»¬è¦è§£å†³çš„é—®é¢˜æ˜¯è¿™æ ·çš„ï¼šå‡è®¾æˆ‘ä»¬æœ‰ä¹‹å‰å±•ç¤ºçš„é‚£ä¸ªä¾‹å­ï¼Œæˆ–è€…ä½ ä»è‡ªå·±çš„å·¥ä½œä¸­æ”¶é›†äº†ä¸€å°ä»½æ•°æ®é›†ï¼Œæƒ³æ•™ç»™æ¨¡å‹ã€‚

è§£æï¼š
* **learn things in weights**ï¼šåœ¨æƒé‡ä¸­å­¦ä¹ ï¼ˆæŒ‡é€šè¿‡è®­ç»ƒè®©æ¨¡å‹å†…åŒ–çŸ¥è¯†ï¼Œè€Œéæ”¾åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼‰
* **get at**ï¼šæƒ³è¦è¡¨è¾¾/æ¢ç©¶ï¼ˆå£è¯­è¡¨è¾¾ï¼‰
* **teach it to the model**ï¼šæ•™ç»™æ¨¡å‹ï¼ˆæ‹ŸäººåŒ–è¡¨è¾¾ï¼‰

---

(15) [22:54-22:59] **It's one thing to put it into context and that's a good way to get started and if you don't have that much data, that'll get you pretty far.**

æŠŠå®ƒæ”¾è¿›ä¸Šä¸‹æ–‡æ˜¯ä¸€ç§æ–¹å¼ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„èµ·ç‚¹ï¼Œå¦‚æœæ•°æ®é‡ä¸å¤§çš„è¯ï¼Œè¿™æ ·åšèƒ½èµ°å¾ˆè¿œã€‚

è§£æï¼š
* **put it into context**ï¼šæ”¾è¿›ä¸Šä¸‹æ–‡ï¼ˆAI æœ¯è¯­ï¼ŒæŒ‡é€šè¿‡ prompt æä¾›ä¿¡æ¯ï¼‰
* **get you pretty far**ï¼šè®©ä½ èµ°å¾—å¾ˆè¿œã€æ•ˆæœä¸é”™ï¼ˆå£è¯­è¡¨è¾¾ï¼‰

---

(16) [22:59-23:11] **But I think we can do more. Like there's some questions that even when your data is in context, the model can't answer. And so what I want us to think about is like how can we inject things into a model uh is such that it learns better than in context and also that it doesn't forget everything that it already knows.**

ä½†æˆ‘è§‰å¾—æˆ‘ä»¬å¯ä»¥åšå¾—æ›´å¤šã€‚æœ‰äº›é—®é¢˜å³ä½¿ä½ çš„æ•°æ®åœ¨ä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹ä¹Ÿå›ç­”ä¸äº†ã€‚æ‰€ä»¥æˆ‘æƒ³è®©å¤§å®¶æ€è€ƒçš„æ˜¯ï¼šæˆ‘ä»¬æ€æ ·æ‰èƒ½æŠŠä¸œè¥¿æ³¨å…¥æ¨¡å‹ï¼Œè®©å®ƒå­¦å¾—æ¯”æ”¾åœ¨ä¸Šä¸‹æ–‡é‡Œæ›´å¥½ï¼ŒåŒæ—¶åˆä¸ä¼šå¿˜è®°å®ƒå·²ç»çŸ¥é“çš„ä¸€åˆ‡ã€‚

è§£æï¼š
* **inject things into a model**ï¼šæŠŠä¸œè¥¿æ³¨å…¥æ¨¡å‹ï¼ˆå½¢è±¡åŒ–è¡¨è¾¾ï¼‰
* **in context**ï¼šåœ¨ä¸Šä¸‹æ–‡ä¸­
* **catastrophic forgetting** æ¦‚å¿µï¼šæ¨¡å‹å­¦æ–°ä¸œè¥¿æ—¶å¿˜æ‰æ—§çŸ¥è¯†ï¼ˆè¿™é‡Œéšå«æåˆ°ï¼‰

---

(17) [23:11-23:38] **Um I want to point out something from my own research which is that there is a fixed capacity to language models. Like one way to think about this is GPT has like only so many parameters. We have this measurement that it can store 3.6 bits per parameter. So like uh I think a billion parameter model is like at 3.6 bits is maybe like four terabytes. Is that right? 4 gigabytes what? Yeah, thank you. Thank you.**

æˆ‘æƒ³æŒ‡å‡ºæˆ‘è‡ªå·±ç ”ç©¶ä¸­çš„ä¸€ç‚¹ï¼šè¯­è¨€æ¨¡å‹æœ‰å›ºå®šçš„å®¹é‡ã€‚å¯ä»¥è¿™æ ·ç†è§£ï¼š**GPT** åªæœ‰é‚£ä¹ˆå¤šå‚æ•°ã€‚æˆ‘ä»¬æœ‰ä¸ªæµ‹é‡ç»“æœï¼Œæ¯ä¸ªå‚æ•°å¯ä»¥å­˜å‚¨ 3.6 æ¯”ç‰¹ã€‚æ‰€ä»¥ä¸€ä¸ªåäº¿å‚æ•°çš„æ¨¡å‹æŒ‰ 3.6 æ¯”ç‰¹ç®—å¤§æ¦‚æ˜¯â€¦â€¦å››å¤ªå­—èŠ‚ï¼Ÿç­‰ç­‰ï¼Œæ˜¯ 4GB å¯¹å§ï¼Ÿå¯¹ï¼Œè°¢è°¢ã€‚

è§£æï¼š
* **fixed capacity**ï¼šå›ºå®šå®¹é‡
* **bits per parameter**ï¼šæ¯å‚æ•°æ¯”ç‰¹æ•°ï¼ˆè¡¡é‡æ¨¡å‹ä¿¡æ¯å­˜å‚¨æ•ˆç‡çš„æŒ‡æ ‡ï¼‰
* **billion parameter model**ï¼šåäº¿å‚æ•°æ¨¡å‹

---

(18) [23:38-24:03] **Um this is like some information but it's actually not that much. So the models they basically do their best to fit the training distribution and they throw everything else out. So like to give you a concrete example this morning I was putting this together. I asked Claude, "What is the capital of the smallest province in Tajikistan?" And it gave me a very detailed answer. It's actually very impressive. No web search. The model just knows this in its parameters.**

è¿™æ˜¯ä¸€äº›ä¿¡æ¯é‡ï¼Œä½†å®é™…ä¸Šå¹¶æ²¡æœ‰é‚£ä¹ˆå¤šã€‚æ‰€ä»¥æ¨¡å‹åŸºæœ¬ä¸Šä¼šå°½åŠ›æ‹Ÿåˆè®­ç»ƒåˆ†å¸ƒï¼Œç„¶åæŠŠå…¶ä»–ä¸œè¥¿éƒ½ä¸¢æ‰ã€‚ä¸¾ä¸ªå…·ä½“çš„ä¾‹å­ï¼Œä»Šå¤©æ—©ä¸Šæˆ‘åœ¨å‡†å¤‡è¿™ä¸ªæ¼”è®²æ—¶ï¼Œé—®äº† **Claude**ï¼š"å¡”å‰å…‹æ–¯å¦æœ€å°çœä»½çš„é¦–åºœæ˜¯ä»€ä¹ˆï¼Ÿ"å®ƒç»™äº†æˆ‘ä¸€ä¸ªéå¸¸è¯¦ç»†çš„ç­”æ¡ˆã€‚ç¡®å®å¾ˆä»¤äººå°è±¡æ·±åˆ»ã€‚æ²¡æœ‰ç½‘ç»œæœç´¢ï¼Œæ¨¡å‹å°±æ˜¯åœ¨å‚æ•°é‡ŒçŸ¥é“è¿™äº›ã€‚

è§£æï¼š
* **fit the training distribution**ï¼šæ‹Ÿåˆè®­ç»ƒåˆ†å¸ƒï¼ˆæœºå™¨å­¦ä¹ æœ¯è¯­ï¼‰
* **throw everything else out**ï¼šæŠŠå…¶ä»–ä¸œè¥¿éƒ½ä¸¢æ‰
* **putting this together**ï¼šå‡†å¤‡è¿™ä¸ªï¼ˆæŒ‡æ¼”è®²ï¼‰

---

(19) [24:03-24:33] **I guess I'm arguing that this is bad. Like if you want to build a system that can answer really detailed documentation questions for your company, you don't need it to know what the capital of the smallest province in Tajikistan is. And since we know these models have fixed capacity, I think that this is bad. Like what we really want is to know how to like find this kind of thing and just like delete it and replace it with the things we care about. And I think that's like what we're getting towards, but we don't 100% know how to do that again.**

æˆ‘çš„è§‚ç‚¹æ˜¯è¿™å…¶å®æ˜¯ä»¶åäº‹ã€‚å¦‚æœä½ æƒ³æ„å»ºä¸€ä¸ªèƒ½å›ç­”ä½ å…¬å¸è¯¦ç»†æ–‡æ¡£é—®é¢˜çš„ç³»ç»Ÿï¼Œä½ ä¸éœ€è¦å®ƒçŸ¥é“å¡”å‰å…‹æ–¯å¦æœ€å°çœä»½çš„é¦–åºœæ˜¯ä»€ä¹ˆã€‚æ—¢ç„¶æˆ‘ä»¬çŸ¥é“è¿™äº›æ¨¡å‹å®¹é‡æœ‰é™ï¼Œæˆ‘è®¤ä¸ºè¿™æ˜¯ä¸å¥½çš„ã€‚æˆ‘ä»¬çœŸæ­£æƒ³è¦çš„æ˜¯çŸ¥é“å¦‚ä½•æ‰¾åˆ°è¿™ç±»ä¸œè¥¿ï¼ŒæŠŠå®ƒåˆ æ‰ï¼Œç„¶åæ›¿æ¢æˆæˆ‘ä»¬å…³å¿ƒçš„å†…å®¹ã€‚æˆ‘è§‰å¾—è¿™å°±æ˜¯æˆ‘ä»¬æ­£åœ¨åŠªåŠ›çš„æ–¹å‘ï¼Œä½†æˆ‘ä»¬è¿˜ä¸æ˜¯ç™¾åˆ†ç™¾çŸ¥é“æ€ä¹ˆåšã€‚

è§£æï¼š
* **I'm arguing that**ï¼šæˆ‘çš„è®ºç‚¹æ˜¯ã€æˆ‘æƒ³è¯´çš„æ˜¯
* **fixed capacity**ï¼šå›ºå®šå®¹é‡
* **we're getting towards**ï¼šæˆ‘ä»¬æ­£åœ¨æœç€â€¦â€¦åŠªåŠ›

---

(20) [24:33-24:44] **Sorry. So when I originally put this talk together, the way I was thinking of explaining it is calling it a neural file system. And then I decided to just call it weights. I think it's easier to understand, but this slide still says neural file systems.**

æŠ±æ­‰ã€‚æœ€åˆå‡†å¤‡è¿™ä¸ªæ¼”è®²æ—¶ï¼Œæˆ‘æƒ³æŠŠå®ƒå«åš"ç¥ç»æ–‡ä»¶ç³»ç»Ÿ"ã€‚åæ¥æˆ‘å†³å®šå°±å«å®ƒ"æƒé‡"ã€‚æˆ‘è§‰å¾—è¿™æ ·æ›´å®¹æ˜“ç†è§£ï¼Œä½†è¿™å¼ å¹»ç¯ç‰‡è¿˜æ˜¯å†™ç€"ç¥ç»æ–‡ä»¶ç³»ç»Ÿ"ã€‚

è§£æï¼š
* **neural file system**ï¼šç¥ç»æ–‡ä»¶ç³»ç»Ÿï¼ˆæ¼”è®²è€…æå‡ºçš„æ¦‚å¿µï¼‰
* **weights**ï¼šæƒé‡ï¼ˆç¥ç»ç½‘ç»œä¸­å­˜å‚¨çŸ¥è¯†çš„å‚æ•°ï¼‰

---

(21) [24:44-25:11] **Um so I think there's a few questions here like we want to train all our data into the model. One question is like how do we train it? Do we do RL? Do we do SFT? Uh what's what even is the data? Um another question is like out of uh all the possible data what do we use? Do we just like fine-tune directly on our data? Do we try to generate more? I think my argument is that we should try to generate more and I'll show you why.**

è¿™é‡Œæœ‰å‡ ä¸ªé—®é¢˜ã€‚æˆ‘ä»¬æƒ³æŠŠæ‰€æœ‰æ•°æ®è®­ç»ƒè¿›æ¨¡å‹ã€‚ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šæ€ä¹ˆè®­ç»ƒï¼Ÿç”¨ **RL** è¿˜æ˜¯ **SFT**ï¼Ÿæ•°æ®åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿå¦ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šåœ¨æ‰€æœ‰å¯èƒ½çš„æ•°æ®ä¸­ï¼Œæˆ‘ä»¬ç”¨å“ªäº›ï¼Ÿæ˜¯ç›´æ¥åœ¨æˆ‘ä»¬çš„æ•°æ®ä¸Šå¾®è°ƒï¼Œè¿˜æ˜¯å°è¯•ç”Ÿæˆæ›´å¤šï¼Ÿæˆ‘çš„è§‚ç‚¹æ˜¯åº”è¯¥å°è¯•ç”Ÿæˆæ›´å¤šï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ ä¸ºä»€ä¹ˆã€‚

è§£æï¼š
* **RL**ï¼šReinforcement Learningï¼Œå¼ºåŒ–å­¦ä¹ 
* **SFT**ï¼šSupervised Fine-Tuningï¼Œæœ‰ç›‘ç£å¾®è°ƒ
* **fine-tune**ï¼šå¾®è°ƒï¼ˆåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šç»§ç»­è®­ç»ƒï¼‰

---

(22) [25:11-25:29] **And then there's an architectural question. Like I think for a long time, people really cared in the machine learning deep learning community about like what architectures we should use. And then for like what 8 years, everyone who knows what they're doing has really just been using transformers unless they're trying to make them better.**

ç„¶åè¿˜æœ‰æ¶æ„é—®é¢˜ã€‚å¾ˆé•¿ä¸€æ®µæ—¶é—´ä»¥æ¥ï¼Œæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ç¤¾åŒºçš„äººéƒ½å¾ˆå…³å¿ƒåº”è¯¥ç”¨ä»€ä¹ˆæ¶æ„ã€‚ç„¶åå¤§æ¦‚ 8 å¹´æ¥ï¼Œæ‰€æœ‰æ‡‚è¡Œçš„äººåŸºæœ¬ä¸Šéƒ½åªç”¨ **Transformer**ï¼Œé™¤éä»–ä»¬åœ¨å°è¯•æ”¹è¿›å®ƒã€‚

è§£æï¼š
* **architectural question**ï¼šæ¶æ„é—®é¢˜
* **Transformer**ï¼šTransformer æ¶æ„ï¼ˆ2017å¹´æå‡ºï¼Œç°ä»£ LLM çš„åŸºç¡€ï¼‰
* **everyone who knows what they're doing**ï¼šæ‰€æœ‰æ‡‚è¡Œçš„äººï¼ˆå£è¯­è¡¨è¾¾ï¼‰

---

(23) [25:29-25:47] **And I think now in this world where we're trying to train stuff into models like like if you think of okay world we all each of us have has our own model or maybe multiple models and those models are getting updated a lot. I think we start to care about architecture again and I'll tell you why and like what I think the options are.**

ç°åœ¨åœ¨è¿™ä¸ªæˆ‘ä»¬è¯•å›¾æŠŠä¸œè¥¿è®­ç»ƒè¿›æ¨¡å‹çš„ä¸–ç•Œé‡Œâ€”â€”æƒ³è±¡ä¸€ä¸‹ï¼Œæˆ‘ä»¬æ¯ä¸ªäººéƒ½æœ‰è‡ªå·±çš„æ¨¡å‹ï¼Œæˆ–è€…å¤šä¸ªæ¨¡å‹ï¼Œè€Œä¸”è¿™äº›æ¨¡å‹ä¼šé¢‘ç¹æ›´æ–°ã€‚æˆ‘è§‰å¾—æˆ‘ä»¬åˆå¼€å§‹å…³å¿ƒæ¶æ„äº†ï¼Œæˆ‘ä¼šå‘Šè¯‰ä½ ä¸ºä»€ä¹ˆï¼Œä»¥åŠæˆ‘è®¤ä¸ºæœ‰å“ªäº›é€‰æ‹©ã€‚

è§£æï¼š
* **train stuff into models**ï¼šæŠŠä¸œè¥¿è®­ç»ƒè¿›æ¨¡å‹
* **getting updated a lot**ï¼šé¢‘ç¹æ›´æ–°

---

(24) [25:47-26:15] **So first let's talk about learning. Um so I think like the mental model here which I mentioned before is like we're trying to train the model to learn the data as best as it possibly can and it's going to be expensive. So like we didn't like RAG but also RAG didn't cost us very much money. I think to do better than RAG, we're gonna have to like pay some GPU points and that's just like the state of the world.**

é¦–å…ˆè®©æˆ‘ä»¬è°ˆè°ˆå­¦ä¹ ã€‚æˆ‘ä¹‹å‰æåˆ°çš„å¿ƒæ™ºæ¨¡å‹æ˜¯è¿™æ ·çš„ï¼šæˆ‘ä»¬è¯•å›¾è®©æ¨¡å‹å°½å¯èƒ½å¥½åœ°å­¦ä¹ æ•°æ®ï¼Œè¿™ä¼šå¾ˆè´µã€‚æˆ‘ä»¬ä¸å¤ªæ»¡æ„ **RAG**ï¼Œä½† **RAG** ä¹Ÿæ²¡èŠ±æˆ‘ä»¬å¤šå°‘é’±ã€‚æˆ‘è®¤ä¸ºè¦åšå¾—æ¯” **RAG** æ›´å¥½ï¼Œæˆ‘ä»¬å°±å¾—èŠ±ä¸€äº› GPU ç‚¹æ•°ï¼Œè¿™å°±æ˜¯ç°çŠ¶ã€‚

è§£æï¼š
* **mental model**ï¼šå¿ƒæ™ºæ¨¡å‹ï¼ˆæ€è€ƒé—®é¢˜çš„æ¡†æ¶ï¼‰
* **pay some GPU points**ï¼šèŠ±ä¸€äº› GPU ç‚¹æ•°ï¼ˆå¹½é»˜è¯´æ³•ï¼ŒæŒ‡æ¶ˆè€—ç®—åŠ›ï¼‰
* **the state of the world**ï¼šç°çŠ¶ã€ä¸–ç•Œçš„çŠ¶æ€

---

(25) [26:15-26:45] **Okay, fine. So, this is our model. It's like this homogeneous blob of data and this is our data. So, like maybe we have the Mastercard data set or maybe we collected data about ourselves or maybe I uh collected all my traces from coding in November and December and I want to like train the model to learn my problems better. What do I do? How do I actually do this? Um let's let's like start with the dumbest possible approach and just like see what happens.**

å¥½å§ã€‚è¿™æ˜¯æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå°±åƒä¸€å›¢åŒè´¨çš„æ•°æ®å—ï¼Œè¿™æ˜¯æˆ‘ä»¬çš„æ•°æ®ã€‚ä¹Ÿè®¸æˆ‘ä»¬æœ‰ **Mastercard** æ•°æ®é›†ï¼Œæˆ–è€…æ”¶é›†äº†å…³äºè‡ªå·±çš„æ•°æ®ï¼Œæˆ–è€…æˆ‘æ”¶é›†äº† 11 æœˆå’Œ 12 æœˆæ‰€æœ‰çš„ç¼–ç¨‹è®°å½•ï¼Œæƒ³è®©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ æˆ‘çš„é—®é¢˜ã€‚æˆ‘è¯¥æ€ä¹ˆåšï¼Ÿå®é™…ä¸Šæ€ä¹ˆæ“ä½œï¼Ÿè®©æˆ‘ä»¬ä»æœ€ç¬¨çš„æ–¹æ³•å¼€å§‹ï¼Œçœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚

è§£æï¼š
* **homogeneous blob**ï¼šåŒè´¨çš„ä¸€å¨/å—ï¼ˆå½¢è±¡æè¿°æ¨¡å‹å‚æ•°ï¼‰
* **traces**ï¼šè®°å½•ã€ç—•è¿¹
* **the dumbest possible approach**ï¼šæœ€ç¬¨çš„æ–¹æ³•ï¼ˆè¿™é‡Œä¸æ˜¯è´¬ä¹‰ï¼ŒæŒ‡æœ€ç®€å•ç›´æ¥çš„æ–¹æ³•ï¼‰

---

(26) [26:45-27:20] **So say uh we start with a data set and we just train on it. Um like using I guess next token prediction. So we actually ran this little experiment. This is like uh 3M. It's a company they make duct tape and um this is like some financial reports. So maybe like you're working there and you really don't want to read all of this. So you just want to ask the model to like really understand this and be able to answer questions and like RAG isn't really working cuz it's like this weird structure and there's a lot of ways the documents interrelate.**

å‡è®¾æˆ‘ä»¬ä»ä¸€ä¸ªæ•°æ®é›†å¼€å§‹ï¼Œç›´æ¥åœ¨ä¸Šé¢è®­ç»ƒï¼Œç”¨ä¸‹ä¸€ä¸ª token é¢„æµ‹ã€‚æˆ‘ä»¬å®é™…ä¸Šåšäº†è¿™ä¸ªå°å®éªŒã€‚è¿™æ˜¯ **3M** å…¬å¸ï¼Œä»–ä»¬ç”Ÿäº§èƒ¶å¸¦ç­‰äº§å“ï¼Œè¿™æ˜¯ä¸€äº›è´¢åŠ¡æŠ¥å‘Šã€‚å‡è®¾ä½ åœ¨é‚£é‡Œå·¥ä½œï¼ŒçœŸçš„ä¸æƒ³è¯»å®Œæ‰€æœ‰è¿™äº›ã€‚ä½ åªæƒ³è®©æ¨¡å‹çœŸæ­£ç†è§£è¿™äº›å†…å®¹å¹¶èƒ½å›ç­”é—®é¢˜ï¼Œè€Œ **RAG** ä¸å¤ªå¥½ç”¨ï¼Œå› ä¸ºæ–‡æ¡£ç»“æ„å¾ˆå¥‡æ€ªï¼Œè€Œä¸”æ–‡æ¡£ä¹‹é—´æœ‰å¾ˆå¤šç›¸äº’å…³è”çš„åœ°æ–¹ã€‚

è§£æï¼š
* **next token prediction**ï¼šä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼ˆè¯­è¨€æ¨¡å‹çš„åŸºæœ¬è®­ç»ƒç›®æ ‡ï¼‰
* **3M**ï¼šæ˜å°¼è‹è¾¾çŸ¿ä¸šåˆ¶é€ å…¬å¸ï¼ˆçŸ¥åä¼ä¸šï¼‰
* **interrelate**ï¼šç›¸äº’å…³è”

---

(27) [27:20-27:40] **Okay, cool. So we're just going to like train the model using next token prediction. See what happens. You know what? Actually, even if you don't train the whole model, um you you still get zero loss. So the model can perfectly memorize this entire uh 3M 10K financial report. Um it's extremely impressive.**

å¥½çš„ï¼Œé‚£æˆ‘ä»¬å°±ç”¨ä¸‹ä¸€ä¸ª token é¢„æµ‹æ¥è®­ç»ƒæ¨¡å‹ï¼Œçœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆã€‚ä½ çŸ¥é“å—ï¼Ÿå®é™…ä¸Šå³ä½¿ä¸è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œä½ ä¹Ÿèƒ½å¾—åˆ°é›¶æŸå¤±ã€‚æ¨¡å‹å¯ä»¥å®Œç¾è®°ä½æ•´ä¸ª **3M** çš„ **10-K** è´¢åŠ¡æŠ¥å‘Šã€‚è¿™éå¸¸ä»¤äººå°è±¡æ·±åˆ»ã€‚

è§£æï¼š
* **zero loss**ï¼šé›¶æŸå¤±ï¼ˆè®­ç»ƒæŒ‡æ ‡ï¼Œè¡¨ç¤ºå®Œç¾æ‹Ÿåˆï¼‰
* **10-K**ï¼šç¾å›½ä¸Šå¸‚å…¬å¸å¹´åº¦è´¢åŠ¡æŠ¥å‘Šï¼ˆSEC è§„å®šçš„æ ¼å¼ï¼‰
* **memorize**ï¼šè®°å¿†ã€èƒŒè¯µ

---

(28) [27:46-28:04] **Okay. So now let's talk to it. So we did this and then we didn't want to ask anything that's like exactly present in the document because we want to see if the model's actually good. So we started you know like everyone loves to test poems. So we started with a poem. We said can you write a poem about 3M in fiscal year 2025? So, register your bets. And what do you think happened?**

å¥½äº†ï¼Œç°åœ¨è®©æˆ‘ä»¬è·Ÿå®ƒå¯¹è¯ã€‚æˆ‘ä»¬åšå®Œè®­ç»ƒåï¼Œä¸æƒ³é—®æ–‡æ¡£ä¸­ç›´æ¥å­˜åœ¨çš„å†…å®¹ï¼Œå› ä¸ºæˆ‘ä»¬æƒ³çœ‹æ¨¡å‹æ˜¯å¦çœŸçš„å­¦å¥½äº†ã€‚ä½ çŸ¥é“çš„ï¼Œå¤§å®¶éƒ½å–œæ¬¢ç”¨è¯—æ¥æµ‹è¯•ã€‚æ‰€ä»¥æˆ‘ä»¬ä»ä¸€é¦–è¯—å¼€å§‹ã€‚æˆ‘ä»¬è¯´"ä½ èƒ½å†™ä¸€é¦–å…³äº **3M** å…¬å¸ 2025 è´¢å¹´çš„è¯—å—ï¼Ÿ"æ¥ï¼Œä¸‹æ³¨å§ã€‚ä½ è§‰å¾—ä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ

è§£æï¼š
* **fiscal year**ï¼šè´¢å¹´
* **register your bets**ï¼šä¸‹æ³¨å§ï¼ˆå£è¯­åŒ–é‚€è¯·ï¼Œè®©å¬ä¼—çŒœæµ‹ç»“æœï¼‰

---

(29) [28:04-28:21] **It's terrible. It's terrible. Someone said it. It says the passage of a passage is a poem. End of sentence. It's crazy. Yeah. So, now maybe we ask like why does this happen and how do we fix it?**

ç»“æœå¾ˆç³Ÿç³•ã€‚çœŸçš„å¾ˆç³Ÿç³•ã€‚æœ‰äººè¯´å‡ºæ¥äº†ã€‚å®ƒå†™çš„æ˜¯"ä¸€æ®µçš„æ®µè½å°±æ˜¯ä¸€é¦–è¯—ã€‚å¥å·ã€‚"å¤ªç–¯ç‹‚äº†ã€‚å¥½ï¼Œç°åœ¨æˆ‘ä»¬æ¥é—®é—®ä¸ºä»€ä¹ˆä¼šè¿™æ ·ï¼Œä»¥åŠæ€ä¹ˆä¿®å¤ã€‚

è§£æï¼š
* æ¨¡å‹è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®åä¸§å¤±äº†æ³›åŒ–èƒ½åŠ›ï¼Œåªèƒ½è¾“å‡ºè®­ç»ƒè¯­æ–™é£æ ¼çš„å†…å®¹

---

(30) [28:21-28:33] **So, unfortunately, this doesn't work. And I actually think this is like one of the reasons why people haven't been doing this yet is because the dumbest possible approach usually does work in machine learning. But in this case, we have to do something a little bit more sophisticated.**

ä¸å¹¸çš„æ˜¯ï¼Œè¿™è¡Œä¸é€šã€‚æˆ‘è§‰å¾—è¿™å…¶å®æ˜¯äººä»¬è¿˜æ²¡è¿™ä¹ˆåšçš„åŸå› ä¹‹ä¸€â€”â€”åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæœ€ç¬¨çš„æ–¹æ³•é€šå¸¸æ˜¯ç®¡ç”¨çš„ã€‚ä½†åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¿…é¡»åšå¾—æ›´ç²¾ç»†ä¸€äº›ã€‚

è§£æï¼š
* **sophisticated**ï¼šå¤æ‚ç²¾ç»†çš„ã€è€ç»ƒçš„

---

(31) [28:33-29:15] **Um, so maybe take a second and think about like what you would do. You're facing this problem at work or in a side project. Um, I think there's like two things we need to fix. One is that um the data is not it's not exactly what we want to train on, I think. And two is that we probably don't want to update the entire model because what we did there was basically overwrite all the you know stuff about Tajikistan and everything else that's in the model with just like this 3M knowledge and I think that's like too specific and then the model is just obsessed with 3M and it'll only produce exact copy sentences from the document. That's clearly too much.**

èŠ±ç‚¹æ—¶é—´æƒ³æƒ³ä½ ä¼šæ€ä¹ˆåšã€‚å‡è®¾ä½ åœ¨å·¥ä½œä¸­æˆ–ä¸šä½™é¡¹ç›®ä¸­é‡åˆ°è¿™ä¸ªé—®é¢˜ã€‚æˆ‘è§‰å¾—æœ‰ä¸¤ä»¶äº‹éœ€è¦ä¿®å¤ã€‚ç¬¬ä¸€ï¼Œæ•°æ®ä¸å®Œå…¨æ˜¯æˆ‘ä»¬æƒ³è¦è®­ç»ƒçš„å†…å®¹ã€‚ç¬¬äºŒï¼Œæˆ‘ä»¬å¯èƒ½ä¸æƒ³æ›´æ–°æ•´ä¸ªæ¨¡å‹ï¼Œå› ä¸ºæˆ‘ä»¬åˆšæ‰åšçš„äº‹åŸºæœ¬ä¸Šæ˜¯ç”¨ **3M** çš„çŸ¥è¯†è¦†ç›–äº†æ¨¡å‹é‡Œå…³äºå¡”å‰å…‹æ–¯å¦å’Œå…¶ä»–æ‰€æœ‰çš„ä¸œè¥¿ã€‚æˆ‘è§‰å¾—é‚£å¤ªå…·ä½“äº†ï¼Œç„¶åæ¨¡å‹å°±å˜å¾—åªç—´è¿·äº **3M**ï¼Œåªä¼šäº§å‡ºæ–‡æ¡£é‡Œçš„åŸå¥å¤åˆ¶ã€‚è¿™æ˜¾ç„¶è¿‡å¤´äº†ã€‚

è§£æï¼š
* **side project**ï¼šä¸šä½™é¡¹ç›®
* **overwrite**ï¼šè¦†ç›–
* **obsessed with**ï¼šç—´è¿·äº

---

(32) [29:15-29:21] **So I think we need a better way to update the model and we need a better way to change the data.**

æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ›´å¥½çš„æ–¹å¼æ¥æ›´æ–°æ¨¡å‹ï¼Œä¹Ÿéœ€è¦æ›´å¥½çš„æ–¹å¼æ¥å¤„ç†æ•°æ®ã€‚

---

(33) [29:21-29:43] **Um, there's this pretty relevant work. I don't know if you follow this like LLM chat thing from Andrej Karpathy. Shout out. I think it's very educational and he had a really good question which is like he built this small LLM and trained it from scratch and everything and then he wanted to teach it about himself and okay maybe the first thing you would try is RAG.**

æœ‰ä¸€ä¸ªéå¸¸ç›¸å…³çš„å·¥ä½œã€‚ä¸çŸ¥é“ä½ ä»¬æœ‰æ²¡æœ‰å…³æ³¨ **Andrej Karpathy** çš„ LLM èŠå¤©é¡¹ç›®ã€‚è‡´æ•¬ä¸€ä¸‹ã€‚æˆ‘è§‰å¾—é‚£å¾ˆæœ‰æ•™è‚²æ„ä¹‰ï¼Œä»–æå‡ºäº†ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ï¼šä»–ä»å¤´æ„å»ºå¹¶è®­ç»ƒäº†ä¸€ä¸ªå°å‹ LLMï¼Œç„¶åæƒ³æ•™å®ƒå…³äºä»–è‡ªå·±çš„ä¿¡æ¯ã€‚ä½ é¦–å…ˆå¯èƒ½ä¼šå°è¯• **RAG**ã€‚

è§£æï¼š
* **Andrej Karpathy**ï¼šè‘—å AI ç ”ç©¶è€…ï¼Œå‰ Tesla AI æ€»ç›‘
* **Shout out**ï¼šè‡´æ•¬ã€ç‰¹åˆ«æä¸€ä¸‹ï¼ˆéæ­£å¼çš„è¡¨æ‰¬ï¼‰
* **from scratch**ï¼šä»å¤´å¼€å§‹

---

(34) [29:43-30:02] **You put like a little database of information about yourself but that's only scalable to a certain amount and then the model can't really like combine things. It can only kind of regurgitate facts. And so he wants to actually teach it properly, he says, meaning in weights. And so notice he doesn't just like take one example and train the model using next token prediction. He does something a bit more complicated.**

ä½ æ”¾ä¸€ä¸ªå…³äºè‡ªå·±çš„å°å‹ä¿¡æ¯æ•°æ®åº“ï¼Œä½†è¿™åªèƒ½æ‰©å±•åˆ°ä¸€å®šç¨‹åº¦ï¼Œç„¶åæ¨¡å‹å°±æ— æ³•çœŸæ­£æŠŠä¸œè¥¿ç»“åˆèµ·æ¥äº†ï¼Œå®ƒåªèƒ½åƒé¹¦é¹‰å­¦èˆŒä¸€æ ·å¤è¿°äº‹å®ã€‚æ‰€ä»¥ä»–æƒ³çœŸæ­£åœ°æ•™ä¼šå®ƒï¼Œä»–è¯´çš„æ˜¯åœ¨æƒé‡ä¸­ã€‚æ³¨æ„ä»–æ²¡æœ‰åªæ‹¿ä¸€ä¸ªä¾‹å­ç”¨ä¸‹ä¸€ä¸ª token é¢„æµ‹æ¥è®­ç»ƒæ¨¡å‹ã€‚ä»–åšäº†ä¸€äº›æ›´å¤æ‚çš„äº‹æƒ…ã€‚

è§£æï¼š
* **scalable**ï¼šå¯æ‰©å±•çš„
* **regurgitate facts**ï¼šååˆäº‹å®ã€æœºæ¢°å¤è¿°ï¼ˆregurgitate åŸæ„æ˜¯ååˆï¼Œè¿™é‡Œå½¢å®¹æœºæ¢°å¤è¿°ï¼‰
* **in weights**ï¼šåœ¨æƒé‡ä¸­ï¼ˆæŒ‡é€šè¿‡è®­ç»ƒå†…åŒ–çŸ¥è¯†ï¼‰

---

## æ®µè½å°ç»“

### æ ¸å¿ƒè§‚ç‚¹

1. **Agentic Search vs RAG**ï¼šä¸¤è€…æœºåˆ¶ä¸åŒï¼Œä¸åº”ç®€å•å½’ç±»

2. **æ›´å¥½å¿…ç„¶æ›´è´µ**ï¼šä»»ä½•æ¯” **RAG** æ•ˆæœæ›´å¥½çš„æ–¹æ¡ˆéƒ½éœ€è¦åœ¨è®­ç»ƒæ—¶æˆ–æ¨ç†æ—¶ä»˜å‡ºæ›´å¤šæˆæœ¬ï¼Œè¿™æ˜¯ä¸å¯é¿å…çš„ **trade-off**

3. **Deep Research æ–¹å‘æ­£ç¡®**ï¼šè™½ç„¶æ¨ç†æ—¶é—´é•¿ï¼Œä½†æ„¿æ„ç­‰å¾…å’Œå¤šæ¬¡æœç´¢æ˜¯æ­£ç¡®çš„æ–¹å‘

4. **æ¨¡å‹å®¹é‡æœ‰é™**ï¼šè¯­è¨€æ¨¡å‹çº¦ 3.6 bits/å‚æ•°çš„å­˜å‚¨èƒ½åŠ›ï¼Œå­˜å‚¨æ— å…³çŸ¥è¯†ä¼šå ç”¨å®è´µç©ºé—´

5. **ç›´æ¥å¾®è°ƒçš„é—®é¢˜**ï¼š
   - æ¨¡å‹ä¼šå®Œç¾è®°å¿†è®­ç»ƒæ•°æ®
   - ä½†ä¸§å¤±æ³›åŒ–èƒ½åŠ›ï¼ˆæ— æ³•å†™è¯—ï¼‰
   - ä¼šè¦†ç›–åŸæœ‰çŸ¥è¯†
   - åªèƒ½å¤è¿°åŸæ–‡

6. **ä¸¤ä¸ªéœ€è¦è§£å†³çš„é—®é¢˜**ï¼šæ•°æ®éœ€è¦è½¬æ¢ + æ›´æ–°ç­–ç•¥éœ€è¦æ”¹è¿›

7. **æ¶æ„å†æ¬¡é‡è¦**ï¼šä¸ªæ€§åŒ–æ¨¡å‹æ—¶ä»£ï¼Œéœ€è¦é‡æ–°å…³æ³¨æ¨¡å‹æ¶æ„è®¾è®¡

### é‡ç‚¹è¯æ±‡è¡¨

| è¯æ±‡ | è¯æ€§ | å«ä¹‰ |
|------|------|------|
| **agentic search** | n. | æ™ºèƒ½ä½“æœç´¢ |
| **RAG** | n. | æ£€ç´¢å¢å¼ºç”Ÿæˆ |
| **inference time** | n. | æ¨ç†æ—¶é—´ |
| **training time** | n. | è®­ç»ƒæ—¶é—´ |
| **trade-off** | n. | æƒè¡¡ã€å–èˆ |
| **up front** | adv. | é¢„å…ˆ |
| **in weights** | prep. | åœ¨æƒé‡ä¸­ |
| **in context** | prep. | åœ¨ä¸Šä¸‹æ–‡ä¸­ |
| **fixed capacity** | n. | å›ºå®šå®¹é‡ |
| **bits per parameter** | n. | æ¯å‚æ•°æ¯”ç‰¹æ•° |
| **SFT** | n. | æœ‰ç›‘ç£å¾®è°ƒ |
| **RL** | n. | å¼ºåŒ–å­¦ä¹  |
| **fine-tune** | v. | å¾®è°ƒ |
| **next token prediction** | n. | ä¸‹ä¸€ä¸ª token é¢„æµ‹ |
| **10-K** | n. | å¹´åº¦è´¢åŠ¡æŠ¥å‘Š |
| **regurgitate** | v. | æœºæ¢°å¤è¿° |
| **sophisticated** | adj. | å¤æ‚ç²¾ç»†çš„ |
| **obsessed with** | adj. | ç—´è¿·äº |
| **shout out** | v. | è‡´æ•¬ |
| **from scratch** | adv. | ä»å¤´å¼€å§‹ |

### å£è¯­è¡¨è¾¾

| è¡¨è¾¾ | å«ä¹‰ |
|------|------|
| I guess | æˆ‘è§‰å¾—ï¼ˆæ¯” I think æ›´éšæ„ï¼‰ |
| a bunch of | ä¸€å †ã€å¾ˆå¤š |
| in a row | è¿ç»­åœ° |
| kind of / sort of | æœ‰ç‚¹ã€æŸç§ç¨‹åº¦ä¸Š |
| you know | ä½ æ‡‚çš„ï¼ˆå¡«å……è¯ï¼‰ |
| It's been a while | å·²ç»å¾ˆä¹…äº† |
| get you pretty far | æ•ˆæœä¸é”™ |
| register your bets | ä¸‹æ³¨å§ |
| the dumbest possible approach | æœ€ç®€å•ç›´æ¥çš„æ–¹æ³• |
| pay some GPU points | èŠ±è´¹ç®—åŠ›ï¼ˆå¹½é»˜è¯´æ³•ï¼‰ |

---

# ç¬¬äºŒéƒ¨åˆ†ï¼šåˆæˆæ•°æ®ä¸å‚æ•°é«˜æ•ˆå¾®è°ƒ

> æ—¶é—´ï¼š30:08 - 40:20

---

(35) [30:08-30:20] **He like generates this task or you don't have to care about the specifics, but there's like basically he makes a diverse training data set of examples that look like the thing he cares about and then trains on it. And if you go, you can find this. It actually does work pretty well, which is cool.**

ä»–ä¼šç”Ÿæˆè¿™ä¸ªä»»åŠ¡â€”â€”ä½ ä¸ç”¨åœ¨æ„å…·ä½“ç»†èŠ‚â€”â€”ä½†åŸºæœ¬ä¸Šä»–ä¼šåˆ¶ä½œä¸€ä¸ªå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®é›†ï¼Œè¿™äº›æ ·æœ¬çœ‹èµ·æ¥åƒä»–å…³å¿ƒçš„ä¸œè¥¿ï¼Œç„¶ååœ¨ä¸Šé¢è®­ç»ƒã€‚å¦‚æœä½ å»æ‰¾ï¼Œä½ èƒ½æ‰¾åˆ°è¿™ä¸ªé¡¹ç›®ã€‚å®ƒå®é™…ä¸Šæ•ˆæœç›¸å½“å¥½ï¼Œå¾ˆé…·ã€‚

è§£æï¼š
* **diverse training data set**ï¼šå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®é›†
* **look like the thing he cares about**ï¼šçœ‹èµ·æ¥åƒä»–å…³å¿ƒçš„ä¸œè¥¿ï¼ˆæŒ‡ç¬¦åˆç›®æ ‡åˆ†å¸ƒçš„æ•°æ®ï¼‰

---

(36) [30:20-30:30] **So, he's able to teach a novel behavior to a model by like generating a lot of synthetic data that looks like the example he cares about and then fine-tuning the model for a little bit and it and it learns.**

æ‰€ä»¥ï¼Œä»–èƒ½å¤Ÿé€šè¿‡ç”Ÿæˆå¤§é‡çœ‹èµ·æ¥åƒä»–å…³å¿ƒçš„ç¤ºä¾‹çš„åˆæˆæ•°æ®ï¼Œç„¶åå¯¹æ¨¡å‹è¿›è¡Œä¸€ç‚¹ç‚¹å¾®è°ƒï¼Œè®©æ¨¡å‹å­¦ä¼šä¸€ç§æ–°è¡Œä¸ºã€‚

è§£æï¼š
* **novel behavior**ï¼šæ–°è¡Œä¸ºã€æ–°èƒ½åŠ›
* **synthetic data**ï¼šåˆæˆæ•°æ®ï¼ˆAI ç”Ÿæˆçš„æ•°æ®ï¼ŒéçœŸå®æ”¶é›†çš„ï¼‰
* **fine-tuning**ï¼šå¾®è°ƒ

---

(37) [30:30-30:48] **There's a paper that's really good uh that's from last year from some folks at Stanford called synthetic continued pre-training and they have the same problem. So they have like a really small data set and they want to teach the model to the data set without like bricking the model essentially.**

æœ‰ä¸€ç¯‡å¾ˆå¥½çš„è®ºæ–‡ï¼Œå»å¹´ **Stanford** çš„ä¸€äº›äººå‘è¡¨çš„ï¼Œå«åš **Synthetic Continued Pre-training**ï¼ˆåˆæˆæŒç»­é¢„è®­ç»ƒï¼‰ï¼Œä»–ä»¬é¢ä¸´åŒæ ·çš„é—®é¢˜ã€‚ä»–ä»¬æœ‰ä¸€ä¸ªå¾ˆå°çš„æ•°æ®é›†ï¼Œæƒ³è®©æ¨¡å‹å­¦ä¼šè¿™ä¸ªæ•°æ®é›†ï¼ŒåŒæ—¶åˆä¸èƒ½æŠŠæ¨¡å‹æåã€‚

è§£æï¼š
* **Synthetic Continued Pre-training**ï¼šåˆæˆæŒç»­é¢„è®­ç»ƒï¼ˆè®ºæ–‡åï¼‰
* **bricking the model**ï¼šæŠŠæ¨¡å‹æåï¼ˆbrick åŸæ„æ˜¯ç –å¤´ï¼Œè¿™é‡ŒæŒ‡è®©è®¾å¤‡å˜ç –ã€å˜å¾—æ— æ³•ä½¿ç”¨ï¼‰

---

(38) [30:48-31:06] **And they have this kind of fancy way of generating synthetic data by extracting entities. But I think the important part is that they take a small data set and they generate like a very large more diverse data set representative of the thing that they care about.**

ä»–ä»¬æœ‰ä¸€ç§æ¯”è¾ƒå·§å¦™çš„æ–¹æ³•ï¼Œé€šè¿‡æå–å®ä½“æ¥ç”Ÿæˆåˆæˆæ•°æ®ã€‚ä½†æˆ‘è®¤ä¸ºé‡è¦çš„æ˜¯ï¼šä»–ä»¬æ‹¿ä¸€ä¸ªå°æ•°æ®é›†ï¼Œç”Ÿæˆä¸€ä¸ªéå¸¸å¤§çš„ã€æ›´å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œè¿™ä¸ªæ•°æ®é›†èƒ½ä»£è¡¨ä»–ä»¬å…³å¿ƒçš„å†…å®¹ã€‚

è§£æï¼š
* **fancy**ï¼šå·§å¦™çš„ã€èŠ±å“¨çš„ï¼ˆå£è¯­ä¸­å¸¸è¡¨ç¤º"å¤æ‚ä½†æœ‰æ•ˆ"ï¼‰
* **extracting entities**ï¼šæå–å®ä½“ï¼ˆNLP æŠ€æœ¯ï¼‰
* **representative of**ï¼šä»£è¡¨â€¦â€¦çš„ã€èƒ½åæ˜ â€¦â€¦çš„

---

(39) [31:06-31:20] **And this is something that like breaks the whole like conventional machine learning paradigm. Like they only have a small training data set. So uh what you learn in school would tell you that you would just like overfit and there's nothing you can do. You just have to go back and collect more data.**

è¿™æ‰“ç ´äº†æ•´ä¸ªä¼ ç»Ÿæœºå™¨å­¦ä¹ èŒƒå¼ã€‚ä»–ä»¬åªæœ‰ä¸€ä¸ªå°è®­ç»ƒæ•°æ®é›†ã€‚ä½ åœ¨å­¦æ ¡å­¦åˆ°çš„çŸ¥è¯†ä¼šå‘Šè¯‰ä½ ï¼šä½ ä¼šè¿‡æ‹Ÿåˆï¼Œæ²¡åŠæ³•ï¼Œä½ åªèƒ½å›å»æ”¶é›†æ›´å¤šæ•°æ®ã€‚

è§£æï¼š
* **conventional machine learning paradigm**ï¼šä¼ ç»Ÿæœºå™¨å­¦ä¹ èŒƒå¼
* **overfit**ï¼šè¿‡æ‹Ÿåˆï¼ˆæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¥½ï¼Œä½†æ³›åŒ–èƒ½åŠ›å·®ï¼‰
* **what you learn in school**ï¼šä½ åœ¨å­¦æ ¡å­¦åˆ°çš„ï¼ˆæš—ç¤ºæ•™ç§‘ä¹¦çŸ¥è¯†å·²è¿‡æ—¶ï¼‰

---

(40) [31:20-31:38] **But actually because LLMs are so good now we can do this second thing where we generate like a much larger training data set. It really contains only the like facts that were present in the original data but it's so large that you can train a model on it. It's like very strange. It only recently started working, but it does work. I'll show you some evidence.**

ä½†å®é™…ä¸Šå› ä¸º LLM ç°åœ¨å¤ªå¼ºäº†ï¼Œæˆ‘ä»¬å¯ä»¥åšç¬¬äºŒä»¶äº‹ï¼šç”Ÿæˆä¸€ä¸ªå¤§å¾—å¤šçš„è®­ç»ƒæ•°æ®é›†ã€‚å®ƒå®é™…ä¸ŠåªåŒ…å«åŸå§‹æ•°æ®ä¸­å­˜åœ¨çš„äº‹å®ï¼Œä½†å®ƒè¶³å¤Ÿå¤§ï¼Œä½ å¯ä»¥åœ¨ä¸Šé¢è®­ç»ƒæ¨¡å‹ã€‚è¿™å¾ˆå¥‡æ€ªã€‚å®ƒæœ€è¿‘æ‰å¼€å§‹å¥æ•ˆï¼Œä½†ç¡®å®æœ‰æ•ˆã€‚æˆ‘ä¼šç»™ä½ å±•ç¤ºä¸€äº›è¯æ®ã€‚

è§£æï¼š
* **contains only the facts that were present in the original data**ï¼šåªåŒ…å«åŸå§‹æ•°æ®ä¸­çš„äº‹å®ï¼ˆæ²¡æœ‰å¼•å…¥æ–°ä¿¡æ¯ï¼Œåªæ˜¯é‡æ–°è¡¨è¿°ï¼‰
* **It only recently started working**ï¼šæœ€è¿‘æ‰å¼€å§‹å¥æ•ˆï¼ˆå¼ºè°ƒè¿™æ˜¯æ–°å‘ç°ï¼‰

---

(41) [31:38-31:50] **Um, the green line is what happens when you do the dumb thing before. So, you just like fine-tune the model on the data. It actually starts at the black line. So, surprisingly, it actually gets worse.**

ç»¿çº¿æ˜¯ä¹‹å‰é‚£ä¸ªç¬¨æ–¹æ³•çš„ç»“æœâ€”â€”å°±æ˜¯ç›´æ¥åœ¨æ•°æ®ä¸Šå¾®è°ƒæ¨¡å‹ã€‚å®ƒå®é™…ä¸Šä»é»‘çº¿å¼€å§‹ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œå®ƒå®é™…ä¸Šå˜å·®äº†ã€‚

è§£æï¼š
* **the dumb thing**ï¼šé‚£ä¸ªç¬¨æ–¹æ³•ï¼ˆæŒ‡ä¹‹å‰æåˆ°çš„ç›´æ¥å¾®è°ƒï¼‰
* **starts at the black line**ï¼šä»é»‘çº¿å¼€å§‹ï¼ˆåŸºçº¿ï¼‰
* **gets worse**ï¼šå˜å·®äº†

---

(42) [31:50-32:02] **So, it like memorizes the data so well that it can't answer any slightly different questions about it. Um the thing they do they have like two different ways of doing it but it's basically like generating lots of synthetic data that describes the things in the original data set.**

æ¨¡å‹æŠŠæ•°æ®è®°å¾—å¤ªå¥½äº†ï¼Œä»¥è‡³äºæ— æ³•å›ç­”ä»»ä½•ç¨å¾®ä¸åŒçš„é—®é¢˜ã€‚ä»–ä»¬åšçš„äº‹æƒ…æœ‰ä¸¤ç§ä¸åŒçš„æ–¹å¼ï¼Œä½†åŸºæœ¬ä¸Šå°±æ˜¯ç”Ÿæˆå¤§é‡æè¿°åŸå§‹æ•°æ®é›†å†…å®¹çš„åˆæˆæ•°æ®ã€‚

è§£æï¼š
* **memorizes the data so well**ï¼šè®°å¾—å¤ªå¥½äº†ï¼ˆè¿‡åº¦æ‹Ÿåˆï¼‰
* **slightly different questions**ï¼šç¨å¾®ä¸åŒçš„é—®é¢˜ï¼ˆæµ‹è¯•æ³›åŒ–èƒ½åŠ›ï¼‰

---

(43) [32:02-32:14] **It works very well like at some scale I guess 100 million tokens close to a billion they can actually outperform GPT-4 in this data set which is really cool.**

æ•ˆæœéå¸¸å¥½ã€‚åœ¨æŸä¸ªè§„æ¨¡ä¸‹ï¼Œæˆ‘çŒœå¤§æ¦‚ 1 äº¿åˆ°æ¥è¿‘ 10 äº¿ä¸ª tokenï¼Œä»–ä»¬å®é™…ä¸Šèƒ½åœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè¶…è¿‡ **GPT-4**ï¼Œè¿™çœŸçš„å¾ˆé…·ã€‚

è§£æï¼š
* **at some scale**ï¼šåœ¨æŸä¸ªè§„æ¨¡ä¸‹
* **100 million tokens**ï¼š1 äº¿ä¸ª token
* **outperform**ï¼šè¶…è¿‡ã€è¡¨ç°ä¼˜äº

---

(44) [32:14-32:26] **So I think like the takeaway here is even though you don't have a lot of data, if you're willing to generate like a large synthetic data set that describes the data you have, you can actually train a model on it and it works really well.**

æ‰€ä»¥æˆ‘è®¤ä¸ºè¿™é‡Œçš„è¦ç‚¹æ˜¯ï¼šå³ä½¿ä½ æ²¡æœ‰å¾ˆå¤šæ•°æ®ï¼Œå¦‚æœä½ æ„¿æ„ç”Ÿæˆä¸€ä¸ªæè¿°ä½ ç°æœ‰æ•°æ®çš„å¤§å‹åˆæˆæ•°æ®é›†ï¼Œä½ å®é™…ä¸Šå¯ä»¥åœ¨ä¸Šé¢è®­ç»ƒæ¨¡å‹ï¼Œè€Œä¸”æ•ˆæœå¾ˆå¥½ã€‚

è§£æï¼š
* **the takeaway**ï¼šè¦ç‚¹ã€å…³é”®æ”¶è·
* **describes the data you have**ï¼šæè¿°ä½ ç°æœ‰çš„æ•°æ®

---

(45) [32:26-32:43] **There's a bunch of other papers that do this. One is called Active Reading. Um they basically ask the LLM how what types of things should we generate? Then they generate from it. There is Self-Study which is from this Karpathy's paper which is more like question answering like asking the model to like quiz itself.**

è¿˜æœ‰å¾ˆå¤šå…¶ä»–è®ºæ–‡åœ¨åšè¿™ä»¶äº‹ã€‚ä¸€ä¸ªå« **Active Reading**ã€‚ä»–ä»¬åŸºæœ¬ä¸Šé—® LLMï¼šæˆ‘ä»¬åº”è¯¥ç”Ÿæˆä»€ä¹ˆç±»å‹çš„å†…å®¹ï¼Ÿç„¶åä»ä¸­ç”Ÿæˆã€‚è¿˜æœ‰ **Self-Study**ï¼Œæ¥è‡ª **Karpathy** çš„è®ºæ–‡ï¼Œæ›´åƒæ˜¯é—®ç­”å½¢å¼ï¼Œè®©æ¨¡å‹è‡ªæˆ‘æµ‹éªŒã€‚

è§£æï¼š
* **Active Reading**ï¼šä¸»åŠ¨é˜…è¯»ï¼ˆè®ºæ–‡åï¼‰
* **Self-Study**ï¼šè‡ªå­¦ï¼ˆè®ºæ–‡åï¼‰
* **quiz itself**ï¼šè‡ªæˆ‘æµ‹éªŒ

---

(46) [32:43-33:00] **And then there's this Rephrasing the Web thing. I didn't realize my whatever a Rephrasing the Web thing where they kind of like rephrase an entire pre-training data set. So this actually works at scale in kind of a surprising way. Um and there's a lot more work in this direction.**

ç„¶åè¿˜æœ‰è¿™ä¸ª **Rephrasing the Web** çš„å·¥ä½œâ€”â€”ä»–ä»¬é‡æ–°è¡¨è¿°æ•´ä¸ªé¢„è®­ç»ƒæ•°æ®é›†ã€‚è¿™åœ¨è§„æ¨¡ä¸Šç«Ÿç„¶èƒ½ç”¨ï¼ŒæŒºè®©äººæƒŠè®¶çš„ã€‚è¿™ä¸ªæ–¹å‘è¿˜æœ‰å¾ˆå¤šå·¥ä½œã€‚

è§£æï¼š
* **Rephrasing the Web**ï¼šé‡æ–°è¡¨è¿°ç½‘ç»œï¼ˆè®ºæ–‡/é¡¹ç›®åï¼‰
* **rephrase**ï¼šé‡æ–°è¡¨è¿°ã€æ”¹å†™
* **works at scale**ï¼šåœ¨è§„æ¨¡ä¸Šæœ‰æ•ˆï¼ˆèƒ½å¤„ç†å¤§é‡æ•°æ®ï¼‰

---

(47) [33:00-33:14] **So I'm really excited about this like and I'm kind of monitoring it. There's a company called Daytology that's doing this really well. They're like generating really high-quality synthetic data. It's just like not something that used to be possible until very recently when LLMs crossed some threshold that they're like able to generate data that's good enough to actually train themselves on.**

æ‰€ä»¥æˆ‘å¯¹è¿™ä¸ªæ–¹å‘çœŸçš„å¾ˆå…´å¥‹ï¼Œæˆ‘ä¸€ç›´åœ¨å…³æ³¨ã€‚æœ‰ä¸€å®¶å« **Daytology** çš„å…¬å¸åœ¨è¿™æ–¹é¢åšå¾—å¾ˆå¥½ã€‚ä»–ä»¬åœ¨ç”Ÿæˆéå¸¸é«˜è´¨é‡çš„åˆæˆæ•°æ®ã€‚è¿™åœ¨ä»¥å‰æ˜¯ä¸å¯èƒ½çš„ï¼Œç›´åˆ°æœ€è¿‘ LLM è·¨è¿‡äº†æŸä¸ªé—¨æ§›ï¼Œå®ƒä»¬èƒ½å¤Ÿç”Ÿæˆè¶³å¤Ÿå¥½çš„æ•°æ®æ¥è®­ç»ƒè‡ªå·±ã€‚

è§£æï¼š
* **monitoring it**ï¼šå…³æ³¨ã€ç›‘æµ‹
* **crossed some threshold**ï¼šè·¨è¿‡äº†æŸä¸ªé—¨æ§›/é˜ˆå€¼
* **good enough to actually train themselves on**ï¼šå¥½åˆ°å¯ä»¥ç”¨æ¥è®­ç»ƒè‡ªå·±

---

(48) [33:14-33:38] **Oh, there's actually something pretty cool. It's not in the slide. It's called Self Adapting Language Models, Self-Edit. It's called SEAL. S E A L. And they uh ask the model what data to generate to make itself better. And under some like constrained scenarios, this is actually working. So that's like actually quite bizarre.**

å“¦ï¼Œè¿˜æœ‰ä¸€ä¸ªå¾ˆé…·çš„ä¸œè¥¿ï¼Œä¸åœ¨å¹»ç¯ç‰‡é‡Œã€‚å«åšè‡ªé€‚åº”è¯­è¨€æ¨¡å‹ï¼Œ**Self-Edit**ï¼Œç¼©å†™æ˜¯ **SEAL**ã€‚ä»–ä»¬è®©æ¨¡å‹å†³å®šç”Ÿæˆä»€ä¹ˆæ•°æ®æ¥è®©è‡ªå·±å˜å¾—æ›´å¥½ã€‚åœ¨ä¸€äº›å—é™åœºæ™¯ä¸‹ï¼Œè¿™å®é™…ä¸Šæ˜¯æœ‰æ•ˆçš„ã€‚è¿™ç›¸å½“è¯¡å¼‚ã€‚

è§£æï¼š
* **SEAL**ï¼šSelf-Adapting Language Models çš„ç¼©å†™
* **constrained scenarios**ï¼šå—é™åœºæ™¯
* **bizarre**ï¼šè¯¡å¼‚çš„ã€å¥‡æ€ªçš„

---

(49) [33:38-33:52] **Um, and like obviously doesn't work infinitely or else they would have caused an intelligence explosion. But the fact that it works at all is like really remarkable and I think like worth monitoring.**

æ˜¾ç„¶å®ƒä¸èƒ½æ— é™åœ°å·¥ä½œï¼Œå¦åˆ™ä»–ä»¬å°±å·²ç»å¼•å‘æ™ºèƒ½çˆ†ç‚¸äº†ã€‚ä½†å®ƒèƒ½å·¥ä½œè¿™ä»¶äº‹æœ¬èº«å°±éå¸¸äº†ä¸èµ·ï¼Œæˆ‘è®¤ä¸ºå€¼å¾—æŒç»­å…³æ³¨ã€‚

è§£æï¼š
* **intelligence explosion**ï¼šæ™ºèƒ½çˆ†ç‚¸ï¼ˆAI è‡ªæˆ‘æ”¹è¿›å¯¼è‡´èƒ½åŠ›æ€¥å‰§å¢é•¿çš„å‡è¯´ï¼‰
* **the fact that it works at all**ï¼šå®ƒèƒ½å·¥ä½œè¿™ä»¶äº‹æœ¬èº«
* **remarkable**ï¼šäº†ä¸èµ·çš„ã€å€¼å¾—æ³¨æ„çš„

---

(50) [33:52-34:04] **So in conclusion for this section, we want to train things into weights. We can generate large synthetic data sets that describe very pretty small data sets and it works fine. Um, now I think the money question here is like how do we inject the information into the model?**

æ‰€ä»¥è¿™ä¸€éƒ¨åˆ†çš„ç»“è®ºæ˜¯ï¼šæˆ‘ä»¬æƒ³æŠŠä¸œè¥¿è®­ç»ƒè¿›æƒé‡ã€‚æˆ‘ä»¬å¯ä»¥ç”Ÿæˆå¤§å‹åˆæˆæ•°æ®é›†æ¥æè¿°éå¸¸å°çš„æ•°æ®é›†ï¼Œè€Œä¸”æ•ˆæœä¸é”™ã€‚ç°åœ¨æˆ‘è®¤ä¸ºå…³é”®é—®é¢˜æ˜¯ï¼šæˆ‘ä»¬å¦‚ä½•æŠŠä¿¡æ¯æ³¨å…¥æ¨¡å‹ï¼Ÿ

è§£æï¼š
* **in conclusion for this section**ï¼šè¿™ä¸€éƒ¨åˆ†çš„ç»“è®º
* **the money question**ï¼šå…³é”®é—®é¢˜ã€æ ¸å¿ƒé—®é¢˜ï¼ˆå£è¯­è¡¨è¾¾ï¼ŒæŒ‡æœ€é‡è¦çš„é—®é¢˜ï¼‰

---

(51) [34:04-34:17] **I think before I mentioned we were training all the parameters and we tried it and it worked really bad. And this is a problem that's been around for a long time. It's called like catastrophic forgetting.**

ä¹‹å‰æˆ‘æåˆ°æˆ‘ä»¬è®­ç»ƒäº†æ‰€æœ‰å‚æ•°ï¼Œå°è¯•äº†ä¸€ä¸‹ï¼Œæ•ˆæœå¾ˆå·®ã€‚è¿™æ˜¯ä¸€ä¸ªå­˜åœ¨å¾ˆä¹…çš„é—®é¢˜ï¼Œå«åšç¾éš¾æ€§é—å¿˜ã€‚

è§£æï¼š
* **catastrophic forgetting**ï¼šç¾éš¾æ€§é—å¿˜ï¼ˆç¥ç»ç½‘ç»œå­¦æ–°çŸ¥è¯†æ—¶å¿˜æ‰æ—§çŸ¥è¯†çš„ç°è±¡ï¼‰
* **been around for a long time**ï¼šå­˜åœ¨å¾ˆä¹…äº†

---

(52) [34:17-34:33] **Um, even in old school machine learning like you train a model to recognize handwritten digits and then you train a model to recognize house numbers and it's no longer able to recognize handwritten digits. This is like a very well-known problem. There's a lot of like theory and like approaches proposed to solve it, but no one really knows how to solve it. It's very very hard.**

å³ä½¿åœ¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ ä¸­ä¹Ÿæ˜¯è¿™æ ·ï¼šä½ è®­ç»ƒä¸€ä¸ªæ¨¡å‹è¯†åˆ«æ‰‹å†™æ•°å­—ï¼Œç„¶åè®­ç»ƒå®ƒè¯†åˆ«é—¨ç‰Œå·ï¼Œå®ƒå°±ä¸å†èƒ½è¯†åˆ«æ‰‹å†™æ•°å­—äº†ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸è‘—åçš„é—®é¢˜ã€‚æœ‰å¾ˆå¤šç†è®ºå’Œæ–¹æ³•è¢«æå‡ºæ¥è§£å†³å®ƒï¼Œä½†æ²¡äººçœŸæ­£çŸ¥é“æ€ä¹ˆè§£å†³ã€‚è¿™éå¸¸éå¸¸éš¾ã€‚

è§£æï¼š
* **old school machine learning**ï¼šä¼ ç»Ÿæœºå™¨å­¦ä¹ 
* **handwritten digits**ï¼šæ‰‹å†™æ•°å­—ï¼ˆå¦‚ MNIST æ•°æ®é›†ï¼‰
* **house numbers**ï¼šé—¨ç‰Œå·ï¼ˆå¦‚ SVHN æ•°æ®é›†ï¼‰

---

(53) [34:33-34:51] **Um, but I think there are some easy ways we can get around it in the conventional paradigm where we have like this big pre-trained ChatGPT transformer. Uh, instead of retraining the entire model, there's a few different ways we can do it.**

ä½†æˆ‘è®¤ä¸ºåœ¨ä¼ ç»ŸèŒƒå¼ä¸‹æœ‰ä¸€äº›ç®€å•çš„æ–¹æ³•å¯ä»¥ç»•è¿‡è¿™ä¸ªé—®é¢˜ï¼Œå°±æ˜¯å½“æˆ‘ä»¬æœ‰ä¸€ä¸ªå¤§å‹é¢„è®­ç»ƒçš„ **ChatGPT** **Transformer** æ—¶ã€‚æˆ‘ä»¬å¯ä»¥ä¸é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ï¼Œæœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•ã€‚

è§£æï¼š
* **get around it**ï¼šç»•è¿‡å®ƒã€è§„é¿å®ƒ
* **conventional paradigm**ï¼šä¼ ç»ŸèŒƒå¼
* **pre-trained**ï¼šé¢„è®­ç»ƒçš„

---

(54) [34:51-35:03] **I mean, the first one is retraining the entire model. So, the things we're training I'm highlighting in blue here. That's like if we take our transformer and we update all the parameters, we're probably going to forget stuff.**

ç¬¬ä¸€ç§æ˜¯é‡æ–°è®­ç»ƒæ•´ä¸ªæ¨¡å‹ã€‚æˆ‘åœ¨è¿™é‡Œç”¨è“è‰²é«˜äº®æ˜¾ç¤ºæˆ‘ä»¬æ­£åœ¨è®­ç»ƒçš„éƒ¨åˆ†ã€‚å¦‚æœæˆ‘ä»¬æ‹¿ **Transformer** æ›´æ–°æ‰€æœ‰å‚æ•°ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šé—å¿˜ä¸€äº›ä¸œè¥¿ã€‚

è§£æï¼š
* **highlighting in blue**ï¼šç”¨è“è‰²é«˜äº®
* **forget stuff**ï¼šé—å¿˜ä¸€äº›ä¸œè¥¿

---

(55) [35:03-35:16] **Um, there's another one that's pretty cool called Prefix Tuning where you just train the KV cache. Um, I mean, I'll like skip the details for now, but ask me if you have questions. Prefix Tuning is cool.**

è¿˜æœ‰ä¸€ä¸ªå¾ˆé…·çš„æ–¹æ³•å« **Prefix Tuning**ï¼Œä½ åªè®­ç»ƒ KV ç¼“å­˜ã€‚æˆ‘ç°åœ¨å…ˆè·³è¿‡ç»†èŠ‚ï¼Œå¦‚æœæœ‰é—®é¢˜å¯ä»¥é—®æˆ‘ã€‚**Prefix Tuning** å¾ˆé…·ã€‚

è§£æï¼š
* **Prefix Tuning**ï¼šå‰ç¼€è°ƒä¼˜ï¼ˆä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼‰
* **KV cache**ï¼šé”®å€¼ç¼“å­˜ï¼ˆTransformer ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ç»„ä»¶ï¼‰

---

(56) [35:16-35:30] **Um, another way is since a lot of these models are called like Mixture of Experts and they have this MLP layer in them, you can add another part to the MLP that is optionally routed to and used and that's like pretty scalable. I think people try this.**

å¦ä¸€ç§æ–¹æ³•æ˜¯ï¼Œå› ä¸ºå¾ˆå¤šæ¨¡å‹å«åšæ··åˆä¸“å®¶æ¨¡å‹ï¼Œé‡Œé¢æœ‰ MLP å±‚ï¼Œä½ å¯ä»¥åœ¨ MLP ä¸Šæ·»åŠ å¦ä¸€éƒ¨åˆ†ï¼Œå¯é€‰åœ°è·¯ç”±åˆ°å¹¶ä½¿ç”¨å®ƒï¼Œè¿™å¾ˆå¯æ‰©å±•ã€‚æˆ‘è®¤ä¸ºæœ‰äººå°è¯•è¿‡è¿™ä¸ªã€‚

è§£æï¼š
* **Mixture of Experts (MoE)**ï¼šæ··åˆä¸“å®¶æ¨¡å‹
* **MLP layer**ï¼šå¤šå±‚æ„ŸçŸ¥å™¨å±‚
* **optionally routed to**ï¼šå¯é€‰åœ°è·¯ç”±åˆ°

---

(57) [35:30-35:47] **Um, there's another approach where you replace instead of like another MLP, you build this thing called a memory layer which is like a big lookup table. I think memory layers are really good. And let me pause and say now this part of the talk is getting close to purely speculative. This is like the things that are like they exist and like someone's going to do this and someone's going to use like one of them but I really don't know what the right answer is.**

è¿˜æœ‰å¦ä¸€ç§æ–¹æ³•ï¼Œä¸æ˜¯æ·»åŠ å¦ä¸€ä¸ª MLPï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ªå«åšè®°å¿†å±‚çš„ä¸œè¥¿ï¼Œå®ƒåƒä¸€ä¸ªå¤§å‹æŸ¥æ‰¾è¡¨ã€‚æˆ‘è®¤ä¸ºè®°å¿†å±‚çœŸçš„å¾ˆå¥½ã€‚è®©æˆ‘æš‚åœä¸€ä¸‹è¯´ï¼Œç°åœ¨è¿™éƒ¨åˆ†æ¼”è®²å·²ç»æ¥è¿‘çº¯æ¨æµ‹äº†ã€‚è¿™äº›ä¸œè¥¿å­˜åœ¨ï¼Œæœ‰äººä¼šåšï¼Œæœ‰äººä¼šç”¨å…¶ä¸­ä¸€ä¸ªï¼Œä½†æˆ‘çœŸçš„ä¸çŸ¥é“æ­£ç¡®ç­”æ¡ˆæ˜¯ä»€ä¹ˆã€‚

è§£æï¼š
* **memory layer**ï¼šè®°å¿†å±‚
* **lookup table**ï¼šæŸ¥æ‰¾è¡¨
* **purely speculative**ï¼šçº¯æ¨æµ‹çš„
* **I really don't know what the right answer is**ï¼šæˆ‘çœŸçš„ä¸çŸ¥é“æ­£ç¡®ç­”æ¡ˆæ˜¯ä»€ä¹ˆï¼ˆè¯šå®æ‰¿è®¤ä¸ç¡®å®šæ€§ï¼‰

---

(58) [35:47-36:07] **Um another one is called LoRA. So Low Rank Adaptation. You probably heard of this very like hot topic. Um they kind of like train a small a small matrix or small few matrices to adapt the linear layers. So it's like if your model's 10 billion parameters, maybe you train 10 million parameters that can like control it.**

å¦ä¸€ä¸ªå« **LoRA**ï¼Œä½ç§©é€‚é…ã€‚ä½ å¯èƒ½å¬è¯´è¿‡è¿™ä¸ªéå¸¸çƒ­é—¨çš„è¯é¢˜ã€‚ä»–ä»¬è®­ç»ƒä¸€ä¸ªå°çŸ©é˜µæˆ–å‡ ä¸ªå°çŸ©é˜µæ¥é€‚é…çº¿æ€§å±‚ã€‚æ‰€ä»¥å¦‚æœä½ çš„æ¨¡å‹æœ‰ 100 äº¿å‚æ•°ï¼Œä½ å¯èƒ½åªè®­ç»ƒ 1000 ä¸‡å‚æ•°æ¥æ§åˆ¶å®ƒã€‚

è§£æï¼š
* **LoRA**ï¼šLow-Rank Adaptationï¼Œä½ç§©é€‚é…
* **hot topic**ï¼šçƒ­é—¨è¯é¢˜
* **linear layers**ï¼šçº¿æ€§å±‚
* **10 billion vs 10 million**ï¼š100 äº¿ vs 1000 ä¸‡ï¼ˆå‚æ•°é‡å·® 1000 å€ï¼‰

---

(59) [36:07-36:34] **Um, and if we look at them together, maybe it's not super obvious which thing would work best. Like ICL is just like putting stuff in context. So we have In-Context RAG full fine tuning. We could do the memory layers in MLP, Karpathy's which is a Prefix Tuning and we could do LoRA. We could also do add something to the Mixture of Experts. I think to me it's not like clear and I'm not positive that it matters which one we do.**

å¦‚æœæˆ‘ä»¬æŠŠå®ƒä»¬æ”¾åœ¨ä¸€èµ·çœ‹ï¼Œå¯èƒ½ä¸å¤ªæ˜æ˜¾å“ªä¸ªæ•ˆæœæœ€å¥½ã€‚**ICL** å°±æ˜¯æŠŠä¸œè¥¿æ”¾è¿›ä¸Šä¸‹æ–‡ã€‚æ‰€ä»¥æˆ‘ä»¬æœ‰ä¸Šä¸‹æ–‡å†…å­¦ä¹ ã€**RAG**ã€å…¨é‡å¾®è°ƒã€‚æˆ‘ä»¬å¯ä»¥åš MLP ä¸­çš„è®°å¿†å±‚ã€**Karpathy** çš„æ–¹æ³•ï¼ˆå‰ç¼€è°ƒä¼˜ï¼‰ã€è¿˜æœ‰ **LoRA**ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨æ··åˆä¸“å®¶æ¨¡å‹ä¸Šæ·»åŠ ä¸œè¥¿ã€‚å¯¹æˆ‘æ¥è¯´è¿™ä¸å¤ªæ¸…æ¥šï¼Œæˆ‘ä¸ç¡®å®šç”¨å“ªä¸ªçœŸçš„é‡è¦ã€‚

è§£æï¼š
* **ICL**ï¼šIn-Context Learningï¼Œä¸Šä¸‹æ–‡å†…å­¦ä¹ 
* **full fine tuning**ï¼šå…¨é‡å¾®è°ƒ
* **I'm not positive that**ï¼šæˆ‘ä¸ç¡®å®šâ€¦â€¦

---

(60) [36:34-36:51] **Like I think the main thing is like we have this giant model and we're adding a tiny bit to it to control it and training only those parameters. That way we retain most of the information in the model. I think that's like the most important part.**

æˆ‘è®¤ä¸ºä¸»è¦çš„æ˜¯ï¼šæˆ‘ä»¬æœ‰è¿™ä¸ªå·¨å¤§çš„æ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨ä¸Šé¢æ·»åŠ ä¸€å°éƒ¨åˆ†æ¥æ§åˆ¶å®ƒï¼Œåªè®­ç»ƒé‚£äº›å‚æ•°ã€‚è¿™æ ·æˆ‘ä»¬ä¿ç•™äº†æ¨¡å‹ä¸­çš„å¤§éƒ¨åˆ†ä¿¡æ¯ã€‚æˆ‘è®¤ä¸ºè¿™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ã€‚

è§£æï¼š
* **a tiny bit**ï¼šä¸€å°éƒ¨åˆ†
* **retain most of the information**ï¼šä¿ç•™å¤§éƒ¨åˆ†ä¿¡æ¯

---

(61) [36:51-37:03] **But I think for the end of this talk I'll just talk through like what I think people are doing in this space up to like the minute and then you can make up your own mind what you think the right way to do it is. So let's talk for a second about what properties we want.**

ä½†æˆ‘æƒ³åœ¨æ¼”è®²ç»“å°¾ï¼Œæˆ‘ä¼šè®²è®²æˆ‘è®¤ä¸ºè¿™ä¸ªé¢†åŸŸçš„äººä»¬æ­£åœ¨åšä»€ä¹ˆï¼Œä¸€ç›´åˆ°æœ€æ–°çš„è¿›å±•ï¼Œç„¶åä½ å¯ä»¥è‡ªå·±å†³å®šä½ è®¤ä¸ºæ­£ç¡®çš„åšæ³•æ˜¯ä»€ä¹ˆã€‚è®©æˆ‘ä»¬å…ˆè°ˆè°ˆæˆ‘ä»¬æƒ³è¦ä»€ä¹ˆå±æ€§ã€‚

è§£æï¼š
* **up to the minute**ï¼šæœ€æ–°çš„ã€åˆ°ç›®å‰ä¸ºæ­¢
* **make up your own mind**ï¼šè‡ªå·±åšå†³å®š

---

(62) [37:03-37:21] **I think we want um we want our changes to the model to be very small. Like say you're serving a model to each person. You actually can do it, but you have to use one of these like parameter efficient methods. If you're trying to fine-tune a new Qwen for each person, Qwen's like a terabyte. It's a trillion parameters. It's just like not even storable, let alone servable.**

æˆ‘è®¤ä¸ºæˆ‘ä»¬å¸Œæœ›å¯¹æ¨¡å‹çš„æ›´æ”¹éå¸¸å°ã€‚æ¯”å¦‚ä½ è¦ç»™æ¯ä¸ªäººæä¾›ä¸€ä¸ªæ¨¡å‹ã€‚ä½ ç¡®å®å¯ä»¥åšåˆ°ï¼Œä½†å¿…é¡»ä½¿ç”¨è¿™äº›å‚æ•°é«˜æ•ˆçš„æ–¹æ³•ä¹‹ä¸€ã€‚å¦‚æœä½ æƒ³ä¸ºæ¯ä¸ªäººå¾®è°ƒä¸€ä¸ªæ–°çš„ **Qwen**ï¼Œ**Qwen** æœ‰å¤§çº¦ 1TBï¼Œæ˜¯ä¸‡äº¿å‚æ•°çº§åˆ«çš„ã€‚æ ¹æœ¬æ— æ³•å­˜å‚¨ï¼Œæ›´åˆ«è¯´æä¾›æœåŠ¡äº†ã€‚

è§£æï¼š
* **parameter efficient methods**ï¼šå‚æ•°é«˜æ•ˆæ–¹æ³•
* **Qwen**ï¼šé€šä¹‰åƒé—®æ¨¡å‹
* **a terabyte / trillion parameters**ï¼š1TB / ä¸‡äº¿å‚æ•°
* **let alone**ï¼šæ›´åˆ«è¯´ï¼ˆé€’è¿›å¦å®šï¼‰

---

(63) [37:21-37:38] **Um we want something that's resistant to forgetting like we said. So it would be nice to have an architectural change that's both small and makes the minimal impact on the model as it is now because the model as it is now works really well.**

æˆ‘ä»¬æƒ³è¦ä¸€äº›æŠ—é—å¿˜çš„ä¸œè¥¿ï¼Œå°±åƒæˆ‘ä»¬è¯´çš„ã€‚æ‰€ä»¥æœ€å¥½æœ‰ä¸€ä¸ªæ¶æ„ä¸Šçš„æ”¹å˜ï¼Œæ—¢å°åˆå¯¹ç°æœ‰æ¨¡å‹çš„å½±å“æœ€å°ï¼Œå› ä¸ºç°æœ‰æ¨¡å‹æ•ˆæœçœŸçš„å¾ˆå¥½ã€‚

è§£æï¼š
* **resistant to forgetting**ï¼šæŠ—é—å¿˜çš„
* **minimal impact**ï¼šæœ€å°å½±å“
* **as it is now**ï¼šç°æœ‰çš„ã€ç›®å‰çš„çŠ¶æ€

---

(64) [37:38-37:55] **Um and preferably high capacity I think like changes that are really expressive and can capture a lot of facts and few parameters are the ones that we prefer and we want to be able to do inference quickly. As like a small aside, you actually can do this quickly with a lot of um a lot of these methods.**

æœ€å¥½æ˜¯é«˜å®¹é‡çš„ã€‚æˆ‘è®¤ä¸ºé‚£äº›çœŸæ­£æœ‰è¡¨è¾¾èƒ½åŠ›çš„ã€èƒ½ç”¨å°‘é‡å‚æ•°æ•è·å¤§é‡äº‹å®çš„æ”¹å˜æ˜¯æˆ‘ä»¬æ›´å–œæ¬¢çš„ï¼Œè€Œä¸”æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿå¿«é€Ÿæ¨ç†ã€‚é¡ºä¾¿è¯´ä¸€å¥ï¼Œä½ å®é™…ä¸Šå¯ä»¥ç”¨å¾ˆå¤šè¿™äº›æ–¹æ³•å¿«é€Ÿåšåˆ°è¿™ä¸€ç‚¹ã€‚

è§£æï¼š
* **high capacity**ï¼šé«˜å®¹é‡
* **expressive**ï¼šæœ‰è¡¨è¾¾èƒ½åŠ›çš„
* **as a small aside**ï¼šé¡ºä¾¿è¯´ä¸€å¥

---

(65) [37:55-38:09] **Like maybe some of you have seen Tinker, this new training API from Thinking Machines. It's basically all predicated on this idea that you can you can serve one model per person as long as you do LoRA and batch the LoRAs.**

ä¹Ÿè®¸ä½ ä»¬æœ‰äº›äººè§è¿‡ **Tinker**ï¼Œè¿™æ˜¯ **Thinking Machines** çš„æ–°è®­ç»ƒ APIã€‚å®ƒåŸºæœ¬ä¸Šå»ºç«‹åœ¨è¿™ä¸ªæƒ³æ³•ä¸Šï¼šåªè¦ä½ ä½¿ç”¨ **LoRA** å¹¶æ‰¹é‡å¤„ç† **LoRA**ï¼Œä½ å°±å¯ä»¥ä¸ºæ¯ä¸ªäººæä¾›ä¸€ä¸ªæ¨¡å‹ã€‚

è§£æï¼š
* **Tinker**ï¼šThinking Machines çš„äº§å“
* **predicated on**ï¼šåŸºäºã€å»ºç«‹åœ¨â€¦â€¦ä¹‹ä¸Š
* **batch the LoRAs**ï¼šæ‰¹é‡å¤„ç† LoRA

---

(66) [38:09-38:27] **And there's like it's actually most interesting from systems perspective. There's like ways you can train it and train each one separately and there's ways you can do inference and it basically has no cost. Um which is really interesting just because like the base model doesn't change and we all share the same base model. So all the ideas I'm going to talk about are kind of like in the same direction as Tinker.**

ä»ç³»ç»Ÿè§’åº¦æ¥çœ‹è¿™å®é™…ä¸Šæ˜¯æœ€æœ‰è¶£çš„ã€‚æœ‰åŠæ³•å¯ä»¥è®­ç»ƒå®ƒã€åˆ†åˆ«è®­ç»ƒæ¯ä¸€ä¸ªï¼Œä¹Ÿæœ‰åŠæ³•å¯ä»¥åšæ¨ç†ï¼Œè€Œä¸”åŸºæœ¬ä¸Šæ²¡æœ‰æˆæœ¬ã€‚è¿™çœŸçš„å¾ˆæœ‰è¶£ï¼Œå› ä¸ºåŸºç¡€æ¨¡å‹ä¸å˜ï¼Œæˆ‘ä»¬éƒ½å…±äº«åŒä¸€ä¸ªåŸºç¡€æ¨¡å‹ã€‚æ‰€ä»¥æˆ‘è¦è®²çš„æ‰€æœ‰æƒ³æ³•éƒ½å’Œ **Tinker** çš„æ–¹å‘ç±»ä¼¼ã€‚

è§£æï¼š
* **from systems perspective**ï¼šä»ç³»ç»Ÿè§’åº¦
* **basically has no cost**ï¼šåŸºæœ¬ä¸Šæ²¡æœ‰æˆæœ¬
* **base model**ï¼šåŸºç¡€æ¨¡å‹

---

(67) [38:27-38:50] **Um we can think about like whether certain methods might learn more or forget more. Um so this is comparing LoRA to full fine-tuning. So LoRA makes a tiny change to the model. Full fine-tuning updates the entire model. And on two different settings, they show like LoRA here is like purplish or pink. The pink one's a little bit smaller capacity. Um, it basically doesn't do as well.**

æˆ‘ä»¬å¯ä»¥æ€è€ƒæŸäº›æ–¹æ³•æ˜¯å¦ä¼šå­¦å¾—æ›´å¤šæˆ–å¿˜å¾—æ›´å¤šã€‚è¿™æ˜¯æ¯”è¾ƒ **LoRA** å’Œå…¨é‡å¾®è°ƒã€‚**LoRA** å¯¹æ¨¡å‹åšå¾®å°æ”¹å˜ï¼Œå…¨é‡å¾®è°ƒæ›´æ–°æ•´ä¸ªæ¨¡å‹ã€‚åœ¨ä¸¤ç§ä¸åŒè®¾ç½®ä¸‹ï¼Œä»–ä»¬å±•ç¤ºçš„ **LoRA** æ˜¯ç´«è‰²æˆ–ç²‰è‰²çš„ã€‚ç²‰è‰²é‚£ä¸ªå®¹é‡ç¨å°ï¼ŒåŸºæœ¬ä¸Šæ•ˆæœä¸é‚£ä¹ˆå¥½ã€‚

è§£æï¼š
* **learn more or forget more**ï¼šå­¦å¾—æ›´å¤šæˆ–å¿˜å¾—æ›´å¤š
* **smaller capacity**ï¼šå®¹é‡æ›´å°

---

(68) [38:50-39:10] **At least when you're doing SFT, uh, LoRA can learn a little bit less, but also if we look at how much it's degrading, it forgets less. So this paper is called "Learns Less and Forgets Less". And it's actually a very nice finding.**

è‡³å°‘åœ¨åš **SFT** æ—¶ï¼Œ**LoRA** å­¦å¾—å°‘ä¸€ç‚¹ï¼Œä½†å¦‚æœæˆ‘ä»¬çœ‹å®ƒé€€åŒ–äº†å¤šå°‘ï¼Œå®ƒä¹Ÿå¿˜å¾—æ›´å°‘ã€‚æ‰€ä»¥è¿™ç¯‡è®ºæ–‡å«åš **"Learns Less and Forgets Less"**ï¼ˆå­¦å¾—å°‘ï¼Œå¿˜å¾—ä¹Ÿå°‘ï¼‰ã€‚è¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å‘ç°ã€‚

è§£æï¼š
* **degrading**ï¼šé€€åŒ–ã€æ€§èƒ½ä¸‹é™
* **"Learns Less and Forgets Less"**ï¼šè®ºæ–‡å
* **a very nice finding**ï¼šä¸€ä¸ªå¾ˆå¥½çš„å‘ç°

---

(69) [39:10-39:24] **So like if you want to at least teach a model via SFT and you use one of these low rank or parameter efficient methods like all the ones I described, they're going to make a small change to the model in a way that it's probably not going to be as expressive as full fine tuning, but it also doesn't destroy a lot of the knowledge.**

æ‰€ä»¥å¦‚æœä½ æƒ³é€šè¿‡ **SFT** æ•™ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶ä¸”ä½¿ç”¨è¿™äº›ä½ç§©æˆ–å‚æ•°é«˜æ•ˆæ–¹æ³•ä¸­çš„ä¸€ç§ï¼Œå°±åƒæˆ‘æè¿°çš„é‚£äº›ï¼Œå®ƒä»¬ä¼šå¯¹æ¨¡å‹åšå°çš„æ”¹å˜ï¼Œå¯èƒ½ä¸ä¼šåƒå…¨é‡å¾®è°ƒé‚£æ ·æœ‰è¡¨è¾¾åŠ›ï¼Œä½†ä¹Ÿä¸ä¼šç ´åå¤ªå¤šçŸ¥è¯†ã€‚

è§£æï¼š
* **low rank methods**ï¼šä½ç§©æ–¹æ³•
* **parameter efficient methods**ï¼šå‚æ•°é«˜æ•ˆæ–¹æ³•
* **destroy a lot of the knowledge**ï¼šç ´åå¤§é‡çŸ¥è¯†

---

(70) [39:24-39:47] **Um here's something going the exact opposite direction. This is the results from Thinking Machines showing that they think LoRA is about as good as full fine tuning, which is interesting because they're doing RL. So it's like maybe dependent on the training mechanism like if you do RL maybe it makes small updates and um you can do LoRA you can do memory layers but for SFT it really has to store a lot of information so you really have to do full fine tuning.**

è¿™æ˜¯å®Œå…¨ç›¸åæ–¹å‘çš„ç»“æœã€‚è¿™æ˜¯ **Thinking Machines** çš„ç»“æœï¼Œæ˜¾ç¤ºä»–ä»¬è®¤ä¸º **LoRA** å’Œå…¨é‡å¾®è°ƒå·®ä¸å¤šå¥½ï¼Œè¿™å¾ˆæœ‰è¶£ï¼Œå› ä¸ºä»–ä»¬åœ¨åš **RL**ã€‚æ‰€ä»¥å¯èƒ½å–å†³äºè®­ç»ƒæœºåˆ¶ï¼šå¦‚æœä½ åš **RL**ï¼Œå¯èƒ½æ›´æ–°å¾ˆå°ï¼Œä½ å¯ä»¥ç”¨ **LoRA** æˆ–è®°å¿†å±‚ï¼›ä½†å¯¹äº **SFT**ï¼Œå®ƒçœŸçš„éœ€è¦å­˜å‚¨å¤§é‡ä¿¡æ¯ï¼Œæ‰€ä»¥ä½ çœŸçš„éœ€è¦åšå…¨é‡å¾®è°ƒã€‚

è§£æï¼š
* **the exact opposite direction**ï¼šå®Œå…¨ç›¸åçš„æ–¹å‘
* **dependent on the training mechanism**ï¼šå–å†³äºè®­ç»ƒæœºåˆ¶
* **RL vs SFT**ï¼šå¼ºåŒ–å­¦ä¹  vs æœ‰ç›‘ç£å¾®è°ƒçš„ä¸åŒéœ€æ±‚

---

(71) [39:47-40:06] **I think that's the takeaway I have and I have some actually a paper that's like kind of blocked for legal reasons but coming out soon. Um here's one result from my paper that's relevant to this. So we have this like Tiny LoRA thing that's even smaller than LoRA.**

æˆ‘è®¤ä¸ºè¿™æ˜¯æˆ‘çš„æ”¶è·ã€‚æˆ‘å®é™…ä¸Šæœ‰ä¸€ç¯‡è®ºæ–‡å› ä¸ºæ³•å¾‹åŸå› è¢«é˜»æ­¢äº†ï¼Œä½†å¾ˆå¿«ä¼šå‘è¡¨ã€‚è¿™æ˜¯æˆ‘è®ºæ–‡ä¸­ä¸æ­¤ç›¸å…³çš„ä¸€ä¸ªç»“æœã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªæ¯” **LoRA** æ›´å°çš„ **Tiny LoRA**ã€‚

è§£æï¼š
* **blocked for legal reasons**ï¼šå› æ³•å¾‹åŸå› è¢«é˜»æ­¢
* **coming out soon**ï¼šå³å°†å‘è¡¨
* **Tiny LoRA**ï¼šæ›´å°çš„ LoRA å˜ä½“

---

(72) [40:06-40:20] **Well there's actually LoRA XS which already exists and then we made Tiny LoRA which is even smaller. And if you're doing RL on GSM8K math reasoning you can train 14 parameters and get like 91% accuracy which is pretty crazy.**

å®é™…ä¸Šå·²ç»æœ‰ **LoRA XS** äº†ï¼Œç„¶åæˆ‘ä»¬åšäº† **Tiny LoRA**ï¼Œæ›´å°ã€‚å¦‚æœä½ åœ¨ **GSM8K** æ•°å­¦æ¨ç†ä¸Šåš **RL**ï¼Œä½ å¯ä»¥åªè®­ç»ƒ 14 ä¸ªå‚æ•°å°±è¾¾åˆ°å¤§çº¦ 91% çš„å‡†ç¡®ç‡ï¼Œè¿™ç›¸å½“ç–¯ç‹‚ã€‚

è§£æï¼š
* **LoRA XS**ï¼šè¶…å°å‹ LoRA
* **GSM8K**ï¼šä¸€ä¸ªæ•°å­¦æ¨ç†åŸºå‡†æµ‹è¯•æ•°æ®é›†
* **14 parameters**ï¼šåªæœ‰ 14 ä¸ªå‚æ•°ï¼ˆæç«¯å‚æ•°é«˜æ•ˆï¼‰
* **91% accuracy**ï¼š91% å‡†ç¡®ç‡

---

## ç¬¬äºŒéƒ¨åˆ†å°ç»“

### æ ¸å¿ƒè§‚ç‚¹

8. **åˆæˆæ•°æ®çš„çªç ´**ï¼šç”¨ LLM ç”Ÿæˆå¤§é‡åˆæˆæ•°æ®æ¥æ‰©å……å°æ•°æ®é›†ï¼Œè¿™æ‰“ç ´äº†ä¼ ç»Ÿ"æ•°æ®ä¸å¤Ÿå°±è¿‡æ‹Ÿåˆ"çš„èŒƒå¼

9. **ç›¸å…³å·¥ä½œ**ï¼š
   - **Synthetic Continued Pre-training**ï¼ˆStanfordï¼‰
   - **Active Reading**
   - **Self-Study**ï¼ˆKarpathyï¼‰
   - **Rephrasing the Web**
   - **SEAL**ï¼ˆè‡ªé€‚åº”è¯­è¨€æ¨¡å‹ï¼‰

10. **ç¾éš¾æ€§é—å¿˜**ï¼šç¥ç»ç½‘ç»œå­¦æ–°çŸ¥è¯†æ—¶å¿˜æ‰æ—§çŸ¥è¯†çš„ç»å…¸é—®é¢˜ï¼Œéå¸¸éš¾è§£å†³

11. **å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•**ï¼š
    - **Full fine-tuning**ï¼šæ›´æ–°æ‰€æœ‰å‚æ•°ï¼ˆå®¹æ˜“é—å¿˜ï¼‰
    - **Prefix Tuning**ï¼šåªè®­ç»ƒ KV ç¼“å­˜
    - **Memory Layers**ï¼šå¤§å‹æŸ¥æ‰¾è¡¨
    - **MoE æ‰©å±•**ï¼šåœ¨æ··åˆä¸“å®¶æ¨¡å‹ä¸Šæ·»åŠ ä¸“å®¶
    - **LoRA**ï¼šä½ç§©é€‚é…ï¼Œåªè®­ç»ƒå°çŸ©é˜µ

12. **LoRA çš„æƒè¡¡**ï¼š"å­¦å¾—å°‘ï¼Œå¿˜å¾—ä¹Ÿå°‘"â€”â€”è¡¨è¾¾èƒ½åŠ›è¾ƒå¼±ä½†ä¿ç•™æ›´å¤šåŸæœ‰çŸ¥è¯†

13. **RL vs SFT**ï¼šå¼ºåŒ–å­¦ä¹ å¯èƒ½æ›´é€‚åˆå‚æ•°é«˜æ•ˆæ–¹æ³•ï¼ŒSFT å¯èƒ½éœ€è¦å…¨é‡å¾®è°ƒ

14. **æç«¯æ•ˆç‡**ï¼šTiny LoRA åªç”¨ 14 ä¸ªå‚æ•°å°±èƒ½åœ¨ GSM8K ä¸Šè¾¾åˆ° 91% å‡†ç¡®ç‡

### æ–°å¢è¯æ±‡è¡¨

| è¯æ±‡ | è¯æ€§ | å«ä¹‰ |
|------|------|------|
| **synthetic data** | n. | åˆæˆæ•°æ® |
| **bricking** | v. | æŠŠâ€¦â€¦æå |
| **overfit** | v. | è¿‡æ‹Ÿåˆ |
| **catastrophic forgetting** | n. | ç¾éš¾æ€§é—å¿˜ |
| **LoRA** | n. | ä½ç§©é€‚é… |
| **Prefix Tuning** | n. | å‰ç¼€è°ƒä¼˜ |
| **memory layer** | n. | è®°å¿†å±‚ |
| **Mixture of Experts (MoE)** | n. | æ··åˆä¸“å®¶æ¨¡å‹ |
| **parameter efficient** | adj. | å‚æ•°é«˜æ•ˆçš„ |
| **intelligence explosion** | n. | æ™ºèƒ½çˆ†ç‚¸ |
| **speculative** | adj. | æ¨æµ‹æ€§çš„ |
| **the money question** | n. | æ ¸å¿ƒé—®é¢˜ |
| **outperform** | v. | è¶…è¿‡ã€è¡¨ç°ä¼˜äº |
| **expressive** | adj. | æœ‰è¡¨è¾¾åŠ›çš„ |

### æ–°å¢å£è¯­è¡¨è¾¾

| è¡¨è¾¾ | å«ä¹‰ |
|------|------|
| fancy | å·§å¦™çš„ï¼ˆæŠ€æœ¯è¯­å¢ƒï¼‰ |
| the takeaway | è¦ç‚¹ã€æ”¶è· |
| as a small aside | é¡ºä¾¿è¯´ä¸€å¥ |
| let alone | æ›´åˆ«è¯´ |
| up to the minute | æœ€æ–°çš„ |
| make up your own mind | è‡ªå·±åšå†³å®š |
| predicated on | åŸºäº |

---

# ç¬¬ä¸‰éƒ¨åˆ†ï¼šQ&A ç¯èŠ‚ä¸æ€»ç»“

> æ—¶é—´ï¼š40:20 - 1:02:26

---

(73) [40:20-40:26] **I think um there's like a lot of reasons for this. Like RL makes really tiny changes.**

æˆ‘è®¤ä¸ºè¿™æœ‰å¾ˆå¤šåŸå› ã€‚**RL** åšçš„æ›´æ–°éå¸¸å¾®å°ã€‚

---

(74) [40:26-40:38] **I think this Qwen model like is something fishy is going on with the training data. You have a one parameter experiment. Oh yeah, one parameter. It actually learns it gets 5% better with one parameter.**

æˆ‘è§‰å¾—è¿™ä¸ª **Qwen** æ¨¡å‹çš„è®­ç»ƒæ•°æ®å¯èƒ½æœ‰äº›è¹Šè··ã€‚ä½ æœ‰ä¸€ä¸ªå•å‚æ•°å®éªŒã€‚å“¦å¯¹ï¼Œä¸€ä¸ªå‚æ•°ã€‚å®ƒç¡®å®èƒ½å­¦ä¹ ï¼Œç”¨ä¸€ä¸ªå‚æ•°èƒ½æå‡ 5%ã€‚

è§£æï¼š
* **fishy**ï¼šå¯ç–‘çš„ã€è¹Šè··çš„ï¼ˆå£è¯­è¡¨è¾¾ï¼‰
* **one parameter experiment**ï¼šå•å‚æ•°å®éªŒ

---

(75) [40:38-40:56] **Pretty cool. It's amazing. Yeah. Yeah. It's it's it's really nice. I think um literally the smallest. Yeah. Yeah. The smallest thing you could possibly train. It's more like you you generate a lot of random projections and then you control them all with one number if that makes sense.**

å¤ªé…·äº†ã€‚å¾ˆæƒŠäººã€‚æ˜¯å•Šã€‚è¿™çœŸçš„å¾ˆæ£’ã€‚æˆ‘è®¤ä¸ºè¿™æ˜¯å­—é¢æ„ä¹‰ä¸Šæœ€å°çš„ã€‚å¯¹ï¼Œä½ èƒ½è®­ç»ƒçš„æœ€å°çš„ä¸œè¥¿ã€‚æ›´åƒæ˜¯ä½ ç”Ÿæˆå¾ˆå¤šéšæœºæŠ•å½±ï¼Œç„¶åç”¨ä¸€ä¸ªæ•°å­—æ§åˆ¶å®ƒä»¬æ‰€æœ‰ï¼Œå¦‚æœä½ èƒ½ç†è§£çš„è¯ã€‚

è§£æï¼š
* **random projections**ï¼šéšæœºæŠ•å½±ï¼ˆæ•°å­¦/ML æ¦‚å¿µï¼‰
* **if that makes sense**ï¼šå¦‚æœä½ èƒ½ç†è§£çš„è¯

---

(76) [40:56-41:08] **Like the model actually changes a lot but the only thing you can actually train and store is the one parameter. Uh I tell you more about it later. Um but yeah, it's pretty cool.**

æ¨¡å‹å®é™…ä¸Šå˜åŒ–å¾ˆå¤§ï¼Œä½†ä½ çœŸæ­£èƒ½è®­ç»ƒå’Œå­˜å‚¨çš„åªæœ‰é‚£ä¸€ä¸ªå‚æ•°ã€‚æˆ‘ç¨åä¼šè¯¦ç»†å‘Šè¯‰ä½ ã€‚ä½†æ˜¯ï¼Œè¿™çœŸçš„å¾ˆé…·ã€‚

---

(77) [41:08-41:26] **Um this is another result that's like kind of in the mix, but I'm not sure how to place it. So if you do the KV cache tuning or prefix tuning, this paper thinks prefix tuning works much better than LoRA. I met some people in Meta um when I used to be affiliated there that said that they think LoRA works much better than prefix tuning.**

è¿™æ˜¯å¦ä¸€ä¸ªæœ‰ç‚¹æ··æ‚çš„ç»“æœï¼Œæˆ‘ä¸å¤ªç¡®å®šæ€ä¹ˆå®šä½å®ƒã€‚å¦‚æœä½ åš KV ç¼“å­˜è°ƒä¼˜æˆ–å‰ç¼€è°ƒä¼˜ï¼Œè¿™ç¯‡è®ºæ–‡è®¤ä¸º **Prefix Tuning** æ¯” **LoRA** å¥½å¾ˆå¤šã€‚æˆ‘åœ¨ **Meta** è®¤è¯†ä¸€äº›äººï¼Œæˆ‘ä»¥å‰åœ¨é‚£é‡Œå·¥ä½œè¿‡ï¼Œä»–ä»¬è¯´ä»–ä»¬è®¤ä¸º **LoRA** æ¯” **Prefix Tuning** å¥½å¾ˆå¤šã€‚

è§£æï¼š
* **in the mix**ï¼šåœ¨æ··æ‚ä¸­ã€ä¸ç¡®å®šçš„ä½ç½®
* **affiliated**ï¼šéš¶å±äºã€å…³è”

---

(78) [41:26-41:42] **So I really don't know, but I think like what it really will come down to is like when you do it at scale, what's like most efficient? And I'm not exactly sure, but I think prefix tuning is a pretty good candidate because like KV caches are so commonly used these days.**

æ‰€ä»¥æˆ‘çœŸçš„ä¸çŸ¥é“ï¼Œä½†æˆ‘è®¤ä¸ºæœ€ç»ˆä¼šå½’ç»“ä¸ºï¼šå½“ä½ åœ¨è§„æ¨¡ä¸Šåšè¿™ä»¶äº‹æ—¶ï¼Œä»€ä¹ˆæœ€é«˜æ•ˆï¼Ÿæˆ‘ä¸å¤ªç¡®å®šï¼Œä½†æˆ‘è®¤ä¸º **Prefix Tuning** æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å€™é€‰ï¼Œå› ä¸º KV ç¼“å­˜ç°åœ¨éå¸¸å¸¸ç”¨ã€‚

è§£æï¼š
* **come down to**ï¼šå½’ç»“ä¸º

---

(79) [41:42-42:06] **I think a cool thing about Thinking Machines is like they're designing this entire organization around like scaling LoRA which is awesome but it's not really possible in open source right now. Like there's not kernels for training many LoRAs at the same time. It's like very complex and you have to have a lot of people working on that. Prefix tuning on the other hand is like very well supported.**

æˆ‘è®¤ä¸º **Thinking Machines** å¾ˆé…·çš„ä¸€ç‚¹æ˜¯ä»–ä»¬æ•´ä¸ªç»„ç»‡éƒ½å›´ç»•ç€æ‰©å±• **LoRA** æ¥è®¾è®¡ï¼Œè¿™å¾ˆæ£’ï¼Œä½†åœ¨å¼€æºé¢†åŸŸç›®å‰è¿˜ä¸å¤ªå¯èƒ½ã€‚æ¯”å¦‚æ²¡æœ‰åŒæ—¶è®­ç»ƒå¤šä¸ª **LoRA** çš„å†…æ ¸ã€‚è¿™éå¸¸å¤æ‚ã€‚å¦ä¸€æ–¹é¢ï¼Œ**Prefix Tuning** å¾—åˆ°äº†å¾ˆå¥½çš„æ”¯æŒã€‚

è§£æï¼š
* **kernels**ï¼šå†…æ ¸

---

(80) [42:06-42:28] **Um and then finally I'll quickly talk about memory layers. This is another approach to injecting data into models which I think is good. This is like uh adding an expert to the MLP but the expert is just like this giant differentiable lookup table.**

æœ€åæˆ‘ä¼šå¿«é€Ÿè®²ä¸€ä¸‹è®°å¿†å±‚ã€‚è¿™æ˜¯å¦ä¸€ç§å°†æ•°æ®æ³¨å…¥æ¨¡å‹çš„æ–¹æ³•ï¼Œæˆ‘è®¤ä¸ºå¾ˆå¥½ã€‚è¿™å°±åƒåœ¨ MLP ä¸Šæ·»åŠ ä¸€ä¸ªä¸“å®¶ï¼Œä½†è¿™ä¸ªä¸“å®¶åªæ˜¯ä¸€ä¸ªå·¨å¤§çš„å¯å¾®åˆ†æŸ¥æ‰¾è¡¨ã€‚

è§£æï¼š
* **differentiable lookup table**ï¼šå¯å¾®åˆ†æŸ¥æ‰¾è¡¨

---

(81) [42:28-42:46] **So it's kind of not that important exactly how it works but it's like it's just a different way to inject information into models. The cool thing about memory layers is it's controllable. So in this work uh by Jesse Lynn from this year, they specify exactly which parts of the memory layer get updated and keep it to like a very small number.**

å…·ä½“æ€ä¹ˆå·¥ä½œä¸æ˜¯é‚£ä¹ˆé‡è¦ï¼Œå®ƒåªæ˜¯å¦ä¸€ç§å°†ä¿¡æ¯æ³¨å…¥æ¨¡å‹çš„æ–¹å¼ã€‚è®°å¿†å±‚å¾ˆé…·çš„ä¸€ç‚¹æ˜¯å®ƒæ˜¯å¯æ§çš„ã€‚åœ¨ **Jesse Lynn** ä»Šå¹´çš„è¿™é¡¹å·¥ä½œä¸­ï¼Œä»–ä»¬ç²¾ç¡®æŒ‡å®šè®°å¿†å±‚çš„å“ªäº›éƒ¨åˆ†è¢«æ›´æ–°ï¼Œå¹¶å°†å…¶ä¿æŒåœ¨éå¸¸å°çš„æ•°é‡ã€‚

---

(82) [42:46-43:02] **And so their result shows that memory layers actually work the best. So memory the axes here are forgetting so down is bad and learning right is good. So the memory layers basically don't forget at all and they learn close to as much.**

ä»–ä»¬çš„ç»“æœæ˜¾ç¤ºè®°å¿†å±‚å®é™…ä¸Šæ•ˆæœæœ€å¥½ã€‚è¿™é‡Œçš„åæ ‡è½´æ˜¯é—å¿˜ï¼ˆå‘ä¸‹æ˜¯åçš„ï¼‰å’Œå­¦ä¹ ï¼ˆå‘å³æ˜¯å¥½çš„ï¼‰ã€‚è®°å¿†å±‚åŸºæœ¬ä¸Šå®Œå…¨ä¸é—å¿˜ï¼Œè€Œä¸”å­¦ä¹ èƒ½åŠ›ä¹Ÿå·®ä¸å¤šã€‚

---

(83) [43:02-43:21] **So I think if you're trying to inject information into models that you really care about them not forgetting any of their base information, maybe memory layers are the way to go. I think honestly there's a lot of conflicting evidence right now. Like some people think LoRA is good, some people think prefix tuning is good. These people think memory layers is good. I really am not sure, but I think it's going to be one of them.**

æ‰€ä»¥æˆ‘è®¤ä¸ºå¦‚æœä½ æƒ³æŠŠä¿¡æ¯æ³¨å…¥æ¨¡å‹ï¼Œè€Œä¸”ä½ çœŸçš„å¾ˆåœ¨æ„æ¨¡å‹ä¸è¦å¿˜è®°ä»»ä½•åŸºç¡€ä¿¡æ¯ï¼Œè®°å¿†å±‚å¯èƒ½æ˜¯æœ€å¥½çš„é€‰æ‹©ã€‚è€å®è¯´æˆ‘è®¤ä¸ºç°åœ¨æœ‰å¾ˆå¤šç›¸äº’çŸ›ç›¾çš„è¯æ®ã€‚æœ‰äººè®¤ä¸º **LoRA** å¥½ï¼Œæœ‰äººè®¤ä¸º **Prefix Tuning** å¥½ã€‚è¿™äº›äººè®¤ä¸ºè®°å¿†å±‚å¥½ã€‚æˆ‘çœŸçš„ä¸ç¡®å®šï¼Œä½†æˆ‘è®¤ä¸ºä¼šæ˜¯å…¶ä¸­ä¹‹ä¸€ã€‚

è§£æï¼š
* **the way to go**ï¼šæœ€å¥½çš„é€‰æ‹©
* **conflicting evidence**ï¼šç›¸äº’çŸ›ç›¾çš„è¯æ®

---

(84) [43:21-43:40] **Okay, cool. That's that's the end of the training stuff into weights part. Maybe actually I'll stop and see if anyone has any questions about the different parameterizations.**

å¥½çš„ï¼Œé…·ã€‚è¿™å°±æ˜¯å°†ä¸œè¥¿è®­ç»ƒè¿›æƒé‡éƒ¨åˆ†çš„ç»“å°¾ã€‚ä¹Ÿè®¸æˆ‘ç°åœ¨åœä¸‹æ¥ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰äººå¯¹ä¸åŒçš„å‚æ•°åŒ–æ–¹æ³•æœ‰é—®é¢˜ã€‚

---

## Q&Aï¼šRL vs SFT çš„å‚æ•°éœ€æ±‚

(85) [43:40-44:00] **Oh, yeah. Yeah. Yeah. From from my yet unreleased research. So, have you used SFT before? Yeah. Yeah. I can show you the SFT results later. But SFT uh takes a lot more parameters in the short explanation like many many more like a thousand x or something.**

å“¦ï¼Œå¯¹ã€‚æ¥è‡ªæˆ‘å°šæœªå‘è¡¨çš„ç ”ç©¶ã€‚ä½ ç”¨è¿‡ **SFT** å—ï¼Ÿæ˜¯çš„ã€‚æˆ‘å¯ä»¥ç¨åç»™ä½ çœ‹ **SFT** çš„ç»“æœã€‚ä½†ç®€å•æ¥è¯´ï¼Œ**SFT** éœ€è¦å¤šå¾—å¤šçš„å‚æ•°ï¼Œå¤šå¾ˆå¤šï¼Œå¤§æ¦‚ 1000 å€å·¦å³ã€‚

è§£æï¼š
* **a thousand x**ï¼š1000 å€

---

(86) [44:00-44:26] **And you attribute that to the sparsity of the reward. Yeah. Yeah. I think it's something like that. Like the SFT learning signal is like cross entropy on all of the tokens with or without thinking tokens. And that's a lot of bits essentially. And then RL just gives you a one or a zero. If you get it right and you already knew, then it's no information. If you get it wrong, you get like one bit.**

ä½ æŠŠè¿™å½’å› äºå¥–åŠ±çš„ç¨€ç–æ€§ã€‚æ˜¯çš„ã€‚**SFT** çš„å­¦ä¹ ä¿¡å·æ˜¯å¯¹æ‰€æœ‰ token çš„äº¤å‰ç†µï¼Œä¸ç®¡æœ‰æ²¡æœ‰æ€è€ƒ tokenã€‚è¿™åŸºæœ¬ä¸Šæ˜¯å¾ˆå¤šæ¯”ç‰¹çš„ä¿¡æ¯ã€‚è€Œ **RL** åªç»™ä½ ä¸€ä¸ª 1 æˆ– 0ã€‚å¦‚æœä½ ç­”å¯¹äº†è€Œä¸”ä½ æœ¬æ¥å°±çŸ¥é“ï¼Œé‚£å°±æ²¡æœ‰ä¿¡æ¯ã€‚å¦‚æœä½ ç­”é”™äº†ï¼Œä½ åªå¾—åˆ°å¤§çº¦ä¸€æ¯”ç‰¹çš„ä¿¡æ¯ã€‚

è§£æï¼š
* **sparsity of the reward**ï¼šå¥–åŠ±çš„ç¨€ç–æ€§
* **cross entropy**ï¼šäº¤å‰ç†µ

---

(87) [44:26-44:48] **So I think because RL is like so sparse and uh information efficient, then you can do it with way fewer parameters. That's that's kind of the takeaway from our paper actually. So you didn't do GRPO after doing SFT? No, no SFT. We just either do GRPO or SFT and then we see like kind of how many parameters you need to train to get to equivalent performance and SFT requires many more parameters.**

æ‰€ä»¥æˆ‘è®¤ä¸ºå› ä¸º **RL** éå¸¸ç¨€ç–ä¸”ä¿¡æ¯é«˜æ•ˆï¼Œæ‰€ä»¥ä½ å¯ä»¥ç”¨å°‘å¾—å¤šçš„å‚æ•°æ¥åšã€‚è¿™å…¶å®æ˜¯æˆ‘ä»¬è®ºæ–‡çš„è¦ç‚¹ã€‚æ‰€ä»¥ä½ æ²¡æœ‰åœ¨åšå®Œ **SFT** åå†åš **GRPO**ï¼Ÿä¸ï¼Œæ²¡æœ‰ **SFT**ã€‚æˆ‘ä»¬åªæ˜¯åš **GRPO** æˆ– **SFT** å…¶ä¸­ä¹‹ä¸€ï¼Œç„¶åçœ‹è¾¾åˆ°åŒç­‰æ€§èƒ½éœ€è¦è®­ç»ƒå¤šå°‘å‚æ•°ï¼Œ**SFT** éœ€è¦å¤šå¾—å¤šçš„å‚æ•°ã€‚

è§£æï¼š
* **GRPO**ï¼šGroup Relative Policy Optimization

---

## Q&Aï¼šRAG vs è®­ç»ƒçš„é€‰æ‹©

(88) [44:48-45:47] **Uh so here you are comparing like uh training versus RAG... So is the volume of the document also matter... because if some problem has a less number of document uh RAG will be better or the training will be better. That's a really good point... I think the question is like okay you're trying to train all of your data into a model but something only happens once... when I should pick focus on RAG and when I should focus on training... if I have like a small set of documents the training might not be feasible. Yes. Yes.**

ä½ æ˜¯åœ¨æ¯”è¾ƒè®­ç»ƒå’Œ **RAG**â€¦â€¦æ–‡æ¡£é‡æ˜¯å¦ä¹Ÿé‡è¦â€¦â€¦å¦‚æœé—®é¢˜çš„æ–‡æ¡£æ•°é‡è¾ƒå°‘ï¼Œ**RAG** ä¼šæ›´å¥½è¿˜æ˜¯è®­ç»ƒä¼šæ›´å¥½ï¼Ÿè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„è§‚ç‚¹ã€‚é—®é¢˜æ˜¯ä½ æƒ³æŠŠæ‰€æœ‰æ•°æ®è®­ç»ƒè¿›æ¨¡å‹ï¼Œä½†æœ‰äº›äº‹æƒ…åªå‘ç”Ÿä¸€æ¬¡â€¦â€¦ä»€ä¹ˆæ—¶å€™åº”è¯¥ä¸“æ³¨äº **RAG**ï¼Œä»€ä¹ˆæ—¶å€™ä¸“æ³¨äºè®­ç»ƒâ€¦â€¦å¦‚æœæˆ‘åªæœ‰ä¸€å°ç»„æ–‡æ¡£ï¼Œè®­ç»ƒå¯èƒ½ä¸å¯è¡Œã€‚æ˜¯çš„ã€‚

---

(89) [45:47-46:18] **Let me point out like okay, so obviously we're always going to put stuff into context and I think we'll also probably always do RAG. Like I think there's basically no scenario that you can imagine for a long time where you're just like always training the model and never doing RAG. I think you'll do both. I think like maybe if you have a ton of documents, maybe every day you do this big training and then every time you serve you also do RAG.**

è®©æˆ‘æŒ‡å‡ºï¼Œæ˜¾ç„¶æˆ‘ä»¬æ€»æ˜¯ä¼šæŠŠä¸œè¥¿æ”¾è¿›ä¸Šä¸‹æ–‡ï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬å¯èƒ½ä¹Ÿæ€»æ˜¯ä¼šåš **RAG**ã€‚åœ¨å¾ˆé•¿ä¸€æ®µæ—¶é—´å†…ï¼ŒåŸºæœ¬ä¸Šæ²¡æœ‰ä½ åªè®­ç»ƒæ¨¡å‹è€Œä»ä¸åš **RAG** çš„åœºæ™¯ã€‚æˆ‘è®¤ä¸ºä½ ä¼šä¸¤è€…éƒ½åšã€‚ä¹Ÿè®¸å¦‚æœä½ æœ‰å¤§é‡æ–‡æ¡£ï¼Œä¹Ÿè®¸æ¯å¤©ä½ åšä¸€æ¬¡å¤§è®­ç»ƒï¼Œç„¶åæ¯æ¬¡æœåŠ¡æ—¶ä½ ä¹Ÿåš **RAG**ã€‚

---

(90) [46:18-46:55] **And so like what I really imagine is like or maybe my point is that no one is doing this right now and like people will start doing that... I would definitely be interested to see both analysis on how the frequency of information affects like the trade-off and how just like how much data you have to have for training to become economically feasible. That's a really good question.**

æˆ‘çœŸæ­£æƒ³è±¡çš„æ˜¯â€”â€”æˆ–è€…æˆ‘çš„è§‚ç‚¹æ˜¯ç°åœ¨æ²¡æœ‰äººåœ¨åšè¿™ä¸ªï¼Œä½†äººä»¬ä¼šå¼€å§‹åšã€‚æˆ‘è‚¯å®šä¼šå¯¹ä¸¤ç§åˆ†ææ„Ÿå…´è¶£ï¼šä¿¡æ¯é¢‘ç‡å¦‚ä½•å½±å“æƒè¡¡ï¼Œä»¥åŠä½ éœ€è¦å¤šå°‘æ•°æ®è®­ç»ƒæ‰å˜å¾—ç»æµå¯è¡Œã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚

è§£æï¼š
* **economically feasible**ï¼šç»æµä¸Šå¯è¡Œçš„

---

## Q&Aï¼šå¾®è°ƒç”¨äºåµŒå…¥è¿˜æ˜¯è¡¥å…¨

(91) [46:55-47:44] **Is your suggestion kind of in diving more into like the weights side to use a fine-tuned model for like completion type tasks or also for embeddings? Oh yeah, that's a good question. No, I think the fine-tuning I'm talking about is all for like assistant engine completion. It's an interesting question. You probably could do like dynamic embedding model training, but I guess like the way I think about it is like the real like 10x improvement here is going to come from training to weights. You could maybe make RAG like 2x better if you really really worked, but I think there's so many fundamental problems with it that I wouldn't spend that much time on making it better.**

ä½ çš„å»ºè®®æ˜¯æ·±å…¥ç ”ç©¶æƒé‡è¿™è¾¹ï¼Œç”¨å¾®è°ƒæ¨¡å‹åšè¡¥å…¨ç±»å‹çš„ä»»åŠ¡ï¼Œè¿˜æ˜¯ä¹ŸåšåµŒå…¥ï¼Ÿå“¦ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ã€‚ä¸ï¼Œæˆ‘è®¤ä¸ºæˆ‘è¯´çš„å¾®è°ƒéƒ½æ˜¯é’ˆå¯¹åŠ©æ‰‹å¼•æ“è¡¥å…¨çš„ã€‚ä½ å¯èƒ½å¯ä»¥åšåŠ¨æ€åµŒå…¥æ¨¡å‹è®­ç»ƒï¼Œä½†æˆ‘è§‰å¾—çœŸæ­£çš„ 10 å€æ”¹è¿›ä¼šæ¥è‡ªäºè®­ç»ƒåˆ°æƒé‡ã€‚å¦‚æœä½ çœŸçš„åŠªåŠ›ï¼Œä½ å¯èƒ½è®© **RAG** å¥½ 2 å€ï¼Œä½†æˆ‘è®¤ä¸ºå®ƒæœ‰å¤ªå¤šæ ¹æœ¬æ€§é—®é¢˜ï¼Œæˆ‘ä¸ä¼šèŠ±é‚£ä¹ˆå¤šæ—¶é—´å»æ”¹è¿›å®ƒã€‚

---

## Q&Aï¼šRAG çš„æ ¹æœ¬é—®é¢˜

(92) [47:44-48:09] **What do you feel like the most fundamental problem is where even if like your retrieval was fantastic, you still kind of... I think like chunking um yeah, you just like kind of retrieve some of the stuff you need and then you can't really reason across all of it. And like I think in the limit like there's some types of data where like no matter how you chunk, you'll never get like everything you need if that makes sense.**

ä½ è§‰å¾—æœ€æ ¹æœ¬çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Œå³ä½¿ä½ çš„æ£€ç´¢éå¸¸å¥½ï¼Œä½ ä»ç„¶â€¦â€¦æˆ‘è®¤ä¸ºæ˜¯åˆ†å—ã€‚ä½ åªæ˜¯æ£€ç´¢åˆ°ä½ éœ€è¦çš„ä¸€éƒ¨åˆ†ä¸œè¥¿ï¼Œç„¶åä½ æ— æ³•çœŸæ­£åœ¨æ‰€æœ‰å†…å®¹ä¸Šè¿›è¡Œæ¨ç†ã€‚æˆ‘è®¤ä¸ºåœ¨æé™æƒ…å†µä¸‹ï¼Œæœ‰äº›ç±»å‹çš„æ•°æ®æ— è®ºä½ æ€ä¹ˆåˆ†å—ï¼Œä½ æ°¸è¿œä¸ä¼šå¾—åˆ°ä½ éœ€è¦çš„ä¸€åˆ‡ã€‚

è§£æï¼š
* **chunking**ï¼šåˆ†å—ï¼ˆRAG çš„æ ¸å¿ƒé—®é¢˜ï¼‰

---

## Q&Aï¼šè§„æ¨¡åŒ–ä¸ªæ€§åŒ–

(93) [48:09-48:55] **Do you see any fundamental limitations as you scale up the amount of personalization you need? Let's say you had a B2C product that had 100 million or 10 million users memory for all of those. Do you think that's just not feasible? Um no, no, I actually think it is feasible. Like LoRA, maybe you train a few megabytes per user or something. It's not that crazy, right? Like YouTube probably has gigabytes per user multiple times, right? That's a good point. Like the continual updates are hard. Like probably in realistic short term, it's more like you update once a day or something like that. But I think that's doable. But you make a good point that the paradigm I'm describing is much more expensive.**

è§„æ¨¡åŒ–ä¸ªæ€§åŒ–æ—¶æœ‰ä»€ä¹ˆæ ¹æœ¬æ€§é™åˆ¶å—ï¼Ÿå‡è®¾ä½ æœ‰ä¸€ä¸ª **B2C** äº§å“ï¼Œæœ‰ 1 äº¿æˆ– 1000 ä¸‡ç”¨æˆ·ï¼Œè¦ä¸ºä»–ä»¬æ‰€æœ‰äººå­˜å‚¨è®°å¿†ã€‚ä½ è®¤ä¸ºè¿™ä¸å¯è¡Œå—ï¼Ÿä¸ï¼Œæˆ‘å®é™…ä¸Šè®¤ä¸ºæ˜¯å¯è¡Œçš„ã€‚æ¯”å¦‚ **LoRA**ï¼Œä¹Ÿè®¸ä½ æ¯ä¸ªç”¨æˆ·è®­ç»ƒå‡ å…†å­—èŠ‚ã€‚è¿™æ²¡é‚£ä¹ˆç–¯ç‹‚ï¼Œå¯¹å§ï¼Ÿ**YouTube** å¯èƒ½æ¯ä¸ªç”¨æˆ·æœ‰å¥½å‡ ä¸ª GB çš„æ•°æ®ã€‚è¿™æ˜¯ä¸ªå¥½è§‚ç‚¹ã€‚æŒç»­æ›´æ–°å¾ˆéš¾ã€‚åœ¨ç°å®çš„çŸ­æœŸå†…ï¼Œå¯èƒ½æ›´åƒæ˜¯æ¯å¤©æ›´æ–°ä¸€æ¬¡ã€‚ä½†æˆ‘è®¤ä¸ºè¿™æ˜¯å¯è¡Œçš„ã€‚ä½†ä½ è¯´å¾—å¯¹ï¼Œæˆ‘æè¿°çš„èŒƒå¼æ›´è´µã€‚

---

## Q&Aï¼šä¸‰ä¸ªä¼˜åŒ–è½´

(94) [49:00-49:26] **Also, you do consider there's a lot more that you can do in the other two buckets. You compress the data context. You compress it before you put RAG. You break it up into other buckets. You don't just have to use RAG and use SQL and knowledge graphs to all of them together in different buckets and that solves a lot of problems. Yeah. Yeah, that's a good point. There's kind of like three axes of optimization here. And I guess like we are we're getting pretty good at this. We're okay at this and we're horrible at this. And so like we'll continue improving upon all three axes.**

å¦å¤–ï¼Œä½ ç¡®å®è¦è€ƒè™‘åœ¨å¦å¤–ä¸¤ä¸ªæ¡¶é‡Œä½ è¿˜å¯ä»¥åšå¾ˆå¤šã€‚ä½ å‹ç¼©æ•°æ®ä¸Šä¸‹æ–‡ã€‚ä½ åœ¨æ”¾è¿› **RAG** ä¹‹å‰å‹ç¼©å®ƒã€‚ä½ æŠŠå®ƒåˆ†åˆ°å…¶ä»–æ¡¶é‡Œã€‚ä½ ä¸å¿…åªç”¨ **RAG**ï¼Œå¯ä»¥ç”¨ SQL å’ŒçŸ¥è¯†å›¾è°±ï¼ŒæŠŠå®ƒä»¬æ”¾åœ¨ä¸åŒçš„æ¡¶é‡Œï¼Œè¿™è§£å†³äº†å¾ˆå¤šé—®é¢˜ã€‚æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½è§‚ç‚¹ã€‚è¿™é‡Œæœ‰ä¸‰ä¸ªä¼˜åŒ–è½´ã€‚æˆ‘ä»¬åœ¨è¿™ä¸ªä¸Šåšå¾—å¾ˆå¥½ï¼Œè¿™ä¸ªè¿˜å¯ä»¥ï¼Œè¿™ä¸ªå¾ˆç³Ÿç³•ã€‚æ‰€ä»¥æˆ‘ä»¬ä¼šç»§ç»­åœ¨æ‰€æœ‰ä¸‰ä¸ªè½´ä¸Šæ”¹è¿›ã€‚

---

## Q&Aï¼šå†³ç­–è¾¹ç•Œ

(95) [49:26-50:31] **What's your kind of like intuition or guess in terms of like where the decision boundary is in terms of investing your effort in those optimizations... is it the freshness of the data how fast changing is the number of documents there what's your... Yeah it's a really good question. I think the paradigm I'm describing is especially effective when you have like a large amount of data that's not been indexed into the LLM at all and it gives you a big benefit there. I think when you start seeing like sparser updates to your data set or like some new data comes in but it's not that much and it's like fairly often then you probably want to turn to inference time approaches that are closer to deep research.**

ä½ çš„ç›´è§‰æˆ–çŒœæµ‹æ˜¯ä»€ä¹ˆï¼Œå…³äºåœ¨è¿™äº›ä¼˜åŒ–ä¸­æŠ•å…¥åŠªåŠ›çš„å†³ç­–è¾¹ç•Œåœ¨å“ªé‡Œâ€¦â€¦æ˜¯æ•°æ®çš„æ–°é²œåº¦å—ï¼Ÿå˜åŒ–æœ‰å¤šå¿«ï¼Ÿæ–‡æ¡£æ•°é‡ï¼Ÿè¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æˆ‘è®¤ä¸ºæˆ‘æè¿°çš„èŒƒå¼åœ¨ä½ æœ‰å¤§é‡æ•°æ®ä¸”è¿™äº›æ•°æ®å®Œå…¨æ²¡æœ‰è¢«ç´¢å¼•è¿› LLM æ—¶ç‰¹åˆ«æœ‰æ•ˆã€‚å½“ä½ å¼€å§‹çœ‹åˆ°å¯¹æ•°æ®é›†æ›´ç¨€ç–çš„æ›´æ–°ï¼Œæˆ–è€…æœ‰ä¸€äº›æ–°æ•°æ®è¿›æ¥ä½†ä¸æ˜¯å¾ˆå¤šä¸”ç›¸å½“é¢‘ç¹æ—¶ï¼Œä½ å¯èƒ½æƒ³è½¬å‘æ›´æ¥è¿‘ **Deep Research** çš„æ¨ç†æ—¶æ–¹æ³•ã€‚

---

## Q&Aï¼šåˆæˆæ•°æ®ç”Ÿæˆçš„åº”ç”¨

(96) [50:31-52:09] **Can you elaborate a little bit more about the synthetic data generation... let's say that you have YouTube to talk similar language terminology like proprietary data right like millions of documents like how is synthetic data generation that context helpful... I think synthetic data generation could work for that problem. So I guess like it depends on how information dense your data is. If you have millions of documents from your company, I would guess many of them share formatting and only contribute maybe like a few bits of kind of global information to the data set. And so what you want to think about is like does there exist a function that could produce a good training data set for an LLM that would teach it about my data? And like there probably is. Like you could probably design some strategy that looks at the documents, kind of like figures out what's new about each document and creates like kind of question answer pairs, but this is very blue sky.**

ä½ èƒ½è¯¦ç»†è¯´ä¸€ä¸‹åˆæˆæ•°æ®ç”Ÿæˆå—ï¼Ÿå‡è®¾ä½ æœ‰ç±»ä¼¼ **YouTube** çš„ä¸œè¥¿ï¼Œä½¿ç”¨ç±»ä¼¼çš„è¯­è¨€æœ¯è¯­ï¼Œæ¯”å¦‚ä¸“æœ‰æ•°æ®ï¼Œæ¯”å¦‚æ•°ç™¾ä¸‡ä»½æ–‡æ¡£ï¼Œåˆæˆæ•°æ®ç”Ÿæˆåœ¨é‚£ä¸ªåœºæ™¯ä¸‹æ€ä¹ˆæœ‰å¸®åŠ©ï¼Ÿæˆ‘è®¤ä¸ºåˆæˆæ•°æ®ç”Ÿæˆå¯ä»¥è§£å†³é‚£ä¸ªé—®é¢˜ã€‚è¿™å–å†³äºä½ çš„æ•°æ®ä¿¡æ¯å¯†åº¦æœ‰å¤šé«˜ã€‚å¦‚æœä½ æœ‰å…¬å¸çš„æ•°ç™¾ä¸‡ä»½æ–‡æ¡£ï¼Œæˆ‘çŒœå¾ˆå¤šæ–‡æ¡£å…±äº«æ ¼å¼ï¼Œåªå¯¹æ•°æ®é›†è´¡çŒ®å¤§æ¦‚å‡ æ¯”ç‰¹çš„å…¨å±€ä¿¡æ¯ã€‚æ‰€ä»¥ä½ è¦æ€è€ƒçš„æ˜¯ï¼šæ˜¯å¦å­˜åœ¨ä¸€ä¸ªå‡½æ•°å¯ä»¥äº§ç”Ÿä¸€ä¸ªå¥½çš„ LLM è®­ç»ƒæ•°æ®é›†æ¥æ•™å®ƒå…³äºä½ çš„æ•°æ®ï¼Ÿå¯èƒ½æœ‰ã€‚ä½ å¯ä»¥è®¾è®¡ç­–ç•¥æ¥æŸ¥çœ‹æ–‡æ¡£ï¼Œæ‰¾å‡ºæ¯ä¸ªæ–‡æ¡£çš„æ–°å†…å®¹ï¼Œåˆ›å»ºé—®ç­”å¯¹ï¼Œä½†è¿™éå¸¸è“å¤©ï¼ˆå‰ç»æ€§çš„ï¼‰ã€‚

è§£æï¼š
* **blue sky**ï¼šå‰ç»æ€§çš„ç ”ç©¶

---

## Q&Aï¼šç†æƒ³æƒ…å†µä¸‹ä¸éœ€è¦æç¤ºè¯

(97) [52:37-53:51] **With this approach what would the prompt basically look like... is there anything within the in context learning that would still need to be kind of specified to bring your data into a context. Yeah. I think actually if you do it right, you don't need a prompt at all like you can just ask the model a question. No system prompt, no extra information and if nothing has changed, it should know everything. Like and you even there's some scenarios where there's only one document and the model knows which document it is so you don't have to specify that you're even asking a question about the document it's like implied. I think in like the ideal case there's no prompt at all.**

ç”¨è¿™ç§æ–¹æ³•ï¼Œæç¤ºè¯åŸºæœ¬ä¸Šä¼šæ˜¯ä»€ä¹ˆæ ·å­ï¼Ÿåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­è¿˜éœ€è¦æŒ‡å®šä»€ä¹ˆæ¥æŠŠä½ çš„æ•°æ®å¸¦å…¥ä¸Šä¸‹æ–‡å—ï¼Ÿæˆ‘è®¤ä¸ºå¦‚æœä½ åšå¯¹äº†ï¼Œä½ æ ¹æœ¬ä¸éœ€è¦æç¤ºè¯ï¼Œä½ å¯ä»¥ç›´æ¥é—®æ¨¡å‹ä¸€ä¸ªé—®é¢˜ã€‚æ²¡æœ‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ²¡æœ‰é¢å¤–ä¿¡æ¯ï¼Œå¦‚æœä»€ä¹ˆéƒ½æ²¡å˜ï¼Œå®ƒåº”è¯¥çŸ¥é“ä¸€åˆ‡ã€‚ç”šè‡³åœ¨æŸäº›åœºæ™¯ä¸‹åªæœ‰ä¸€ä¸ªæ–‡æ¡£ï¼Œæ¨¡å‹çŸ¥é“æ˜¯å“ªä¸ªæ–‡æ¡£ï¼Œæ‰€ä»¥ä½ ç”šè‡³ä¸éœ€è¦æŒ‡å®šä½ åœ¨é—®å…³äºè¿™ä¸ªæ–‡æ¡£çš„é—®é¢˜ï¼Œè¿™æ˜¯éšå«çš„ã€‚åœ¨ç†æƒ³æƒ…å†µä¸‹æ ¹æœ¬ä¸éœ€è¦æç¤ºè¯ã€‚

---

## Q&Aï¼šä¸ºä»€ä¹ˆè¦å­˜å‚¨åœ¨æƒé‡ä¸­

(98) [53:51-54:57] **It's not obvious to me that information is best stored in model. Yeah why do you have... This is a good question. I'm not saying that it's best to store information in weights. I guess I'm arguing that that gets you a lot and we're not using it right now. And like once you get to the scale of like a GitHub repo, you might have millions of tokens and it's just like very expensive. And so at least like this is the cheapest way to do it. Do you know what I mean when I say it's cheaper though like if you have a million token prompt you can just like compress it into the weights and produce a model that gives the same outputs with no prompt and then the inference costs less.**

å¯¹æˆ‘æ¥è¯´ä¿¡æ¯æœ€å¥½å­˜å‚¨åœ¨æ¨¡å‹ä¸­å¹¶ä¸æ˜¯æ˜¾è€Œæ˜“è§çš„ã€‚è¿™æ˜¯ä¸€ä¸ªå¥½é—®é¢˜ã€‚æˆ‘ä¸æ˜¯è¯´åœ¨æƒé‡ä¸­å­˜å‚¨ä¿¡æ¯æ˜¯æœ€å¥½çš„ã€‚æˆ‘æƒ³è¯´çš„æ˜¯è¿™èƒ½ç»™ä½ å¾ˆå¤šå¥½å¤„ï¼Œè€Œæˆ‘ä»¬ç°åœ¨æ²¡æœ‰ä½¿ç”¨å®ƒã€‚ä¸€æ—¦ä½ è¾¾åˆ° **GitHub** ä»“åº“çš„è§„æ¨¡ï¼Œä½ å¯èƒ½æœ‰æ•°ç™¾ä¸‡ä¸ª tokenï¼Œè¿™éå¸¸æ˜‚è´µã€‚æ‰€ä»¥è‡³å°‘è¿™æ˜¯æœ€ä¾¿å®œçš„æ–¹å¼ã€‚ä½ ç†è§£æˆ‘è¯´æ›´ä¾¿å®œæ˜¯ä»€ä¹ˆæ„æ€å—ï¼Ÿå¦‚æœä½ æœ‰ä¸€ç™¾ä¸‡ token çš„æç¤ºè¯ï¼Œä½ å¯ä»¥æŠŠå®ƒå‹ç¼©è¿›æƒé‡ï¼Œäº§ç”Ÿä¸€ä¸ªä¸éœ€è¦æç¤ºè¯å°±èƒ½ç»™å‡ºç›¸åŒè¾“å‡ºçš„æ¨¡å‹ï¼Œç„¶åæ¨ç†æˆæœ¬æ›´ä½ã€‚

---

## Q&Aï¼šå¯¹æŠ—æ€§æ•°æ®

(99) [55:04-55:57] **I have one after that there is no adversarial data. That's actually a really good question. Never thought about it before. Um I think it's probably pretty hard. Like I guess if you're training on user data and like you have some user that wants to sabotage your system and you're generating training data from their inputs, there probably are a lot of like security risks. And uh I guess in this scenario, if you're serving the same model that user and it doesn't work anymore, that's like not your problem. But once you start aggregating information across users, I bet it becomes hard. I'm sure ChatGPT has the same problem where some people always click thumbs down instead of thumbs up to try to like...**

å…³äºå¯¹æŠ—æ€§æ•°æ®ã€‚è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜ã€‚æˆ‘ä»¥å‰ä»æ²¡æƒ³è¿‡ã€‚æˆ‘è®¤ä¸ºè¿™å¯èƒ½ç›¸å½“éš¾ã€‚å¦‚æœä½ åœ¨ç”¨æˆ·æ•°æ®ä¸Šè®­ç»ƒï¼Œæœ‰äº›ç”¨æˆ·æƒ³ç ´åä½ çš„ç³»ç»Ÿï¼Œä½ ä»ä»–ä»¬çš„è¾“å…¥ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œå¯èƒ½æœ‰å¾ˆå¤šå®‰å…¨é£é™©ã€‚æˆ‘çŒœåœ¨è¿™ä¸ªåœºæ™¯ä¸‹ï¼Œå¦‚æœä½ ç»™é‚£ä¸ªç”¨æˆ·æä¾›åŒä¸€ä¸ªæ¨¡å‹è€Œå®ƒä¸å·¥ä½œäº†ï¼Œé‚£ä¸æ˜¯ä½ çš„é—®é¢˜ã€‚ä½†ä¸€æ—¦ä½ å¼€å§‹è·¨ç”¨æˆ·èšåˆä¿¡æ¯ï¼Œæˆ‘æ‰“èµŒä¼šå˜å¾—å¾ˆéš¾ã€‚æˆ‘ç¡®å®š **ChatGPT** æœ‰åŒæ ·çš„é—®é¢˜ï¼Œæœ‰äº›äººæ€»æ˜¯ç‚¹è¸©è€Œä¸æ˜¯ç‚¹èµæ¥è¯•å›¾â€¦â€¦

è§£æï¼š
* **adversarial data**ï¼šå¯¹æŠ—æ€§æ•°æ®
* **sabotage**ï¼šç ´å

---

## Q&Aï¼šç‰ˆæœ¬æ§åˆ¶ä¸çŸ›ç›¾ä¿¡æ¯

(100) [55:57-57:00] **Thinking maybe a little bit about practical implementations... especially in terms of version controlling, you mentioned GitHub models that you keep fine-tuning over time. Say you're a company that just changed a policy and it's just a one line sentence... that keeps going back and forth. Do you then start from the base model again and then fine-tune that or go back to the one that already a good representation of it... and then how that is joined at the hip with hallucinations which is kind of why we were doing full context to avoid that. Do you have any thoughts on how that might work? Yeah, I think so his question was about what do you do once you start making multiple updates to the model especially when you have like conflicting information and I think like the optimal synthetic data strategy was somehow figure this out during training and maybe even like if there's some documents from a few days ago that are no longer relevant you can just like delete them but I don't know how.**

è€ƒè™‘ä¸€ä¸‹å®é™…å®ç°ã€‚ç‰¹åˆ«æ˜¯ç‰ˆæœ¬æ§åˆ¶æ–¹é¢ï¼Œä½ æåˆ° **GitHub** æ¨¡å‹ä½ ä¼šéšæ—¶é—´æŒç»­å¾®è°ƒã€‚å‡è®¾ä½ æ˜¯ä¸€å®¶å…¬å¸åˆšåˆšæ”¹å˜äº†æ”¿ç­–ï¼Œåªæ˜¯ä¸€å¥è¯â€¦â€¦æ¥å›å˜åŒ–ã€‚ä½ æ˜¯ä»åŸºç¡€æ¨¡å‹é‡æ–°å¼€å§‹å†å¾®è°ƒï¼Œè¿˜æ˜¯å›åˆ°å·²ç»æœ‰è‰¯å¥½è¡¨ç¤ºçš„é‚£ä¸ªâ€¦â€¦è¿™å’Œå¹»è§‰é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬åšå…¨ä¸Šä¸‹æ–‡æ¥é¿å…é‚£ä¸ªã€‚ä»–çš„é—®é¢˜æ˜¯ä¸€æ—¦ä½ å¼€å§‹å¯¹æ¨¡å‹è¿›è¡Œå¤šæ¬¡æ›´æ–°ï¼Œç‰¹åˆ«æ˜¯å½“ä½ æœ‰ç›¸äº’çŸ›ç›¾çš„ä¿¡æ¯æ—¶ä½ æ€ä¹ˆåŠã€‚æˆ‘è®¤ä¸ºæœ€ä¼˜çš„åˆæˆæ•°æ®ç­–ç•¥æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»¥æŸç§æ–¹å¼è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œç”šè‡³å¦‚æœæœ‰å‡ å¤©å‰çš„ä¸€äº›æ–‡æ¡£ä¸å†ç›¸å…³ï¼Œä½ å¯ä»¥åˆ é™¤å®ƒä»¬ï¼Œä½†æˆ‘ä¸çŸ¥é“å…·ä½“æ€ä¹ˆåšã€‚

è§£æï¼š
* **joined at the hip with**ï¼šä¸â€¦â€¦å¯†åˆ‡ç›¸å…³
* **hallucinations**ï¼šå¹»è§‰

---

## Q&Aï¼šè”é‚¦å­¦ä¹ çš„å›å½’

(101) [58:42-59:31] **Have you done any work with federated tuning fine tuning parameters of users? No not really but I think it's an interesting opportunity. So like back in the day a lot of people were really excited about the idea that you could share gradients and train the same model across many machines. This is federated learning. And I think like one of the problems why it's hard is because the models now are so big that the network costs are way too high and because like I'm arguing that you only need to train a million parameters instead of a trillion. It probably comes back into play. So I think it's a very good idea especially in the RL world where you do a lot of work for a long time and then do gradients like very seldomly. So I think it probably will come back and it's smart to think of it but it hasn't quite yet.**

ä½ æœ‰æ²¡æœ‰åšè¿‡ç”¨æˆ·å‚æ•°çš„è”é‚¦è°ƒä¼˜å¾®è°ƒï¼Ÿä¸ï¼Œæ²¡æœ‰ï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„æœºä¼šã€‚ä»¥å‰å¾ˆå¤šäººå¯¹è¿™ä¸ªæƒ³æ³•éå¸¸å…´å¥‹ï¼šä½ å¯ä»¥å…±äº«æ¢¯åº¦ï¼Œåœ¨å¤šå°æœºå™¨ä¸Šè®­ç»ƒåŒä¸€ä¸ªæ¨¡å‹ã€‚è¿™å°±æ˜¯è”é‚¦å­¦ä¹ ã€‚æˆ‘è®¤ä¸ºå®ƒå¾ˆéš¾çš„ä¸€ä¸ªé—®é¢˜æ˜¯ç°åœ¨æ¨¡å‹å¤ªå¤§äº†ï¼Œç½‘ç»œæˆæœ¬å¤ªé«˜ã€‚å› ä¸ºæˆ‘åœ¨è¯´ä½ åªéœ€è¦è®­ç»ƒä¸€ç™¾ä¸‡å‚æ•°è€Œä¸æ˜¯ä¸€ä¸‡äº¿ã€‚å®ƒå¯èƒ½ä¼šé‡æ–°å‘æŒ¥ä½œç”¨ã€‚ç‰¹åˆ«æ˜¯åœ¨ **RL** ä¸–ç•Œé‡Œï¼Œä½ åšå¾ˆé•¿æ—¶é—´çš„å·¥ä½œç„¶åå¾ˆå°‘åšæ¢¯åº¦æ›´æ–°ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºå®ƒå¯èƒ½ä¼šå›æ¥ï¼Œæ€è€ƒè¿™ä¸ªå¾ˆèªæ˜ï¼Œä½†è¿˜æ²¡æœ‰ã€‚

è§£æï¼š
* **federated learning**ï¼šè”é‚¦å­¦ä¹ 
* **comes back into play**ï¼šé‡æ–°å‘æŒ¥ä½œç”¨

---

## Q&Aï¼šä¸“ä¸šåŒ–æ¨¡å‹ vs é€šç”¨æ¨ç†å¼•æ“

(102) [59:31-1:01:18] **So your argument here about training in information seems to be counter to Karpathy's view of like a reasoning engine like distilling just the pure intelligence aspect of a model down to like a two billion parameter thing. Um and like I think that there's a bit of overlap there... like a lawyer is not doesn't have the entire legal code memorized but they know how to use the tools available to them to find what they need to... Yeah. So I think there may be a comparison between some people who have said, "Oh, the best model we could ever have is like really small and knows nothing but can use tools really well." And I guess I was proposing some similar ideas. I said models know way too much. I think everyone agrees the model doesn't need to know the capital of the smallest province of Tajikistan for most use cases. But I think it's really hard to create a model that doesn't know anything. And so I'm more advocating for like specialized models that are good at something you care about but bad at other things rather than advocating for a model that's like bad at everything.**

ä½ è¿™é‡Œå…³äºè®­ç»ƒä¿¡æ¯çš„è®ºç‚¹ä¼¼ä¹ä¸ **Karpathy** å…³äºæ¨ç†å¼•æ“çš„è§‚ç‚¹ç›¸åâ€”â€”æŠŠæ¨¡å‹çš„çº¯æ™ºèƒ½æ–¹é¢è’¸é¦åˆ°ä¸€ä¸ª 20 äº¿å‚æ•°çš„ä¸œè¥¿ã€‚æˆ‘è®¤ä¸ºè¿™é‡Œæœ‰ä¸€äº›é‡å â€¦â€¦æ¯”å¦‚å¾‹å¸ˆå¹¶æ²¡æœ‰èƒŒä¸‹æ•´ä¸ªæ³•å¾‹æ¡æ–‡ï¼Œä½†ä»–ä»¬çŸ¥é“å¦‚ä½•ä½¿ç”¨å¯ç”¨çš„å·¥å…·æ‰¾åˆ°ä»–ä»¬éœ€è¦çš„ä¸œè¥¿â€¦â€¦æ˜¯çš„ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºå¯èƒ½æœ‰ä¸€ä¸ªæ¯”è¾ƒï¼Œæœ‰äº›äººè¯´"æˆ‘ä»¬èƒ½æ‹¥æœ‰çš„æœ€å¥½çš„æ¨¡å‹æ˜¯éå¸¸å°çš„ï¼Œä»€ä¹ˆéƒ½ä¸çŸ¥é“ä½†èƒ½å¾ˆå¥½åœ°ä½¿ç”¨å·¥å…·"ã€‚æˆ‘æƒ³æˆ‘ä¹Ÿåœ¨æå‡ºä¸€äº›ç±»ä¼¼çš„æƒ³æ³•ã€‚æˆ‘è¯´æ¨¡å‹çŸ¥é“çš„å¤ªå¤šäº†ã€‚æˆ‘è®¤ä¸ºæ¯ä¸ªäººéƒ½åŒæ„ï¼Œå¯¹äºå¤§å¤šæ•°ç”¨ä¾‹ï¼Œæ¨¡å‹ä¸éœ€è¦çŸ¥é“å¡”å‰å…‹æ–¯å¦æœ€å°çœä»½çš„é¦–åºœã€‚ä½†æˆ‘è®¤ä¸ºåˆ›å»ºä¸€ä¸ªä»€ä¹ˆéƒ½ä¸çŸ¥é“çš„æ¨¡å‹çœŸçš„å¾ˆéš¾ã€‚æ‰€ä»¥æˆ‘æ›´å€¾å‘äºä¸“ä¸šåŒ–çš„æ¨¡å‹ï¼Œæ“…é•¿ä½ å…³å¿ƒçš„ä¸œè¥¿ä½†ä¸æ“…é•¿å…¶ä»–ä¸œè¥¿ï¼Œè€Œä¸æ˜¯å€¡å¯¼ä¸€ä¸ªä»€ä¹ˆéƒ½ä¸æ“…é•¿çš„æ¨¡å‹ã€‚

è§£æï¼š
* **distilling**ï¼šè’¸é¦
* **specialized models**ï¼šä¸“ä¸šåŒ–æ¨¡å‹

---

## Q&Aï¼šæ—¶é—´å…ƒç´ ä¸æœªæ¥ç ”ç©¶

(103) [1:01:18-1:02:18] **Have you ever done research yet in the temporal elements of the information? No, but I think that's like one of the first things to think about is like, okay, if you have information from day one and day two and day three, do you just sort of like concatenate everything or do you train in order kind of like you were asking or do you like train multiple models and merge them or I actually don't know, but that's a good segue. So now I'm working on this problems related to this a lot, thinking about this a lot. Started a company with a few other people and this is like the kind of research we're doing. If anyone knows someone who lives in San Francisco and is a good engineer and you think they're interested in this, let me know or send me an email. Or if you're interested in like using this kind of thing, send me an email. That would be great. It's temporal stuff or not necessarily. I mean it's kind of all of this I would say. Trying to build models that you can teach things to. All right. Thanks so much for having me. This is great.**

ä½ æœ‰æ²¡æœ‰åšè¿‡å…³äºä¿¡æ¯æ—¶é—´å…ƒç´ çš„ç ”ç©¶ï¼Ÿæ²¡æœ‰ï¼Œä½†æˆ‘è®¤ä¸ºé‚£æ˜¯é¦–å…ˆè¦è€ƒè™‘çš„äº‹æƒ…ä¹‹ä¸€ã€‚å¦‚æœä½ æœ‰ç¬¬ä¸€å¤©ã€ç¬¬äºŒå¤©ã€ç¬¬ä¸‰å¤©çš„ä¿¡æ¯ï¼Œä½ æ˜¯æŠŠæ‰€æœ‰ä¸œè¥¿è¿æ¥èµ·æ¥ï¼Œè¿˜æ˜¯æŒ‰é¡ºåºè®­ç»ƒå°±åƒä½ é—®çš„é‚£æ ·ï¼Œè¿˜æ˜¯è®­ç»ƒå¤šä¸ªæ¨¡å‹ç„¶ååˆå¹¶å®ƒä»¬ï¼Ÿæˆ‘å®é™…ä¸Šä¸çŸ¥é“ï¼Œä½†è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„å¼•å­ã€‚æ‰€ä»¥ç°åœ¨æˆ‘æ­£åœ¨å¤§é‡ç ”ç©¶ä¸æ­¤ç›¸å…³çš„é—®é¢˜ï¼Œæ€è€ƒè¿™äº›é—®é¢˜ã€‚æˆ‘å’Œå…¶ä»–å‡ ä¸ªäººåˆ›åŠäº†ä¸€å®¶å…¬å¸ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬æ­£åœ¨åšçš„ç ”ç©¶ç±»å‹ã€‚å¦‚æœæœ‰äººè®¤è¯†ä½åœ¨æ—§é‡‘å±±çš„ä¼˜ç§€å·¥ç¨‹å¸ˆï¼Œä½ è®¤ä¸ºä»–ä»¬å¯¹æ­¤æ„Ÿå…´è¶£ï¼Œè¯·å‘Šè¯‰æˆ‘æˆ–å‘é‚®ä»¶ç»™æˆ‘ã€‚æˆ–è€…å¦‚æœä½ å¯¹ä½¿ç”¨è¿™ç§ä¸œè¥¿æ„Ÿå…´è¶£ï¼Œå‘é‚®ä»¶ç»™æˆ‘ã€‚é‚£å¤ªå¥½äº†ã€‚æ˜¯å…³äºæ—¶é—´çš„ä¸œè¥¿è¿˜æ˜¯ä¸ä¸€å®šï¼Ÿæˆ‘çš„æ„æ€æ˜¯æˆ‘ä¼šè¯´è¿™äº›éƒ½æ˜¯ã€‚å°è¯•æ„å»ºä½ å¯ä»¥æ•™ä¸œè¥¿çš„æ¨¡å‹ã€‚å¥½çš„ã€‚éå¸¸æ„Ÿè°¢é‚€è¯·æˆ‘ã€‚è¿™å¤ªæ£’äº†ã€‚

è§£æï¼š
* **temporal elements**ï¼šæ—¶é—´å…ƒç´ 
* **segue**ï¼šå¼•å­ã€è¿‡æ¸¡

---

## ç¬¬ä¸‰éƒ¨åˆ†å°ç»“

### Q&A æ ¸å¿ƒè¦ç‚¹

15. **RL vs SFT å‚æ•°éœ€æ±‚**ï¼šRL å› ä¸ºå­¦ä¹ ä¿¡å·ç¨€ç–ï¼ˆåªæœ‰ 0/1ï¼‰ï¼Œæ¯” SFT éœ€è¦å°‘ 1000 å€çš„å‚æ•°

16. **RAG vs è®­ç»ƒçš„é€‰æ‹©**ï¼š
    - ä¸¤è€…åº”è¯¥ç»“åˆä½¿ç”¨
    - å¤§é‡æ•°æ® + ä¸é¢‘ç¹æ›´æ–° â†’ è®­ç»ƒåˆ°æƒé‡
    - æ•°æ®é¢‘ç¹å˜åŒ– â†’ æ¨ç†æ—¶æ–¹æ³•ï¼ˆå¦‚ Deep Researchï¼‰

17. **RAG çš„æ ¹æœ¬é—®é¢˜**ï¼šåˆ†å—ï¼ˆchunkingï¼‰â€”â€”æ— è®ºæ€ä¹ˆåˆ†å—ï¼ŒæŸäº›ç±»å‹çš„æ•°æ®ä½ æ°¸è¿œæ— æ³•è·å¾—å…¨éƒ¨éœ€è¦çš„å†…å®¹

18. **è§„æ¨¡åŒ–ä¸ªæ€§åŒ–**ï¼šå¯è¡Œçš„ã€‚æ¯ç”¨æˆ·å‡  MB çš„ LoRA

19. **åˆæˆæ•°æ®ç”Ÿæˆ**ï¼š
    - å¯¹ä¿¡æ¯å¯†åº¦é«˜çš„å¤§é‡æ–‡æ¡£æœ‰æ•ˆ
    - å¯ä»¥ç”Ÿæˆé—®ç­”å¯¹æ¥è®­ç»ƒ
    - ç›®å‰æ²¡æœ‰é€šç”¨è§£å†³æ–¹æ¡ˆ

20. **ç‰ˆæœ¬æ§åˆ¶ä¸çŸ›ç›¾ä¿¡æ¯**ï¼š
    - æœ€ä¼˜ç­–ç•¥æ˜¯åœ¨è®­ç»ƒæ—¶è§£å†³
    - åˆ é™¤ä¸å†ç›¸å…³çš„æ—§æ–‡æ¡£
    - ä¸ RAG æœ‰ç›¸åŒçš„é™åˆ¶

21. **è”é‚¦å­¦ä¹ çš„å›å½’**ï¼šå› ä¸ºç°åœ¨åªéœ€è¦è®­ç»ƒç™¾ä¸‡å‚æ•°è€Œä¸æ˜¯ä¸‡äº¿ï¼Œè”é‚¦å­¦ä¹ å¯èƒ½ä¼šé‡æ–°ç›¸å…³

22. **ä¸“ä¸šåŒ–æ¨¡å‹ vs é€šç”¨æ¨ç†å¼•æ“**ï¼š
    - æ¼”è®²è€…å€¡å¯¼ä¸“ä¸šåŒ–æ¨¡å‹ï¼šæ“…é•¿ä½ å…³å¿ƒçš„ï¼Œä¸æ“…é•¿å…¶ä»–çš„
    - è€Œä¸æ˜¯ä»€ä¹ˆéƒ½ä¸çŸ¥é“ä½†ä¼šç”¨å·¥å…·çš„æ¨¡å‹

23. **æ—¶é—´å…ƒç´ **ï¼šå¦‚ä½•å¤„ç†ä¸åŒæ—¶é—´çš„ä¿¡æ¯æ˜¯æœªè§£å†³çš„ç ”ç©¶é—®é¢˜

### ç¬¬ä¸‰éƒ¨åˆ†æ–°å¢è¯æ±‡

| è¯æ±‡ | è¯æ€§ | å«ä¹‰ |
|------|------|------|
| **fishy** | adj. | å¯ç–‘çš„ã€è¹Šè··çš„ |
| **random projections** | n. | éšæœºæŠ•å½± |
| **cross entropy** | n. | äº¤å‰ç†µ |
| **GRPO** | n. | Group Relative Policy Optimization |
| **chunking** | n. | åˆ†å— |
| **federated learning** | n. | è”é‚¦å­¦ä¹  |
| **adversarial data** | n. | å¯¹æŠ—æ€§æ•°æ® |
| **hallucinations** | n. | å¹»è§‰ |
| **distilling** | v. | è’¸é¦ |
| **temporal elements** | n. | æ—¶é—´å…ƒç´  |
| **specialized models** | n. | ä¸“ä¸šåŒ–æ¨¡å‹ |

### ç¬¬ä¸‰éƒ¨åˆ†æ–°å¢å£è¯­è¡¨è¾¾

| è¡¨è¾¾ | å«ä¹‰ |
|------|------|
| fishy | å¯ç–‘çš„ |
| if that makes sense | å¦‚æœä½ èƒ½ç†è§£çš„è¯ |
| come down to | å½’ç»“ä¸º |
| in the mix | ä¸ç¡®å®šçš„ä½ç½® |
| the way to go | æœ€å¥½çš„é€‰æ‹© |
| blue sky | å‰ç»æ€§çš„ç ”ç©¶ |
| joined at the hip with | ä¸â€¦â€¦å¯†åˆ‡ç›¸å…³ |
| comes back into play | é‡æ–°å‘æŒ¥ä½œç”¨ |

---

# å…¨æ–‡æ€»ç»“ ğŸ¯

## æ ¸å¿ƒè®ºç‚¹

è¿™åœºæ¼”è®²çš„æ ¸å¿ƒè®ºç‚¹æ˜¯ï¼š**æˆ‘ä»¬åº”è¯¥æŠŠä¿¡æ¯è®­ç»ƒè¿›æ¨¡å‹æƒé‡ï¼Œè€Œä¸ä»…ä»…ä¾èµ– RAG**ã€‚

## ä¸»è¦å†…å®¹å›é¡¾

### ç¬¬ä¸€éƒ¨åˆ†ï¼šRAG çš„å±€é™æ€§
- **Agentic Search** ä¸æ˜¯ RAGï¼Œæœ‰ä¸åŒçš„é™åˆ¶
- æ›´å¥½çš„æ–¹æ¡ˆå¿…ç„¶æ›´è´µï¼ˆè®­ç»ƒæ—¶æˆ–æ¨ç†æ—¶ï¼‰
- æ¨¡å‹å®¹é‡æœ‰é™ï¼ˆçº¦ 3.6 bits/å‚æ•°ï¼‰
- ç›´æ¥å¾®è°ƒä¼šå¯¼è‡´ç¾éš¾æ€§é—å¿˜å’Œè¿‡æ‹Ÿåˆ

### ç¬¬äºŒéƒ¨åˆ†ï¼šè§£å†³æ–¹æ¡ˆ
- **åˆæˆæ•°æ®ç”Ÿæˆ**ï¼šç”¨ LLM æ‰©å……å°æ•°æ®é›†
- **å‚æ•°é«˜æ•ˆå¾®è°ƒ**ï¼šLoRAã€Prefix Tuningã€Memory Layers
- **RL vs SFT**ï¼šRL éœ€è¦çš„å‚æ•°å°‘ 1000 å€

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®è·µè€ƒé‡
- RAG å’Œè®­ç»ƒåº”è¯¥ç»“åˆä½¿ç”¨
- åˆ†å—æ˜¯ RAG çš„æ ¹æœ¬é—®é¢˜
- è§„æ¨¡åŒ–ä¸ªæ€§åŒ–æ˜¯å¯è¡Œçš„
- ä¸“ä¸šåŒ–æ¨¡å‹ä¼˜äº"ä»€ä¹ˆéƒ½ä¸çŸ¥é“ä½†ä¼šç”¨å·¥å…·"çš„æ¨¡å‹

## æ¼”è®²è€…çš„æ ¸å¿ƒæ´è§

1. æ¨¡å‹çŸ¥é“å¤ªå¤šä¸éœ€è¦çš„ä¸œè¥¿
2. åˆæˆæ•°æ®ç”Ÿæˆæ‰“ç ´äº†ä¼ ç»Ÿ ML èŒƒå¼
3. å‚æ•°é«˜æ•ˆæ–¹æ³•è®©ä¸ªæ€§åŒ–æ¨¡å‹æˆä¸ºå¯èƒ½
4. è¿™ä¸ªé¢†åŸŸéå¸¸æ–°ï¼Œæœ‰å¾ˆå¤šç ”ç©¶æœºä¼š
