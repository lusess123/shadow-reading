# ğŸ¯ Diffusion æ‰©æ•£æ¨¡å‹æŠ€æœ¯è®¿è°ˆ è‹±è¯­æ®µè½ç¿»è¯‘

æœ¬æ–‡å…± **25 ä¸ªè¯­ä¹‰å•å…ƒ**ï¼Œå°†å…¨éƒ¨ç¿»è¯‘ã€‚

---

(1) [0:00-0:18] **Welcome back to another episode of Decoded. Today I'm sitting down with YC visiting partner Francois Shaard to talk about one of the most important topics in AI today, diffusion. Francois has been doing computer vision since 2012 when he started in Fei-Fei Li's lab.**

æ¬¢è¿å›åˆ° **Decoded** çš„æ–°ä¸€æœŸèŠ‚ç›®ã€‚ä»Šå¤©æˆ‘è¦å’Œ **YC** çš„è®¿é—®åˆä¼™äºº **Francois Shaard** èŠèŠå½“ä»Š AI é¢†åŸŸæœ€é‡è¦çš„è¯é¢˜ä¹‹ä¸€â€”â€”æ‰©æ•£æ¨¡å‹ã€‚**Francois** ä» 2012 å¹´èµ·å°±åœ¨ **Fei-Fei Li**ï¼ˆæé£é£ï¼‰çš„å®éªŒå®¤å¼€å§‹åšè®¡ç®—æœºè§†è§‰ç ”ç©¶ã€‚

è§£æï¼š
* **sitting down with** ğŸ”¥ï¼šçŸ­è¯­ï¼Œå’ŒæŸäººåä¸‹æ¥æ·±åº¦äº¤è°ˆ
* **visiting partner**ï¼šè®¿é—®åˆä¼™äººï¼ˆçŸ­æœŸé¡¾é—®è§’è‰²ï¼‰

---

(2) [0:13-0:32] **And after a decade running focal systems, he's currently back at Stanford finishing his PhD working on diffusion-based world models for AGI. We're going to break down what diffusion is, how it's evolved over the past decade, and how it's used today. Francois, thanks for being here. Thank you for having me.**

åœ¨è¿è¥ **focal systems** å…¬å¸åå¹´åï¼Œä»–ç°åœ¨å›åˆ°æ–¯å¦ç¦å®Œæˆåšå£«å­¦ä¸šï¼Œç ”ç©¶åŸºäºæ‰©æ•£çš„ä¸–ç•Œæ¨¡å‹ç”¨äº **AGI**ã€‚ä»Šå¤©æˆ‘ä»¬ä¼šæ‹†è§£ä»€ä¹ˆæ˜¯æ‰©æ•£æ¨¡å‹ã€å®ƒåœ¨è¿‡å»åå¹´å¦‚ä½•æ¼”è¿›ã€ä»¥åŠç°åœ¨çš„åº”ç”¨åœºæ™¯ã€‚**Francois**ï¼Œæ„Ÿè°¢ä½ æ¥ã€‚è°¢è°¢ä½ é‚€è¯·æˆ‘ã€‚

è§£æï¼š
* **a decade**ï¼šåå¹´
* **diffusion-based world models**ï¼šåŸºäºæ‰©æ•£çš„ä¸–ç•Œæ¨¡å‹
* **break down** ğŸ”¥ï¼šæ‹†è§£ã€åˆ†è§£è®²è§£

---

(3) [0:33-0:52] **Well, we just got back from NeurIPS. We just spent a lot of time talking to researchers and thinking about all the newest models out there. I think we saw diffusion pop up over and over and newer versions of these type of approaches that are not auto regressive LLM. And so I wanted to talk to you about those today.**

å¥½ï¼Œæˆ‘ä»¬åˆšä» **NeurIPS** å›æ¥ï¼ŒèŠ±äº†å¾ˆå¤šæ—¶é—´å’Œç ”ç©¶äººå‘˜äº¤æµï¼Œè®¨è®ºæœ€æ–°çš„æ¨¡å‹ã€‚æˆ‘å‘ç°æ‰©æ•£æ¨¡å‹åå¤å‡ºç°ï¼Œè¿˜æœ‰å¾ˆå¤šä¸æ˜¯è‡ªå›å½’ **LLM** çš„æ–°æ–¹æ³•ã€‚æ‰€ä»¥ä»Šå¤©æƒ³å’Œä½ èŠèŠè¿™äº›ã€‚

è§£æï¼š
* **NeurIPS**ï¼šç¥ç»ä¿¡æ¯å¤„ç†ç³»ç»Ÿå¤§ä¼šï¼Œé¡¶çº§ AI å­¦æœ¯ä¼šè®®
* **pop up over and over** ğŸ”¥ï¼šåå¤å‡ºç°ã€ä¸æ–­å†’å‡ºæ¥
* **auto regressive LLM**ï¼šè‡ªå›å½’å¤§è¯­è¨€æ¨¡å‹

---

(4) [0:50-1:05] **So first, why don't we start by defining what is diffusion? Diffusion is a very fundamental machine learning framework that allows you to learn any P data, any probability of data for any domain as long as you have the data. So you're trying to learn some data distribution. That's right.**

é¦–å…ˆï¼Œæˆ‘ä»¬ä»å®šä¹‰å¼€å§‹å§â€”â€”ä»€ä¹ˆæ˜¯æ‰©æ•£æ¨¡å‹ï¼Ÿæ‰©æ•£æ˜¯ä¸€ä¸ªéå¸¸åŸºç¡€çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼Œåªè¦ä½ æœ‰æ•°æ®ï¼Œå®ƒå°±èƒ½è®©ä½ å­¦ä¹ ä»»ä½•é¢†åŸŸçš„æ•°æ®æ¦‚ç‡åˆ†å¸ƒã€‚æ‰€ä»¥ä½ æ˜¯åœ¨å°è¯•å­¦ä¹ æŸç§æ•°æ®åˆ†å¸ƒã€‚æ²¡é”™ã€‚

è§£æï¼š
* **why don't we start by**ï¼šæˆ‘ä»¬ä½•ä¸ä»...å¼€å§‹
* **P data / probability of data**ï¼šæ•°æ®çš„æ¦‚ç‡åˆ†å¸ƒ
* **as long as** ğŸ”¥ï¼šåªè¦...

---

(5) [1:05-1:23] **Now in a sense all LLMs or all machine learning models are about learning data distributions. How does diffusion in particular, what stance does it take or what approach does it take to being able to learn distribution? Yeah, I mean I think you can use diffusion to always do that.**

ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œæ‰€æœ‰ **LLM** æˆ–æ‰€æœ‰æœºå™¨å­¦ä¹ æ¨¡å‹éƒ½æ˜¯åœ¨å­¦ä¹ æ•°æ®åˆ†å¸ƒã€‚é‚£æ‰©æ•£æ¨¡å‹å…·ä½“é‡‡å–ä»€ä¹ˆç«‹åœºã€ä»€ä¹ˆæ–¹æ³•æ¥å­¦ä¹ åˆ†å¸ƒå‘¢ï¼Ÿæ˜¯çš„ï¼Œæˆ‘è§‰å¾—æ‰©æ•£æ¨¡å‹ä¸€ç›´éƒ½èƒ½åšåˆ°è¿™ç‚¹ã€‚

è§£æï¼š
* **in a sense**ï¼šä»æŸç§æ„ä¹‰ä¸Šè¯´
* **what stance does it take** ğŸ”¥ï¼šå®ƒé‡‡å–ä»€ä¹ˆç«‹åœº/æ€åº¦

---

(6) [1:20-1:48] **The thing where it stands out in particular is mapping from high dimensions to high dimensions, especially in low data regimes. So, say I only have 30 images of Gary, which I actually have some code that we're going to walk through. I only have 30 images of Gary and we're in this thousand by 10,000 by 3 dimensional space and I want to map to another 3 million dimensional space with only 30 training samples and I can still do it. It's pretty powerful in that way.**

å®ƒç‰¹åˆ«çªå‡ºçš„åœ°æ–¹æ˜¯ä»é«˜ç»´æ˜ å°„åˆ°é«˜ç»´ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®é‡å°‘çš„æƒ…å†µä¸‹ã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘åªæœ‰ 30 å¼  **Gary** çš„ç…§ç‰‡ï¼Œä¸€ä¼šå„¿æˆ‘ä»¬ä¼šçœ‹ä»£ç ã€‚æˆ‘åªæœ‰ 30 å¼ ç…§ç‰‡ï¼Œæˆ‘ä»¬å¤„äºä¸€ä¸ª 1000Ã—10000Ã—3 çš„ç»´åº¦ç©ºé—´ï¼Œæˆ‘æƒ³æ˜ å°„åˆ°å¦ä¸€ä¸ª 300 ä¸‡ç»´çš„ç©ºé—´ï¼Œåªç”¨ 30 ä¸ªè®­ç»ƒæ ·æœ¬æˆ‘å°±èƒ½åšåˆ°ã€‚è¿™çœŸçš„éå¸¸å¼ºå¤§ã€‚

è§£æï¼š
* **stands out** ğŸ”¥ï¼šè„±é¢–è€Œå‡ºã€ç‰¹åˆ«çªå‡º
* **low data regimes**ï¼šæ•°æ®é‡å°‘çš„åœºæ™¯
* **walk through** ğŸ”¥ï¼šé€æ­¥è®²è§£ã€æ¼”ç¤º

---

(7) [1:48-2:05] **Okay, cool. So you have this ability to use relatively small amounts of data compared to the dimensionality to learn a P data. That's right. What's the basic process by which diffusion works? Like just walk through at a very high level, we'll walk through the math a little bit later, but at a very high level, how does this process actually work?**

å¥½çš„ï¼Œé…·ã€‚æ‰€ä»¥ä½ æœ‰è¿™ä¸ªèƒ½åŠ›â€”â€”ç›¸å¯¹äºç»´åº¦æ¥è¯´ï¼Œç”¨å¾ˆå°‘çš„æ•°æ®å°±èƒ½å­¦ä¹ æ•°æ®åˆ†å¸ƒã€‚æ²¡é”™ã€‚é‚£æ‰©æ•£çš„åŸºæœ¬è¿‡ç¨‹æ˜¯ä»€ä¹ˆï¼Ÿå…ˆä»é«˜å±‚æ¬¡è®²ä¸€ä¸‹ï¼Œä¹‹åæˆ‘ä»¬å†çœ‹æ•°å­¦ç»†èŠ‚ï¼Œä½†ç°åœ¨å…ˆè®²è®²è¿™ä¸ªè¿‡ç¨‹åˆ°åº•æ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Ÿ

è§£æï¼š
* **compared to the dimensionality**ï¼šä¸ç»´åº¦ç›¸æ¯”
* **at a very high level** ğŸ”¥ï¼šä»å¾ˆé«˜çš„å±‚æ¬¡ã€å®è§‚åœ°è®²

---

(8) [2:05-2:32] **We take some sample of the data, an image of Anka, an image of Gary, and we just hit it with noise. And then we just keep hitting it with noise and we create this train of noised up images. It's very easy to create noisy images, right? It's hard to walk backwards and create from noise images of you or Gary. And so then we flip it and then we try to teach the model to reverse that process. And that's basically it.**

æˆ‘ä»¬å–ä¸€äº›æ•°æ®æ ·æœ¬ï¼Œæ¯”å¦‚ä¸€å¼  **Anka** çš„å›¾ç‰‡ã€ä¸€å¼  **Gary** çš„å›¾ç‰‡ï¼Œç„¶åå¾€ä¸Šé¢åŠ å™ªå£°ã€‚æˆ‘ä»¬ä¸æ–­åŠ å™ªå£°ï¼Œåˆ›å»ºå‡ºä¸€ç³»åˆ—åŠ äº†å™ªå£°çš„å›¾ç‰‡ã€‚åˆ›å»ºå™ªå£°å›¾ç‰‡å¾ˆå®¹æ˜“ï¼Œå¯¹å§ï¼Ÿä½†åè¿‡æ¥ä»å™ªå£°ä¸­ç”Ÿæˆå›¾ç‰‡å°±å¾ˆéš¾äº†ã€‚æ‰€ä»¥æˆ‘ä»¬æŠŠè¿‡ç¨‹åè¿‡æ¥ï¼Œè®©æ¨¡å‹å­¦ä¼šé€†è½¬è¿™ä¸ªè¿‡ç¨‹ã€‚åŸºæœ¬ä¸Šå°±æ˜¯è¿™æ ·ã€‚

è§£æï¼š
* **hit it with noise** ğŸ”¥ï¼šå¾€ä¸Šé¢åŠ å™ªå£°ï¼ˆå½¢è±¡è¯´æ³•ï¼‰
* **a train of**ï¼šä¸€ç³»åˆ—ã€ä¸€è¿ä¸²
* **flip it** ğŸ”¥ï¼šåè½¬å®ƒ

---

(9) [2:32-2:53] **Okay, cool. So it's basically a noiser and a denoiser and the denoiser is the model that you end up training. Exactly. You will basically teach your force and give it noised up images and then have it learn intermediate representations to get back to P data. Cool. Nice. And what kinds of stuff is diffusion used for today? What are some applications that it's widely deployed in?**

å¥½çš„ï¼Œé…·ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šå°±æ˜¯ä¸€ä¸ª"åŠ å™ªå™¨"å’Œä¸€ä¸ª"å»å™ªå™¨"ï¼Œå»å™ªå™¨å°±æ˜¯ä½ æœ€ç»ˆè®­ç»ƒçš„æ¨¡å‹ã€‚æ²¡é”™ã€‚ä½ åŸºæœ¬ä¸Šå°±æ˜¯ç»™å®ƒåŠ å™ªçš„å›¾ç‰‡ï¼Œè®©å®ƒå­¦ä¹ ä¸­é—´è¡¨ç¤ºï¼Œç„¶åå›åˆ°åŸå§‹æ•°æ®åˆ†å¸ƒã€‚é…·ï¼Œä¸é”™ã€‚é‚£æ‰©æ•£æ¨¡å‹ç°åœ¨éƒ½ç”¨åœ¨å“ªäº›åœ°æ–¹ï¼Ÿæœ‰å“ªäº›å¹¿æ³›éƒ¨ç½²çš„åº”ç”¨ï¼Ÿ

è§£æï¼š
* **denoiser**ï¼šå»å™ªå™¨ï¼ˆå»å™ªæ¨¡å‹ï¼‰
* **intermediate representations** ğŸ”¥ï¼šä¸­é—´è¡¨ç¤ºï¼ˆæ·±åº¦å­¦ä¹ æœ¯è¯­ï¼‰

---

(10) [2:53-3:18] **It's honestly surprising how applicable this process is. I think the original 2015 Joshua Sohl-Dickstein paper was on CIFAR-10 which is just images. And I think it's got its roots in images, but it is far more sprawling than just images. As you've seen, Deep Mind just won the Nobel Prize for doing this exact procedure on protein folding.**

è¯´å®è¯ï¼Œè¿™ä¸ªæŠ€æœ¯çš„é€‚ç”¨æ€§ä»¤äººæƒŠè®¶ã€‚æˆ‘è§‰å¾— 2015 å¹´ **Joshua Sohl-Dickstein** çš„åŸå§‹è®ºæ–‡æ˜¯åœ¨ **CIFAR-10** ä¸Šåšçš„ï¼Œåªæ˜¯å›¾ç‰‡ã€‚å®ƒèµ·æºäºå›¾åƒï¼Œä½†ç°åœ¨çš„åº”ç”¨èŒƒå›´è¿œä¸æ­¢å›¾åƒã€‚æ­£å¦‚ä½ çœ‹åˆ°çš„ï¼Œ**DeepMind** åˆšåˆšå› ä¸ºå°†è¿™ä¸ªæ–¹æ³•ç”¨äºè›‹ç™½è´¨æŠ˜å è€Œè·å¾—è¯ºè´å°”å¥–ã€‚

è§£æï¼š
* **applicable** ğŸ”¥ï¼šå¯åº”ç”¨çš„ã€é€‚ç”¨çš„
* **has its roots in** ğŸ”¥ï¼šèµ·æºäºã€æ ¹æ¤äº
* **sprawling**ï¼šè”“å»¶çš„ã€æ‰©å±•çš„
* **protein folding**ï¼šè›‹ç™½è´¨æŠ˜å 

---

(11) [3:18-3:44] **You can drive cars with this with the diffusion policy paper, which is like an insane result. You can predict the weather. There's really no limit to the things that this can do. Yeah, it's pretty incredible to see. I mean we have these image and video generation models that seem to be really advancing over the last few years. Stable diffusion is the one that I think many people have heard of.**

ä½ å¯ä»¥ç”¨æ‰©æ•£ç­–ç•¥è®ºæ–‡é‡Œçš„æ–¹æ³•æ¥é©¾é©¶æ±½è½¦ï¼Œè¿™æ˜¯ä¸€ä¸ªç–¯ç‹‚çš„ç»“æœã€‚ä½ è¿˜å¯ä»¥é¢„æµ‹å¤©æ°”ã€‚è¿™ä¸ªæŠ€æœ¯èƒ½åšçš„äº‹æƒ…çœŸçš„æ²¡æœ‰é™åˆ¶ã€‚æ˜¯çš„ï¼Œçœ‹åˆ°è¿™äº›çœŸçš„å¾ˆä¸å¯æ€è®®ã€‚æˆ‘ä»¬æœ‰è¿™äº›å›¾åƒå’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œè¿‡å»å‡ å¹´ä¸€ç›´åœ¨å¿«é€Ÿè¿›æ­¥ã€‚**Stable Diffusion** æ˜¯å¾ˆå¤šäººå¬è¯´è¿‡çš„ã€‚

è§£æï¼š
* **diffusion policy paper**ï¼šæ‰©æ•£ç­–ç•¥è®ºæ–‡ï¼ˆæœºå™¨äººæ§åˆ¶é¢†åŸŸï¼‰
* **insane result** ğŸ”¥ï¼šç–¯ç‹‚çš„ç»“æœï¼ˆä»¤äººéš¾ä»¥ç½®ä¿¡çš„å¥½ï¼‰
* **there's no limit to**ï¼š...æ²¡æœ‰é™åˆ¶

---

(12) [3:41-4:05] **And then newer versions of it seem to be using this as well. And then yeah in the world of life sciences that my company was in too. I think we see this newest generation of life sciences AI companies are heavily investing in this set of technologies. There's a model called DiffDock that works really well for predicting small molecule binding to proteins and then yeah AlphaFold especially the newest AlphaFold versions use diffusion pretty heavily. It's really cool to see the same core piece of technology apply to so many different domains.**

å®ƒçš„æ–°ç‰ˆæœ¬ä¹Ÿåœ¨ä½¿ç”¨è¿™é¡¹æŠ€æœ¯ã€‚åœ¨æˆ‘å…¬å¸æ‰€åœ¨çš„ç”Ÿå‘½ç§‘å­¦é¢†åŸŸä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬çœ‹åˆ°æœ€æ–°ä¸€ä»£çš„ç”Ÿå‘½ç§‘å­¦ AI å…¬å¸æ­£åœ¨å¤§åŠ›æŠ•èµ„è¿™äº›æŠ€æœ¯ã€‚æœ‰ä¸ªå« **DiffDock** çš„æ¨¡å‹ï¼Œåœ¨é¢„æµ‹å°åˆ†å­ä¸è›‹ç™½è´¨ç»“åˆæ–¹é¢æ•ˆæœéå¸¸å¥½ã€‚**AlphaFold** å°¤å…¶æ˜¯æœ€æ–°ç‰ˆæœ¬å¤§é‡ä½¿ç”¨äº†æ‰©æ•£æ¨¡å‹ã€‚çœ‹åˆ°åŒæ ·çš„æ ¸å¿ƒæŠ€æœ¯åº”ç”¨äºè¿™ä¹ˆå¤šä¸åŒé¢†åŸŸï¼ŒçœŸçš„å¾ˆé…·ã€‚

è§£æï¼š
* **life sciences**ï¼šç”Ÿå‘½ç§‘å­¦
* **heavily investing in** ğŸ”¥ï¼šå¤§åŠ›æŠ•èµ„äº
* **small molecule binding to proteins**ï¼šå°åˆ†å­ä¸è›‹ç™½è´¨çš„ç»“åˆ

---

(13) [4:06-4:33] **This class of models has evolved over the years and there's a whole slew of papers someone could read. So you should probably go read the papers to learn all the details. But maybe at a high level we can try to trace out a few of the key innovations that happened starting with the paper you already mentioned that now led to the newest versions of these models. So how would you map those out? Like what was the first kind of turn of the crank from this very high level diffusion process you outlined, what was the first version of that that started to work?**

è¿™ç±»æ¨¡å‹è¿™äº›å¹´ä¸€ç›´åœ¨æ¼”è¿›ï¼Œæœ‰ä¸€å¤§å †è®ºæ–‡å¯ä»¥è¯»ã€‚å¦‚æœæƒ³äº†è§£æ‰€æœ‰ç»†èŠ‚ï¼Œä½ åº”è¯¥å»è¯»é‚£äº›è®ºæ–‡ã€‚ä½†ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œæˆ‘ä»¬å¯ä»¥å°è¯•æ¢³ç†ä¸€ä¸‹ä»ä½ æåˆ°çš„é‚£ç¯‡è®ºæ–‡å¼€å§‹çš„å‡ ä¸ªå…³é”®åˆ›æ–°ã€‚ä½ ä¼šæ€ä¹ˆæ¢³ç†è¿™äº›å‘¢ï¼Ÿä»ä½ æè¿°çš„é«˜å±‚æ¬¡æ‰©æ•£è¿‡ç¨‹åˆ°ç¬¬ä¸€ä¸ªèƒ½ç”¨çš„ç‰ˆæœ¬ï¼Œç¬¬ä¸€ä¸ªè½¬æŠ˜ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ

è§£æï¼š
* **a whole slew of** ğŸ”¥ï¼šä¸€å¤§å †ã€å¾ˆå¤š
* **trace out**ï¼šæ¢³ç†ã€è¿½æº¯
* **turn of the crank** ğŸ”¥ï¼šè½¬ä¸€ä¸‹æ›²æŸ„ï¼ˆæ¯”å–»ä¸€æ¬¡è¿­ä»£æ”¹è¿›ï¼‰

---

(14) [4:33-4:56] **Yeah so I think that the 2015 original Joshua paper put up all the key pieces, all the key components of modern diffusion. And so now we're just playing with different things. So the scheduler, how do we add noise at what weight, that's a whole part that we can discuss. What's the loss function? Should the deep learning model condition upon x of t predict the actual data x of t minus one or should it predict the error that was just added to it?**

æ˜¯çš„ï¼Œæˆ‘è®¤ä¸º 2015 å¹´ **Joshua** çš„åŸå§‹è®ºæ–‡å·²ç»æå‡ºäº†ç°ä»£æ‰©æ•£æ¨¡å‹çš„æ‰€æœ‰å…³é”®ç»„ä»¶ï¼Œæ‰€ä»¥ç°åœ¨æˆ‘ä»¬åªæ˜¯åœ¨ç©å„ç§å˜ä½“ã€‚æ¯”å¦‚è°ƒåº¦å™¨â€”â€”ä»¥ä»€ä¹ˆæƒé‡æ·»åŠ å™ªå£°ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯ä»¥è®¨è®ºçš„éƒ¨åˆ†ã€‚æŸå¤±å‡½æ•°æ˜¯ä»€ä¹ˆï¼Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ç»™å®š x(t) çš„æ¡ä»¶ä¸‹ï¼Œåº”è¯¥é¢„æµ‹å®é™…æ•°æ® x(t-1)ï¼Œè¿˜æ˜¯é¢„æµ‹åˆšåŠ ä¸Šå»çš„è¯¯å·®ï¼Ÿ

è§£æï¼š
* **put up**ï¼šæå‡ºã€å»ºç«‹
* **scheduler**ï¼šè°ƒåº¦å™¨ï¼ˆæ§åˆ¶å™ªå£°æ·»åŠ çš„ç»„ä»¶ï¼‰
* **loss function** ğŸ”¥ï¼šæŸå¤±å‡½æ•°
* **condition upon**ï¼šä»¥...ä¸ºæ¡ä»¶

---

(15) [4:56-5:18] **Or should it predict the velocity which is the error divided by the time? Should it predict the velocity of the start and the end, that's called flow matching. There's all these different plays on what the loss function is. So in all of those the idea is still to do denoising. Yes. But the objective for each of them is somewhat different from each other and they're all pretty closely related.**

è¿˜æ˜¯åº”è¯¥é¢„æµ‹é€Ÿåº¦ï¼ˆè¯¯å·®é™¤ä»¥æ—¶é—´ï¼‰ï¼Ÿè¿˜æ˜¯åº”è¯¥é¢„æµ‹èµ·ç‚¹å’Œç»ˆç‚¹çš„é€Ÿåº¦â€”â€”è¿™å«åšæµåŒ¹é…ã€‚æŸå¤±å‡½æ•°æœ‰å¾ˆå¤šä¸åŒçš„ç©æ³•ã€‚æ‰€ä»¥åœ¨æ‰€æœ‰è¿™äº›æ–¹æ³•ä¸­ï¼Œæ ¸å¿ƒæ€æƒ³ä»ç„¶æ˜¯å»å™ªã€‚æ˜¯çš„ã€‚ä½†æ¯ç§æ–¹æ³•çš„ç›®æ ‡éƒ½ç•¥æœ‰ä¸åŒï¼Œå®ƒä»¬éƒ½éå¸¸ç›¸å…³ã€‚

è§£æï¼š
* **velocity**ï¼šé€Ÿåº¦
* **flow matching**ï¼šæµåŒ¹é…ï¼ˆä¸€ç§æ‰©æ•£æ¨¡å‹å˜ä½“ï¼‰
* **plays on** ğŸ”¥ï¼šåœ¨...ä¸Šçš„ç©æ³•/å˜ä½“
* **somewhat different**ï¼šç•¥æœ‰ä¸åŒ

---

(16) [5:18-5:55] **Whether it's basically a delta between two things or the previous step or the first step. How did these all actually come together? These are a series of papers that happened one after another. Yeah I think we just kind of hill climbed on this FrÃ©chet inception distance metric that's kind of a kooky weird measure to see how good an image is. But we just kept getting better and better on it by doing these little tricks.**

æ— è®ºæ˜¯ä¸¤ä¸ªä¸œè¥¿ä¹‹é—´çš„å·®å€¼ï¼Œè¿˜æ˜¯å‰ä¸€æ­¥ï¼Œè¿˜æ˜¯ç¬¬ä¸€æ­¥ã€‚è¿™äº›æ˜¯æ€ä¹ˆç»“åˆåœ¨ä¸€èµ·çš„ï¼Ÿè¿™æ˜¯ä¸€ç³»åˆ—æ¥è¿å‘è¡¨çš„è®ºæ–‡ã€‚æ˜¯çš„ï¼Œæˆ‘è§‰å¾—æˆ‘ä»¬å°±æ˜¯åœ¨ **FID**ï¼ˆFrÃ©chet åˆå§‹è·ç¦»ï¼‰è¿™ä¸ªæŒ‡æ ‡ä¸Šçˆ¬å±±ä¼˜åŒ–ã€‚è¿™æ˜¯ä¸€ä¸ªæœ‰ç‚¹å¤æ€ªçš„è¡¡é‡å›¾åƒå¥½åçš„æ–¹æ³•ã€‚ä½†æˆ‘ä»¬é€šè¿‡è¿™äº›å°æŠ€å·§ä¸æ–­æ”¹è¿›ã€‚

è§£æï¼š
* **delta**ï¼šå·®å€¼ã€å˜åŒ–é‡
* **one after another** ğŸ”¥ï¼šæ¥è¿åœ°ã€ä¸€ä¸ªæ¥ä¸€ä¸ª
* **hill climbed** ğŸ”¥ï¼šçˆ¬å±±ä¼˜åŒ–ï¼ˆé€æ­¥æ”¹è¿›ï¼‰
* **FID**ï¼šè¯„ä¼°ç”Ÿæˆå›¾åƒè´¨é‡çš„æŒ‡æ ‡
* **kooky**ï¼šå¤æ€ªçš„ã€å¥‡ç‰¹çš„

---

(17) [5:46-6:08] **And so it turns out that predicting the actual data itself is actually quite hard and maybe predicting the error is actually easier. And predicting the velocity was even easier than that. And then predicting the global error across the entire diffusion schedule is even easier than that. And we just kept finding easier and easier ways to basically sample from noise to data.**

ç»“æœå‘ç°ï¼Œé¢„æµ‹å®é™…æ•°æ®æœ¬èº«å…¶å®å¾ˆéš¾ï¼Œé¢„æµ‹è¯¯å·®å¯èƒ½æ›´å®¹æ˜“ï¼Œé¢„æµ‹é€Ÿåº¦æ¯”é‚£è¿˜å®¹æ˜“ï¼Œé¢„æµ‹æ•´ä¸ªæ‰©æ•£è°ƒåº¦è¿‡ç¨‹ä¸­çš„å…¨å±€è¯¯å·®å°±æ›´å®¹æ˜“äº†ã€‚æˆ‘ä»¬å°±è¿™æ ·ä¸æ–­æ‰¾åˆ°è¶Šæ¥è¶Šç®€å•çš„æ–¹æ³•ï¼Œä»å™ªå£°é‡‡æ ·ç”Ÿæˆæ•°æ®ã€‚

è§£æï¼š
* **it turns out that** ğŸ”¥ï¼šç»“æœå‘ç°ã€åŸæ¥
* **global error**ï¼šå…¨å±€è¯¯å·®
* **diffusion schedule**ï¼šæ‰©æ•£è°ƒåº¦

---

(18) [6:09-6:42] **And here when you say easier, was the ease largely driven by it was mathematically simpler or it was easier to implement and engineer or simpler to reason about? It actually is that too, but I didn't mean it that way. What I actually meant was it's easier for the model to learn. But it is also, and we'll go through some coding examples, the math actually got easier. And the code got smaller, which is actually oppositely true in most of the case of most machine learning. Things usually get more complicated.**

å½“ä½ è¯´"æ›´å®¹æ˜“"æ—¶ï¼Œè¿™ç§å®¹æ˜“ä¸»è¦æ˜¯å› ä¸ºæ•°å­¦ä¸Šæ›´ç®€å•ï¼Œè¿˜æ˜¯å®ç°å’Œå·¥ç¨‹ä¸Šæ›´å®¹æ˜“ï¼Œè¿˜æ˜¯æ›´å®¹æ˜“ç†è§£ï¼Ÿå…¶å®è¿™äº›éƒ½å¯¹ï¼Œä½†æˆ‘ä¸æ˜¯é‚£ä¸ªæ„æ€ã€‚æˆ‘çœŸæ­£çš„æ„æ€æ˜¯æ¨¡å‹æ›´å®¹æ˜“å­¦ä¹ äº†ã€‚ä½†ç¡®å®ï¼Œæ•°å­¦ä¹Ÿå˜ç®€å•äº†â€”â€”æˆ‘ä»¬ä¸€ä¼šå„¿ä¼šçœ‹ä»£ç ç¤ºä¾‹ã€‚ä»£ç ä¹Ÿå˜çŸ­äº†ï¼Œè¿™åœ¨å¤§å¤šæ•°æœºå™¨å­¦ä¹ é¢†åŸŸå…¶å®æ˜¯ç›¸åçš„â€”â€”é€šå¸¸ä¸œè¥¿ä¼šå˜å¾—æ›´å¤æ‚ã€‚

è§£æï¼š
* **the ease**ï¼šè¿™ç§å®¹æ˜“
* **largely driven by**ï¼šä¸»è¦ç”±...é©±åŠ¨
* **reason about** ğŸ”¥ï¼šæ¨ç†ã€æ€è€ƒ
* **oppositely true**ï¼šç›¸åçš„æƒ…å†µ

---

(19) [6:42-7:08] **I think we started with U-Nets and that was like the predominant architecture. We didn't really talk about architectures that much, but then we got into these diffusion transformers and like this cross attention mechanism and things like that. And so, yeah, we just kept getting better and better at reducing FID. Interesting. Should we dive into some code examples? Let's do it. I'll walk you through.**

æˆ‘è§‰å¾—æˆ‘ä»¬æœ€å¼€å§‹ç”¨çš„æ˜¯ **U-Net**ï¼Œé‚£æ˜¯ä¸»æµæ¶æ„ã€‚æˆ‘ä»¬æ²¡æ€ä¹ˆè®¨è®ºæ¶æ„ï¼Œä½†åæ¥æœ‰äº†æ‰©æ•£ **Transformer**ï¼Œè¿˜æœ‰äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¹‹ç±»çš„ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å°±è¿™æ ·åœ¨é™ä½ **FID** ä¸Šè¶Šæ¥è¶Šå¥½ã€‚æœ‰æ„æ€ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹ä»£ç ç¤ºä¾‹å§ï¼Ÿå¼€å§‹å§ã€‚æˆ‘æ¥å¸¦ä½ çœ‹ä¸€ä¸‹ã€‚

è§£æï¼š
* **U-Net**ï¼šä¸€ç§å¸¸ç”¨äºæ‰©æ•£æ¨¡å‹çš„ CNN æ¶æ„
* **predominant**ï¼šä¸»è¦çš„ã€å ä¸»å¯¼åœ°ä½çš„
* **cross attention mechanism**ï¼šäº¤å‰æ³¨æ„åŠ›æœºåˆ¶
* **dive into** ğŸ”¥ï¼šæ·±å…¥ç ”ç©¶

---

(20) [7:03-7:35] **I made about seven of these that I implemented with varying levels of success, but the structures are going to be the same. So the Joshua paper, the non-equilibrium thermodynamics paper, you can see here are some nice images of Gary. This is what I could find online. So those are images of Gary that you've downsampled so that they're smaller. These are 64 by 64. Yeah, they're really small. This is just a very small example.**

æˆ‘å®ç°äº†å¤§æ¦‚ä¸ƒä¸ªç‰ˆæœ¬ï¼ŒæˆåŠŸç¨‹åº¦å„æœ‰ä¸åŒï¼Œä½†ç»“æ„éƒ½æ˜¯ä¸€æ ·çš„ã€‚è¿™æ˜¯ **Joshua** çš„è®ºæ–‡ï¼Œéå¹³è¡¡çƒ­åŠ›å­¦è®ºæ–‡ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œæœ‰ä¸€äº› **Gary** çš„æ¼‚äº®å›¾ç‰‡ï¼Œè¿™æ˜¯æˆ‘åœ¨ç½‘ä¸Šèƒ½æ‰¾åˆ°çš„ã€‚è¿™äº›æ˜¯ä½ ä¸‹é‡‡æ ·åçš„å›¾ç‰‡ï¼Œå˜å¾—æ›´å°äº†ã€‚è¿™äº›æ˜¯ 64Ã—64 çš„ã€‚æ˜¯çš„ï¼Œéå¸¸å°ã€‚è¿™åªæ˜¯ä¸€ä¸ªå¾ˆå°çš„ä¾‹å­ã€‚

è§£æï¼š
* **varying levels of success**ï¼šä¸åŒç¨‹åº¦çš„æˆåŠŸ
* **non-equilibrium thermodynamics**ï¼šéå¹³è¡¡çƒ­åŠ›å­¦
* **downsampled**ï¼šä¸‹é‡‡æ ·ï¼ˆé™ä½åˆ†è¾¨ç‡ï¼‰

---

(21) [7:35-8:02] **64 and then I randomly augment it to create more data. Great. Because I was lazy and that was easier than downloading more images. Didn't want to get security called on you. Exactly. So, I implemented this diffusion schedule and this is probably one of the most important parts of diffusion that's difficult to comprehend. I would say that the noise schedule is actually the hardest part to understand that I really struggled with myself.**

64ï¼Œç„¶åæˆ‘éšæœºå¢å¼ºæ¥åˆ›å»ºæ›´å¤šæ•°æ®ã€‚å¾ˆå¥½ã€‚å› ä¸ºæˆ‘æ‡’ï¼Œè¿™æ¯”ä¸‹è½½æ›´å¤šå›¾ç‰‡å®¹æ˜“ã€‚ä¸æƒ³è®©å®‰ä¿æ‰¾ä¸Šä½ ã€‚æ²¡é”™ã€‚ç„¶åæˆ‘å®ç°äº†è¿™ä¸ªæ‰©æ•£è°ƒåº¦ï¼Œè¿™å¯èƒ½æ˜¯æ‰©æ•£æ¨¡å‹ä¸­æœ€é‡è¦ä½†æœ€éš¾ç†è§£çš„éƒ¨åˆ†ä¹‹ä¸€ã€‚æˆ‘è§‰å¾—å™ªå£°è°ƒåº¦å…¶å®æ˜¯æœ€éš¾ç†è§£çš„éƒ¨åˆ†ï¼Œæˆ‘è‡ªå·±ä¹Ÿå¾ˆæŒ£æ‰ã€‚

è§£æï¼š
* **randomly augment** ğŸ”¥ï¼šéšæœºå¢å¼ºï¼ˆæ•°æ®å¢å¼ºæŠ€æœ¯ï¼‰
* **get security called on you**ï¼šè®©å®‰ä¿æ¥æ‰¾ä½ ï¼ˆå¼€ç©ç¬‘ï¼‰
* **noise schedule** ğŸ”¥ï¼šå™ªå£°è°ƒåº¦

---

(22) [8:02-8:26] **And so if you can see here the noise that's added from time step zero to t to 10 to 25 all the way to 100 is clearly destroying the structure. Yes. And then we want to train where you end is basically random static. Exactly. And we want to basically reverse this and from here get to here and have the model get to that point, get to this point, etc.**

ä½ å¯ä»¥çœ‹åˆ°ï¼Œä»æ—¶é—´æ­¥ 0 åˆ° tã€åˆ° 10ã€åˆ° 25ã€ä¸€ç›´åˆ° 100ï¼Œæ·»åŠ çš„å™ªå£°æ˜æ˜¾åœ¨ç ´åå›¾åƒç»“æ„ã€‚æ˜¯çš„ã€‚æˆ‘ä»¬å¸Œæœ›è®­ç»ƒçš„ç»ˆç‚¹åŸºæœ¬ä¸Šæ˜¯éšæœºé™æ€å™ªå£°ã€‚æ²¡é”™ã€‚æˆ‘ä»¬åŸºæœ¬ä¸Šæƒ³è¦é€†è½¬è¿™ä¸ªè¿‡ç¨‹ï¼Œä»è¿™é‡Œåˆ°è¿™é‡Œï¼Œè®©æ¨¡å‹åˆ°è¾¾é‚£ä¸ªç‚¹ã€è¿™ä¸ªç‚¹ï¼Œç­‰ç­‰ã€‚

è§£æï¼š
* **random static**ï¼šéšæœºé™æ€å™ªå£°ï¼ˆåƒç”µè§†é›ªèŠ±ï¼‰
* **reverse this**ï¼šé€†è½¬è¿™ä¸ª

---

(23) [8:26-8:57] **And so, the interesting part, and this is Joshua really implemented almost everything that we needed for diffusion. And there was just a few little tweaks that were missing, and he didn't scale it up. That's to me the parts that were missing. And if you see here the noise schedule. So it would make sense to me that I would have linear interpolation between the image and the noise and I would start with like one and zero, one being the image and zero being the noise. You gradually add it.**

æœ‰è¶£çš„æ˜¯ï¼Œ**Joshua** çœŸçš„å®ç°äº†æ‰©æ•£æ‰€éœ€çš„å‡ ä¹æ‰€æœ‰ä¸œè¥¿ï¼Œåªç¼ºå°‘ä¸€äº›å°è°ƒæ•´ï¼Œè€Œä¸”ä»–æ²¡æœ‰æŠŠå®ƒè§„æ¨¡åŒ–ã€‚å¯¹æˆ‘æ¥è¯´ï¼Œè¿™å°±æ˜¯ç¼ºå¤±çš„éƒ¨åˆ†ã€‚çœ‹è¿™é‡Œçš„å™ªå£°è°ƒåº¦ã€‚æˆ‘è§‰å¾—åœ¨å›¾åƒå’Œå™ªå£°ä¹‹é—´åšçº¿æ€§æ’å€¼æ˜¯åˆç†çš„ï¼Œä» 1 å’Œ 0 å¼€å§‹ï¼Œ1 ä»£è¡¨å›¾åƒï¼Œ0 ä»£è¡¨å™ªå£°ã€‚ä½ é€æ¸æ·»åŠ ã€‚

è§£æï¼š
* **tweaks** ğŸ”¥ï¼šå°è°ƒæ•´ã€å¾®è°ƒ
* **scale it up**ï¼šè§„æ¨¡åŒ–ã€æ”¾å¤§
* **linear interpolation**ï¼šçº¿æ€§æ’å€¼

---

(24) [8:55-9:23] **But if you do that it actually is massively unstable because the instantaneous amount of error that you're adding is very small in the beginning. If you think about like an image on a relative basis. On a relative basis and then at the end you have to destroy all the image, to get to complete noise you need to add a lot of error. And so if you're a model and you're just looking at this little chunk of the noise schedule then you have to handle a lot of error in one step.**

ä½†å¦‚æœä½ è¿™æ ·åšï¼Œå®é™…ä¸Šä¼šéå¸¸ä¸ç¨³å®šï¼Œå› ä¸ºä¸€å¼€å§‹ä½ æ·»åŠ çš„ç¬æ—¶è¯¯å·®é‡éå¸¸å°ã€‚ä»ç›¸å¯¹è§’åº¦æ¥æƒ³è±¡ä¸€å¼ å›¾ç‰‡ã€‚ä»ç›¸å¯¹è§’åº¦çœ‹ï¼Œåˆ°æœ€åä½ è¦å½»åº•ç ´åå›¾åƒå˜æˆå™ªå£°ï¼Œéœ€è¦æ·»åŠ å¤§é‡è¯¯å·®ã€‚æ‰€ä»¥å¦‚æœä½ æ˜¯ä¸€ä¸ªæ¨¡å‹ï¼Œåªçœ‹å™ªå£°è°ƒåº¦çš„è¿™ä¸€å°å—ï¼Œä½ éœ€è¦åœ¨ä¸€æ­¥ä¸­å¤„ç†å¤§é‡è¯¯å·®ã€‚

è§£æï¼š
* **massively unstable**ï¼šéå¸¸ä¸ç¨³å®š
* **instantaneous**ï¼šç¬æ—¶çš„ã€å³æ—¶çš„
* **on a relative basis** ğŸ”¥ï¼šä»ç›¸å¯¹è§’åº¦

---

(25) [9:23-10:31] **And on this side of the schedule you need to handle such small amounts of error. And what you actually want is relatively constant amount of error being introduced every single time step, and the cumulative sum of all that error actually ends up looking like this curve here. That's the pink curve. Yeah. And so they call this a beta schedule. Beta is the diffusion rate, the rate of diffusion that I'm doing while I'm rolling this thing out from time zero to time T. And so you can see here the beta schedule. We usually have some beta min to beta max and then one minus that is the alpha. You can think about the beta as how much noise I'm adding at every time step. And you think about the alpha as how much is being retained. And then the term that really matters is the alpha bar and these are the weights that are used and it has this kind of like one minus sigmoid looking thing.**

è€Œåœ¨è°ƒåº¦çš„å¦ä¸€ä¾§ï¼Œä½ åªéœ€è¦å¤„ç†å¾ˆå°‘çš„è¯¯å·®ã€‚ä½ çœŸæ­£æƒ³è¦çš„æ˜¯æ¯ä¸ªæ—¶é—´æ­¥å¼•å…¥ç›¸å¯¹æ’å®šçš„è¯¯å·®é‡ï¼Œæ‰€æœ‰è¯¯å·®çš„ç´¯ç§¯å’Œæœ€ç»ˆçœ‹èµ·æ¥åƒè¿™æ¡æ›²çº¿ã€‚é‚£æ˜¯ç²‰è‰²æ›²çº¿ã€‚æ˜¯çš„ã€‚æ‰€ä»¥ä»–ä»¬ç§°ä¹‹ä¸º **beta** è°ƒåº¦ã€‚**Beta** æ˜¯æ‰©æ•£é€Ÿç‡ï¼Œæ˜¯æˆ‘ä»æ—¶é—´ 0 åˆ°æ—¶é—´ T å±•å¼€è¿™ä¸ªè¿‡ç¨‹æ—¶çš„æ‰©æ•£é€Ÿç‡ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œçš„ **beta** è°ƒåº¦ã€‚æˆ‘ä»¬é€šå¸¸æœ‰ä¸€ä¸ª **beta_min** åˆ° **beta_max**ï¼Œç„¶å 1 å‡å»å®ƒå°±æ˜¯ **alpha**ã€‚ä½ å¯ä»¥æŠŠ **beta** ç†è§£ä¸ºæ¯ä¸ªæ—¶é—´æ­¥æ·»åŠ å¤šå°‘å™ªå£°ã€‚**Alpha** æ˜¯ä¿ç•™äº†å¤šå°‘ã€‚çœŸæ­£é‡è¦çš„é¡¹æ˜¯ **alpha_bar**ï¼Œè¿™äº›æ˜¯ä½¿ç”¨çš„æƒé‡ï¼Œå®ƒçœ‹èµ·æ¥åƒ 1 å‡å» sigmoid çš„å½¢çŠ¶ã€‚

è§£æï¼š
* **cumulative sum**ï¼šç´¯ç§¯å’Œ
* **beta schedule** ğŸ”¥ï¼šbeta è°ƒåº¦ï¼ˆæ§åˆ¶å™ªå£°æ·»åŠ é€Ÿç‡ï¼‰
* **diffusion rate**ï¼šæ‰©æ•£é€Ÿç‡
* **alpha bar (á¾±)**ï¼šç´¯ç§¯ alphaï¼ˆæ‰€æœ‰æ—¶é—´æ­¥ alpha çš„ä¹˜ç§¯ï¼‰
* **one minus sigmoid**ï¼š1 å‡å» sigmoidï¼ˆS å½¢æ›²çº¿ï¼‰

---

## ğŸ“š æ®µè½å°ç»“

è¿™æ˜¯ä¸€æ®µå…³äº **Diffusionï¼ˆæ‰©æ•£æ¨¡å‹ï¼‰** çš„æŠ€æœ¯è®¿è°ˆã€‚ä¸»æŒäººå’Œ **Francois Shaard**ï¼ˆæ–¯å¦ç¦åšå£«ç”Ÿã€YC è®¿é—®åˆä¼™äººï¼‰è®¨è®ºäº†æ‰©æ•£æ¨¡å‹çš„åŸºæœ¬åŸç†ï¼šé€šè¿‡é€æ­¥å‘å›¾åƒæ·»åŠ å™ªå£°ï¼Œç„¶åè®­ç»ƒæ¨¡å‹é€†è½¬è¿™ä¸ªè¿‡ç¨‹æ¥ç”Ÿæˆæ–°å›¾åƒã€‚è®¿è°ˆè¿˜æ¶µç›–äº†æ‰©æ•£æ¨¡å‹çš„å¹¿æ³›åº”ç”¨ï¼ˆå›¾åƒç”Ÿæˆã€è›‹ç™½è´¨æŠ˜å ã€è‡ªåŠ¨é©¾é©¶ã€å¤©æ°”é¢„æµ‹ç­‰ï¼‰ã€å…³é”®æŠ€æœ¯æ¼”è¿›ï¼ˆæŸå¤±å‡½æ•°ã€æ¶æ„ã€å™ªå£°è°ƒåº¦ï¼‰ï¼Œä»¥åŠå™ªå£°è°ƒåº¦ï¼ˆbeta scheduleï¼‰çš„é‡è¦æ€§ã€‚

### ğŸ”¥ æ ¸å¿ƒè¯æ±‡è¡¨

| è¯æ±‡/çŸ­è¯­ | å«ä¹‰ |
|---------|------|
| **diffusion** | æ‰©æ•£ï¼ˆæ¨¡å‹åç§°æ¥æºäºç‰©ç†å­¦çš„æ‰©æ•£è¿‡ç¨‹ï¼‰ |
| **denoiser** | å»å™ªå™¨ï¼ˆæ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒç»„ä»¶ï¼‰ |
| **noise schedule / beta schedule** | å™ªå£°è°ƒåº¦ / beta è°ƒåº¦ |
| **low data regimes** | æ•°æ®é‡å°‘çš„åœºæ™¯ |
| **stands out** | è„±é¢–è€Œå‡ºã€ç‰¹åˆ«çªå‡º |
| **hill climb** | çˆ¬å±±ä¼˜åŒ– |
| **FID** | FrÃ©chet Inception Distanceï¼Œå›¾åƒè´¨é‡æŒ‡æ ‡ |
| **flow matching** | æµåŒ¹é…ï¼ˆæ‰©æ•£æ¨¡å‹å˜ä½“ï¼‰ |
| **intermediate representations** | ä¸­é—´è¡¨ç¤º |
| **walk through** | é€æ­¥è®²è§£ |
| **turn of the crank** | ä¸€æ¬¡è¿­ä»£æ”¹è¿› |
| **it turns out that** | ç»“æœå‘ç° |
| **dive into** | æ·±å…¥ç ”ç©¶ |
| **a whole slew of** | ä¸€å¤§å † |
| **on a relative basis** | ä»ç›¸å¯¹è§’åº¦çœ‹ |
