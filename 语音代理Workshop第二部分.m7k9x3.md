# ğŸ¯ Cerebras è¯­éŸ³ä»£ç† Workshopï¼ˆç¬¬äºŒéƒ¨åˆ†ï¼‰è‹±è¯­æ®µè½ç¿»è¯‘

æœ¬æ–‡å…± **27 ä¸ªè¯­ä¹‰å•å…ƒ**ï¼Œå°†å…¨éƒ¨ç¿»è¯‘ã€‚

---

(1) [10:35-10:46] **And so today we're going to be focusing on the sales agent use case. So, first let's talk about what's actually happening inside a voice agent when you're having a conversation and break it down.**

ä»Šå¤©æˆ‘ä»¬å°†ä¸“æ³¨äºé”€å”®ä»£ç†çš„ä½¿ç”¨åœºæ™¯ã€‚é¦–å…ˆï¼Œè®©æˆ‘ä»¬æ¥èŠèŠå½“ä½ å’Œè¯­éŸ³ä»£ç†å¯¹è¯æ—¶ï¼Œå®ƒå†…éƒ¨åˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼Œæˆ‘ä»¬æ¥æ‹†è§£ä¸€ä¸‹ã€‚

è§£æï¼š
* **use case** ğŸ”¥ï¼šåè¯ï¼Œä½¿ç”¨åœºæ™¯ã€ç”¨ä¾‹
* **break it down**ï¼šçŸ­è¯­ï¼Œæ‹†è§£ã€åˆ†è§£ï¼ˆæŠŠå¤æ‚äº‹ç‰©åˆ†æˆå°éƒ¨åˆ†è§£é‡Šï¼‰

---

(2) [10:46-11:04] **Yeah. So, you guys can see on this diagram on the right, once speech is detected, the voice data is forwarded to STT or that's called speech to text. This listens and converts your words to text in real time. And the last step in this process is end of utterance um or end of turn detection.**

å¥½çš„ã€‚å¤§å®¶å¯ä»¥çœ‹å³è¾¹è¿™å¼ å›¾ï¼Œä¸€æ—¦æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯­éŸ³æ•°æ®å°±ä¼šè¢«è½¬å‘åˆ° **STT**ï¼ˆä¹Ÿå°±æ˜¯è¯­éŸ³è½¬æ–‡å­—ï¼‰ã€‚å®ƒä¼šç›‘å¬å¹¶å®æ—¶å°†ä½ çš„è¯è½¬æ¢æˆæ–‡å­—ã€‚è¿™ä¸ªè¿‡ç¨‹çš„æœ€åä¸€æ­¥æ˜¯ã€Œè¯è¯­ç»“æŸã€æˆ–ã€Œè½®æ¬¡ç»“æŸã€æ£€æµ‹ã€‚

è§£æï¼š
* **diagram**ï¼šåè¯ï¼Œå›¾è¡¨ã€ç¤ºæ„å›¾
* **forward**ï¼šåŠ¨è¯ï¼Œè½¬å‘
* **STT (Speech to Text)**ï¼šè¯­éŸ³è½¬æ–‡å­—
* **utterance** ğŸ”¥ï¼šåè¯ï¼Œè¯è¯­ã€å‘è¨€ï¼ˆè¯­éŸ³å¤„ç†æœ¯è¯­ï¼‰
* **end of turn detection**ï¼šè½®æ¬¡ç»“æŸæ£€æµ‹ï¼ˆåˆ¤æ–­ç”¨æˆ·æ˜¯å¦è¯´å®Œï¼‰

---

(3) [11:04-11:31] **Um being interrupted by AI every time you pause. It's like very annoying. So, while VAD can help the system know when you are and you aren't speaking, it's also very important to analyze like what you're saying, the context of your speech, and to predict like whether you've done sharing your thoughts. So, we have another smaller model here that runs quickly on the CPU, which will instruct the system to wait if it predicts you're still speaking.**

æ¯æ¬¡ä½ åœé¡¿ä¸€ä¸‹å°±è¢« AI æ‰“æ–­ï¼ŒçœŸçš„å¾ˆçƒ¦äººã€‚æ‰€ä»¥è™½ç„¶ **VAD** å¯ä»¥å¸®åŠ©ç³»ç»ŸçŸ¥é“ä½ ä»€ä¹ˆæ—¶å€™åœ¨è¯´è¯ã€ä»€ä¹ˆæ—¶å€™æ²¡æœ‰ï¼Œä½†åŒæ ·é‡è¦çš„æ˜¯è¦åˆ†æä½ åœ¨è¯´ä»€ä¹ˆã€ä½ è¯´è¯çš„ä¸Šä¸‹æ–‡ï¼Œä»¥åŠé¢„æµ‹ä½ æ˜¯å¦å·²ç»è¡¨è¾¾å®Œæƒ³æ³•ã€‚æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œæœ‰å¦ä¸€ä¸ªæ›´å°çš„æ¨¡å‹ï¼Œåœ¨ CPU ä¸Šå¿«é€Ÿè¿è¡Œï¼Œå¦‚æœå®ƒé¢„æµ‹ä½ è¿˜åœ¨è¯´è¯ï¼Œå°±ä¼šæŒ‡ç¤ºç³»ç»Ÿç­‰å¾…ã€‚

è§£æï¼š
* **VAD (Voice Activity Detection)** ğŸ”¥ï¼šè¯­éŸ³æ´»åŠ¨æ£€æµ‹
* **annoying**ï¼šå½¢å®¹è¯ï¼Œçƒ¦äººçš„
* **context**ï¼šåè¯ï¼Œä¸Šä¸‹æ–‡ã€è¯­å¢ƒ
* **predict**ï¼šåŠ¨è¯ï¼Œé¢„æµ‹
* **instruct**ï¼šåŠ¨è¯ï¼ŒæŒ‡ç¤º

---

(4) [11:31-11:52] **So, once your turn is done, the final text transcription is forwarded to the next layer. And then after that phase, we have the thinking phase. So your entire question is now passed onto the large language model. Um, and this is basically, you know, the brain like understands what you're asking.**

ä¸€æ—¦ä½ çš„å‘è¨€ç»“æŸï¼Œæœ€ç»ˆçš„æ–‡å­—è½¬å½•å°±ä¼šè¢«è½¬å‘åˆ°ä¸‹ä¸€å±‚ã€‚åœ¨é‚£ä¸ªé˜¶æ®µä¹‹åï¼Œæˆ‘ä»¬è¿›å…¥æ€è€ƒé˜¶æ®µã€‚ä½ çš„æ•´ä¸ªé—®é¢˜ç°åœ¨è¢«ä¼ é€’ç»™å¤§è¯­è¨€æ¨¡å‹ã€‚è¿™åŸºæœ¬ä¸Šå°±åƒæ˜¯å¤§è„‘åœ¨ç†è§£ä½ åœ¨é—®ä»€ä¹ˆã€‚

è§£æï¼š
* **transcription**ï¼šåè¯ï¼Œè½¬å½•ã€æ–‡å­—è®°å½•
* **phase** ğŸ”¥ï¼šåè¯ï¼Œé˜¶æ®µ
* **large language model (LLM)**ï¼šå¤§è¯­è¨€æ¨¡å‹
* **pass onto**ï¼šä¼ é€’ç»™

---

(5) [11:51-12:04] **So it might need to look things up, which we'll walk through later. Um, like checking in this case, if we're doing a sales call, we'll want to pull additional context like documents, your other like more information about your company basically.**

æ‰€ä»¥å®ƒå¯èƒ½éœ€è¦æŸ¥æ‰¾ä¸€äº›ä¸œè¥¿ï¼Œæˆ‘ä»¬ç¨åä¼šè¯¦ç»†è®²ã€‚æ¯”å¦‚åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œå¦‚æœæˆ‘ä»¬åœ¨è¿›è¡Œé”€å”®é€šè¯ï¼Œæˆ‘ä»¬ä¼šæƒ³è¦æ‹‰å–é¢å¤–çš„ä¸Šä¸‹æ–‡ï¼Œæ¯”å¦‚æ–‡æ¡£ï¼Œæˆ–è€…æ›´å¤šå…³äºä½ å…¬å¸çš„ä¿¡æ¯ã€‚

è§£æï¼š
* **look things up**ï¼šçŸ­è¯­ï¼ŒæŸ¥æ‰¾ï¼ˆä¿¡æ¯ï¼‰
* **pull**ï¼šåŠ¨è¯ï¼Œæ‹‰å–ï¼ˆæ•°æ®ï¼‰
* **additional context**ï¼šé¢å¤–çš„ä¸Šä¸‹æ–‡

---

(6) [12:04-12:26] **Yeah. And then the third and the final step is the speaking phase. So as LLM streams response back to the agent, the agent will immediately start forwarding these LLM tokens to the TTS engine or text to speech. Um this generated audio from TTS streams back to your client's application in real time and that's why the agent can actually start responding when it's still thinking.**

ç„¶åç¬¬ä¸‰æ­¥ä¹Ÿæ˜¯æœ€åä¸€æ­¥æ˜¯è¯´è¯é˜¶æ®µã€‚å½“ **LLM** æŠŠå“åº”æµå¼ä¼ è¾“å›ä»£ç†æ—¶ï¼Œä»£ç†ä¼šç«‹å³å¼€å§‹å°†è¿™äº› **LLM** token è½¬å‘ç»™ **TTS** å¼•æ“ï¼ˆæ–‡å­—è½¬è¯­éŸ³ï¼‰ã€‚**TTS** ç”Ÿæˆçš„éŸ³é¢‘ä¼šå®æ—¶æµå¼ä¼ è¾“å›ä½ çš„å®¢æˆ·ç«¯åº”ç”¨ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»£ç†åœ¨è¿˜åœ¨æ€è€ƒçš„æ—¶å€™å°±èƒ½å¼€å§‹å›åº”äº†ã€‚

è§£æï¼š
* **stream**ï¼šåŠ¨è¯ï¼Œæµå¼ä¼ è¾“
* **TTS (Text to Speech)**ï¼šæ–‡å­—è½¬è¯­éŸ³
* **token**ï¼štoken/æ ‡è®°ï¼ˆLLM çš„æœ€å°è¾“å‡ºå•ä½ï¼‰
* **in real time**ï¼šå®æ—¶åœ°

---

(7) [12:26-12:52] **So the final result is that all of these components tied together is what's making, you know, an AI agent that feels very responsive, that feels very cohesive and immediate, even though there's a lot of complex processing happening behind the scenes. So there's a lot of moving pieces. In this case, we're going to be using LiveKit's agent SDK to handle all this orchestration for us.**

æ‰€ä»¥æœ€ç»ˆç»“æœæ˜¯ï¼Œæ‰€æœ‰è¿™äº›ç»„ä»¶ç»‘åœ¨ä¸€èµ·ï¼Œæ‰é€ å°±äº†ä¸€ä¸ªæ„Ÿè§‰éå¸¸å“åº”è¿…é€Ÿã€éå¸¸è¿è´¯å’Œå³æ—¶çš„ AI ä»£ç†ï¼Œå°½ç®¡å¹•åæœ‰å¤§é‡å¤æ‚çš„å¤„ç†åœ¨è¿›è¡Œã€‚æœ‰å¾ˆå¤šæ´»åŠ¨éƒ¨ä»¶ã€‚åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **LiveKit** çš„ **Agent SDK** æ¥å¸®æˆ‘ä»¬å¤„ç†æ‰€æœ‰è¿™äº›ç¼–æ’å·¥ä½œã€‚

è§£æï¼š
* **tied together**ï¼šç»‘åœ¨ä¸€èµ·ã€è¿æ¥åœ¨ä¸€èµ·
* **responsive** ğŸ”¥ï¼šå½¢å®¹è¯ï¼Œå“åº”è¿…é€Ÿçš„
* **cohesive**ï¼šå½¢å®¹è¯ï¼Œè¿è´¯çš„ã€æœ‰å‡èšåŠ›çš„
* **behind the scenes**ï¼šå¹•å
* **moving pieces**ï¼šæ´»åŠ¨éƒ¨ä»¶ï¼ˆæ¯”å–»å¤æ‚ç³»ç»Ÿä¸­çš„å„ä¸ªç»„æˆéƒ¨åˆ†ï¼‰
* **orchestration** ğŸ”¥ï¼šåè¯ï¼Œç¼–æ’ã€åè°ƒï¼ˆæŠ€æœ¯æœ¯è¯­ï¼‰

---

(8) [12:45-13:00] **Um, it's going to manage the audio streams, keep track of the context, and coordinate all these different AI services that we've just talked about. So, now that we have a little bit of context, um you can access the starter code here. We shared it already.**

å®ƒä¼šç®¡ç†éŸ³é¢‘æµã€è·Ÿè¸ªä¸Šä¸‹æ–‡ã€åè°ƒæˆ‘ä»¬åˆšæ‰è®¨è®ºçš„æ‰€æœ‰è¿™äº›ä¸åŒçš„ AI æœåŠ¡ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†ä¸€äº›èƒŒæ™¯çŸ¥è¯†ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œè®¿é—® starter codeï¼Œæˆ‘ä»¬å·²ç»åˆ†äº«è¿‡äº†ã€‚

è§£æï¼š
* **manage**ï¼šåŠ¨è¯ï¼Œç®¡ç†
* **keep track of**ï¼šè·Ÿè¸ªã€è®°å½•
* **coordinate**ï¼šåŠ¨è¯ï¼Œåè°ƒ

---

(9) [13:00-13:21] **And if you want to run the first section right here, it'll allow you to install all of the necessary packages. So, if you click on it, um you'll be able to see some of the output of the packages being downloaded. And so, this is going to use LiveKit agents with support for Cartisia, Silero for voice activity detection, and OpenAI compatibility.**

å¦‚æœä½ æƒ³è¿è¡Œè¿™é‡Œçš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå®ƒä¼šè®©ä½ å®‰è£…æ‰€æœ‰å¿…è¦çš„åŒ…ã€‚ç‚¹å‡»å®ƒï¼Œä½ å°±èƒ½çœ‹åˆ°åŒ…è¢«ä¸‹è½½çš„è¾“å‡ºã€‚è¿™å°†ä½¿ç”¨ **LiveKit agents**ï¼Œæ”¯æŒ **Cartisia**ã€ç”¨äºè¯­éŸ³æ´»åŠ¨æ£€æµ‹çš„ **Silero**ï¼Œä»¥åŠ **OpenAI** å…¼å®¹æ€§ã€‚

è§£æï¼š
* **packages**ï¼šè½¯ä»¶åŒ…
* **compatibility**ï¼šåè¯ï¼Œå…¼å®¹æ€§
* **Silero**ï¼šä¸€ä¸ªè½»é‡çº§çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹æ¨¡å‹

---

(10) [13:21-14:05] **And so we've very briefly talked about Cerebras. It is 50 times faster than GPUs. And um I'll skip here. And so as a final note, so for this workshop, we're actually going to be using Llama 3.3. And if you see in the chart on the bottom right, this is a chart from artificial analysis. Artificial analysis, if you're unfamiliar, is an independent benchmark that benchmarks a lot of different models, API providers, etc. um on intelligence, speed, latency, everything. And so you can see a comparison here of Cerebras on the very left in terms of tokens per second and any of your other providers like Nvidia.**

æˆ‘ä»¬ç®€å•è®²äº†ä¸€ä¸‹ **Cerebras**ï¼Œå®ƒæ¯” GPU å¿« 50 å€ã€‚è¿™é‡Œæˆ‘è·³è¿‡ä¸€ä¸‹ã€‚æœ€åè¯´æ˜ä¸€ä¸‹ï¼Œè¿™æ¬¡ workshop æˆ‘ä»¬å®é™…ä¸Šä¼šä½¿ç”¨ **Llama 3.3**ã€‚å¦‚æœä½ çœ‹å³ä¸‹è§’çš„å›¾è¡¨ï¼Œè¿™æ˜¯æ¥è‡ª **Artificial Analysis** çš„å›¾è¡¨ã€‚å¦‚æœä½ ä¸ç†Ÿæ‚‰çš„è¯ï¼Œ**Artificial Analysis** æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œå®ƒå¯¹å¾ˆå¤šä¸åŒçš„æ¨¡å‹ã€API æä¾›å•†ç­‰åœ¨æ™ºèƒ½ã€é€Ÿåº¦ã€å»¶è¿Ÿç­‰å„æ–¹é¢è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚ä½ å¯ä»¥çœ‹åˆ°è¿™é‡Œ **Cerebras** åœ¨æœ€å·¦è¾¹ï¼Œä»¥æ¯ç§’ token æ•°æ¥æ¯”è¾ƒï¼Œå’Œå…¶ä»–æä¾›å•†å¦‚ **Nvidia** çš„å¯¹æ¯”ã€‚

è§£æï¼š
* **benchmark** ğŸ”¥ï¼šåè¯/åŠ¨è¯ï¼ŒåŸºå‡†æµ‹è¯•
* **latency**ï¼šåè¯ï¼Œå»¶è¿Ÿ
* **tokens per second**ï¼šæ¯ç§’ token æ•°ï¼ˆè¡¡é‡æ¨ç†é€Ÿåº¦çš„æŒ‡æ ‡ï¼‰
* **Artificial Analysis**ï¼šä¸€ä¸ªç‹¬ç«‹çš„ AI æ¨¡å‹è¯„æµ‹å¹³å°

---

(11) [14:05-14:42] **Awesome. Um going back to our code, um hopefully everyone has had a second to kind of install the packages. Um, and now let's also install the LiveKit CLI. This is optional for our workshop today, but if you want to use LiveKit beyond this, um, here are the commands depending on your system. Um, in general, we're obviously using Python notebook today. So, no one has to battle around your environment when we're getting started. But again, if you want to continuously build and deploy uh the voice agent, the CLI probably is the easiest way to do it. So just uh type in LK app create and you can instantly clone a pre-built agent like this one.**

å¥½çš„ï¼Œå›åˆ°æˆ‘ä»¬çš„ä»£ç ï¼Œå¸Œæœ›å¤§å®¶éƒ½æœ‰æ—¶é—´å®‰è£…å¥½åŒ…äº†ã€‚ç°åœ¨æˆ‘ä»¬ä¹Ÿæ¥å®‰è£… **LiveKit CLI**ã€‚è¿™å¯¹ä»Šå¤©çš„ workshop æ˜¯å¯é€‰çš„ï¼Œä½†å¦‚æœä½ æƒ³åœ¨æ­¤ä¹‹åç»§ç»­ä½¿ç”¨ **LiveKit**ï¼Œè¿™é‡Œæ˜¯æ ¹æ®ä½ ç³»ç»Ÿçš„ä¸åŒå‘½ä»¤ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬ä»Šå¤©æ˜¾ç„¶æ˜¯ç”¨ **Python notebook**ï¼Œæ‰€ä»¥å¼€å§‹çš„æ—¶å€™å¤§å®¶ä¸ç”¨çº ç»“ç¯å¢ƒé—®é¢˜ã€‚ä½†å¦‚æœä½ æƒ³æŒç»­æ„å»ºå’Œéƒ¨ç½²è¯­éŸ³ä»£ç†ï¼Œ**CLI** å¯èƒ½æ˜¯æœ€ç®€å•çš„æ–¹å¼ã€‚åªéœ€è¾“å…¥ `lk app create`ï¼Œä½ å°±å¯ä»¥ç«‹å³å…‹éš†ä¸€ä¸ªåƒè¿™æ ·çš„é¢„æ„å»ºä»£ç†ã€‚

è§£æï¼š
* **CLI (Command Line Interface)**ï¼šå‘½ä»¤è¡Œç•Œé¢
* **optional**ï¼šå½¢å®¹è¯ï¼Œå¯é€‰çš„
* **battle around**ï¼šä¸º...çº ç»“/æŒ£æ‰
* **deploy** ğŸ”¥ï¼šåŠ¨è¯ï¼Œéƒ¨ç½²
* **pre-built**ï¼šé¢„æ„å»ºçš„

---

(12) [14:49-15:15] **Cool. And um let's talk a little bit about what exactly LiveKit is and why we need it for a voice agent. So the existing internet isn't exactly designed to build voice agent applications. So HTTP stands for hypertext transfer protocol. So it was designed for transferring text over a network and obviously for what we're building we need to transfer voice data instead of just text over a network with low latency.**

å¥½çš„ï¼Œè®©æˆ‘ä»¬èŠèŠ **LiveKit** åˆ°åº•æ˜¯ä»€ä¹ˆï¼Œä»¥åŠä¸ºä»€ä¹ˆæˆ‘ä»¬çš„è¯­éŸ³ä»£ç†éœ€è¦å®ƒã€‚ç°æœ‰çš„äº’è”ç½‘å…¶å®å¹¶ä¸æ˜¯ä¸ºæ„å»ºè¯­éŸ³ä»£ç†åº”ç”¨è€Œè®¾è®¡çš„ã€‚**HTTP** ä»£è¡¨è¶…æ–‡æœ¬ä¼ è¾“åè®®ï¼Œå®ƒæ˜¯ä¸ºåœ¨ç½‘ç»œä¸Šä¼ è¾“æ–‡æœ¬è€Œè®¾è®¡çš„ã€‚è€Œæˆ‘ä»¬è¦æ„å»ºçš„ä¸œè¥¿æ˜¾ç„¶éœ€è¦åœ¨ç½‘ç»œä¸Šä»¥ä½å»¶è¿Ÿä¼ è¾“è¯­éŸ³æ•°æ®ï¼Œè€Œä¸ä»…ä»…æ˜¯æ–‡æœ¬ã€‚

è§£æï¼š
* **HTTP (Hypertext Transfer Protocol)**ï¼šè¶…æ–‡æœ¬ä¼ è¾“åè®®
* **transfer**ï¼šåŠ¨è¯ï¼Œä¼ è¾“
* **low latency**ï¼šä½å»¶è¿Ÿ

---

(13) [15:15-15:42] **Um and LiveKit is a real-time infrastructure platform for doing just that. So instead of using HTTP it actually uses a different protocol called WebRTC to transport voice data between your client application and AI model with less than 100 milliseconds of latency anywhere in the world which is awesome. It's very resilient, handles a lot of concurrent sessions and it's fully open source. So you can kind of dig into the code and you can see how it works or even host infrastructure yourself as well.**

**LiveKit** æ˜¯ä¸€ä¸ªå®æ—¶åŸºç¡€è®¾æ–½å¹³å°ï¼Œå°±æ˜¯ç”¨æ¥åšè¿™ä»¶äº‹çš„ã€‚å®ƒä¸ä½¿ç”¨ **HTTP**ï¼Œè€Œæ˜¯ä½¿ç”¨ä¸€ç§å«åš **WebRTC** çš„ä¸åŒåè®®ï¼Œåœ¨ä½ çš„å®¢æˆ·ç«¯åº”ç”¨å’Œ AI æ¨¡å‹ä¹‹é—´ä¼ è¾“è¯­éŸ³æ•°æ®ï¼Œå…¨çƒä»»ä½•åœ°æ–¹å»¶è¿Ÿéƒ½ä¸åˆ° 100 æ¯«ç§’ï¼Œè¿™å¤ªæ£’äº†ã€‚å®ƒéå¸¸æœ‰å¼¹æ€§ï¼Œèƒ½å¤„ç†å¤§é‡å¹¶å‘ä¼šè¯ï¼Œè€Œä¸”å®Œå…¨å¼€æºã€‚æ‰€ä»¥ä½ å¯ä»¥æ·±å…¥ä»£ç çœ‹çœ‹å®ƒæ˜¯æ€ä¹ˆå·¥ä½œçš„ï¼Œç”šè‡³è‡ªå·±æ‰˜ç®¡åŸºç¡€è®¾æ–½ã€‚

è§£æï¼š
* **WebRTC** ğŸ”¥ï¼šWeb Real-Time Communicationï¼Œç½‘é¡µå®æ—¶é€šä¿¡åè®®
* **milliseconds**ï¼šæ¯«ç§’
* **resilient**ï¼šå½¢å®¹è¯ï¼Œæœ‰å¼¹æ€§çš„ã€å¯æ¢å¤çš„
* **concurrent sessions**ï¼šå¹¶å‘ä¼šè¯
* **open source**ï¼šå¼€æº
* **dig into**ï¼šæ·±å…¥ç ”ç©¶

---

(14) [15:42-16:16] **Um yeah, so you can use LiveKit to build any type of like voice agents, the ones that can join your meetings, the ones answering phone calls in sales centers and call centers and in our case today an agent that can speak to prospective customers on your website on your behalf. And here you can see connecting it to the original diagram that we showed. So you see like the LLM, TTS, STT and all the AI components that we talked about earlier. And now you can see, you know, how these actual tools like LiveKit, Cartisia, your inference provider, all of these things are actually playing together to help you create a voice agent.**

ä½ å¯ä»¥ç”¨ **LiveKit** æ„å»ºä»»ä½•ç±»å‹çš„è¯­éŸ³ä»£ç†ï¼šèƒ½åŠ å…¥ä½ ä¼šè®®çš„ä»£ç†ã€åœ¨é”€å”®ä¸­å¿ƒå’Œå‘¼å«ä¸­å¿ƒæ¥å¬ç”µè¯çš„ä»£ç†ï¼Œä»¥åŠæˆ‘ä»¬ä»Šå¤©çš„æ¡ˆä¾‹â€”â€”ä¸€ä¸ªèƒ½ä»£è¡¨ä½ åœ¨ç½‘ç«™ä¸Šä¸æ½œåœ¨å®¢æˆ·äº¤è°ˆçš„ä»£ç†ã€‚è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°å®ƒä¸æˆ‘ä»¬ä¹‹å‰å±•ç¤ºçš„åŸå§‹å›¾è¡¨çš„å…³è”ã€‚ä½ å¯ä»¥çœ‹åˆ° **LLM**ã€**TTS**ã€**STT** å’Œæˆ‘ä»¬ä¹‹å‰è®¨è®ºçš„æ‰€æœ‰ AI ç»„ä»¶ã€‚ç°åœ¨ä½ å¯ä»¥çœ‹åˆ°è¿™äº›å®é™…å·¥å…·ï¼Œæ¯”å¦‚ **LiveKit**ã€**Cartisia**ã€ä½ çš„æ¨ç†æä¾›å•†ï¼Œæ‰€æœ‰è¿™äº›æ˜¯å¦‚ä½•ååŒå·¥ä½œæ¥å¸®åŠ©ä½ åˆ›å»ºè¯­éŸ³ä»£ç†çš„ã€‚

è§£æï¼š
* **prospective customers** ğŸ”¥ï¼šæ½œåœ¨å®¢æˆ·
* **on your behalf**ï¼šä»£è¡¨ä½ 
* **call center**ï¼šå‘¼å«ä¸­å¿ƒ
* **playing together**ï¼šååŒå·¥ä½œ

---

(15) [16:16-16:32] **And so the final component as I mentioned is the actual speech processing um which so in addition to Cerebras and LiveKit and as I mentioned we'll be using Cartisia to turn the voice into text and then at the end text back to voice.**

æ­£å¦‚æˆ‘æåˆ°çš„ï¼Œæœ€åä¸€ä¸ªç»„ä»¶æ˜¯å®é™…çš„è¯­éŸ³å¤„ç†ã€‚é™¤äº† **Cerebras** å’Œ **LiveKit**ï¼Œæˆ‘ä»¬è¿˜å°†ä½¿ç”¨ **Cartisia** æŠŠè¯­éŸ³è½¬æˆæ–‡å­—ï¼Œç„¶åæœ€åå†æŠŠæ–‡å­—è½¬å›è¯­éŸ³ã€‚

è§£æï¼š
* **in addition to**ï¼šé™¤äº†...ä¹‹å¤–
* **speech processing**ï¼šè¯­éŸ³å¤„ç†

---

(16) [16:32-16:55] **So now that our API keys are set up, step two is all about teaching our AI sales agent about our business. So when you train a new employee you have to give it information and context on your business. And so that's what we're going to be doing now. Yeah. Um, I think the challenge a lot of the times with LLMs is that they know a lot about everything, but they might not know many specific things or domain things about your company.**

ç°åœ¨æˆ‘ä»¬çš„ API key è®¾ç½®å¥½äº†ï¼Œç¬¬äºŒæ­¥æ˜¯æ•™æˆ‘ä»¬çš„ AI é”€å”®ä»£ç†äº†è§£æˆ‘ä»¬çš„ä¸šåŠ¡ã€‚å½“ä½ åŸ¹è®­æ–°å‘˜å·¥æ—¶ï¼Œä½ å¿…é¡»ç»™ä»–æä¾›å…³äºä¸šåŠ¡çš„ä¿¡æ¯å’ŒèƒŒæ™¯ã€‚è¿™å°±æ˜¯æˆ‘ä»¬ç°åœ¨è¦åšçš„ã€‚æˆ‘è®¤ä¸º **LLM** å¾ˆå¤šæ—¶å€™çš„æŒ‘æˆ˜æ˜¯ï¼Œå®ƒä»¬å¯¹å¾ˆå¤šäº‹æƒ…éƒ½çŸ¥é“ä¸€äº›ï¼Œä½†å¯èƒ½ä¸å¤ªäº†è§£å…³äºä½ å…¬å¸çš„å…·ä½“äº‹æƒ…æˆ–é¢†åŸŸçŸ¥è¯†ã€‚

è§£æï¼š
* **API key**ï¼šAPI å¯†é’¥
* **domain** ğŸ”¥ï¼šé¢†åŸŸã€ä¸“ä¸šé¢†åŸŸ
* **specific things**ï¼šå…·ä½“çš„äº‹æƒ…

---

(17) [16:55-17:23] **Um, and they're only really as good as their training set. So, if we want to respond with any information that isn't common public knowledge, we should really try and load it into the LLM's context to minimize hallucination or any sort of canned responses such as, "I can't help with that." So, in this case, we're just going to be feeding the LLM a document with additional information. So, for example, we can load our pricing details if someone asks about pricing.**

è€Œä¸”å®ƒä»¬çš„èƒ½åŠ›åªå–å†³äºå®ƒä»¬çš„è®­ç»ƒæ•°æ®ã€‚æ‰€ä»¥å¦‚æœæˆ‘ä»¬æƒ³ç”¨ä»»ä½•ä¸æ˜¯å…¬å…±å¸¸è¯†çš„ä¿¡æ¯æ¥å›åº”ï¼Œæˆ‘ä»¬çœŸçš„åº”è¯¥å°è¯•æŠŠå®ƒåŠ è½½åˆ° **LLM** çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥å‡å°‘å¹»è§‰æˆ–ä»»ä½•é‚£ç§ç½å¤´å¼å›å¤ï¼Œæ¯”å¦‚ã€Œæˆ‘å¸®ä¸äº†ä½ ã€ã€‚åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬åªæ˜¯è¦ç»™ **LLM** æä¾›ä¸€ä»½åŒ…å«é¢å¤–ä¿¡æ¯çš„æ–‡æ¡£ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæœ‰äººé—®ä»·æ ¼ï¼Œæˆ‘ä»¬å¯ä»¥åŠ è½½æˆ‘ä»¬çš„å®šä»·è¯¦æƒ…ã€‚

è§£æï¼š
* **training set**ï¼šè®­ç»ƒé›†/è®­ç»ƒæ•°æ®
* **hallucination** ğŸ”¥ï¼šå¹»è§‰ï¼ˆAI æœ¯è¯­ï¼ŒæŒ‡æ¨¡å‹ç¼–é€ ä¸å­˜åœ¨çš„ä¿¡æ¯ï¼‰
* **canned responses**ï¼šç½å¤´å¼å›å¤ã€æ¨¡æ¿åŒ–å›å¤
* **feed**ï¼šåŠ¨è¯ï¼Œå–‚ç»™ã€æä¾›ï¼ˆæ•°æ®ï¼‰

---

(18) [17:17-17:58] **But we can also load information like product descriptions, pricing info, key benefits. And another big thing that we can do is write pre-written responses to common objections. So, for example, if it's common that someone says it's too expensive, you can write a pre-written message so that our agent will always stay on message and it has the correct context. So, if you look at the notebook, you can see what that context looks like in practice, right? You don't have to just give it access to a full document. Um you can see that we've organized all the information that our sales agent needs into a very simple structured format for the AI to understand and reference.**

æˆ‘ä»¬è¿˜å¯ä»¥åŠ è½½äº§å“æè¿°ã€å®šä»·ä¿¡æ¯ã€ä¸»è¦ä¼˜åŠ¿ç­‰ä¿¡æ¯ã€‚å¦ä¸€ä¸ªé‡è¦çš„äº‹æƒ…æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä¸ºå¸¸è§å¼‚è®®ç¼–å†™é¢„è®¾å›å¤ã€‚ä¾‹å¦‚ï¼Œå¦‚æœç»å¸¸æœ‰äººè¯´ã€Œå¤ªè´µäº†ã€ï¼Œä½ å¯ä»¥å†™ä¸€æ¡é¢„è®¾æ¶ˆæ¯ï¼Œè¿™æ ·æˆ‘ä»¬çš„ä»£ç†å°±èƒ½å§‹ç»ˆä¿æŒä¸€è‡´çš„å£å¾„å¹¶æ‹¥æœ‰æ­£ç¡®çš„ä¸Šä¸‹æ–‡ã€‚å¦‚æœä½ çœ‹çœ‹ notebookï¼Œä½ å¯ä»¥çœ‹åˆ°è¿™ä¸ªä¸Šä¸‹æ–‡åœ¨å®è·µä¸­æ˜¯ä»€ä¹ˆæ ·çš„ï¼Œå¯¹å§ï¼Ÿä½ ä¸å¿…åªæ˜¯ç»™å®ƒè®¿é—®å®Œæ•´æ–‡æ¡£çš„æƒé™ã€‚ä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æŠŠé”€å”®ä»£ç†éœ€è¦çš„æ‰€æœ‰ä¿¡æ¯ç»„ç»‡æˆä¸€ä¸ªéå¸¸ç®€å•çš„ç»“æ„åŒ–æ ¼å¼ï¼Œä¾¿äº AI ç†è§£å’Œå¼•ç”¨ã€‚

è§£æï¼š
* **objections** ğŸ”¥ï¼šåè¯ï¼Œå¼‚è®®ã€åå¯¹æ„è§ï¼ˆé”€å”®æœ¯è¯­ï¼‰
* **pre-written responses**ï¼šé¢„è®¾å›å¤
* **stay on message**ï¼šä¿æŒä¸€è‡´çš„å£å¾„/ä¿¡æ¯
* **structured format**ï¼šç»“æ„åŒ–æ ¼å¼
* **reference**ï¼šåŠ¨è¯ï¼Œå¼•ç”¨

---

(19) [17:58-18:27] **So you can see everything that a good salesperson would need like the descriptions and then as we mentioned it has these pre-written messages as well so that you can control the behavior of your voice agent more closely. Um, now we're off to the more exciting part, even more exciting part, step three, where we actually create our sales agent. So, this is where everything that we've just talked about, the components, and we're going to wire them all together into a working system.**

ä½ å¯ä»¥çœ‹åˆ°ä¸€ä¸ªå¥½é”€å”®å‘˜éœ€è¦çš„ä¸€åˆ‡ï¼Œæ¯”å¦‚äº§å“æè¿°ï¼Œç„¶åæ­£å¦‚æˆ‘ä»¬æåˆ°çš„ï¼Œå®ƒè¿˜æœ‰è¿™äº›é¢„è®¾æ¶ˆæ¯ï¼Œè¿™æ ·ä½ å¯ä»¥æ›´ç²¾ç¡®åœ°æ§åˆ¶è¯­éŸ³ä»£ç†çš„è¡Œä¸ºã€‚ç°åœ¨æˆ‘ä»¬è¦è¿›å…¥æ›´æ¿€åŠ¨äººå¿ƒçš„éƒ¨åˆ†äº†ï¼Œç¬¬ä¸‰æ­¥ï¼Œæˆ‘ä»¬å®é™…åˆ›å»ºé”€å”®ä»£ç†ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¼šæŠŠåˆšæ‰è®¨è®ºçš„æ‰€æœ‰ç»„ä»¶è¿æ¥åœ¨ä¸€èµ·ï¼Œç»„æˆä¸€ä¸ªå¯å·¥ä½œçš„ç³»ç»Ÿã€‚

è§£æï¼š
* **more closely**ï¼šæ›´ç²¾ç¡®åœ°ã€æ›´ç´§å¯†åœ°
* **we're off to**ï¼šæˆ‘ä»¬è¦è¿›å…¥...
* **wire together** ğŸ”¥ï¼šè¿æ¥åœ¨ä¸€èµ·ï¼ˆæŠŠå„ç»„ä»¶æ¥çº¿è¿æ¥ï¼‰

---

(20) [18:27-19:02] **Um, and before you run anything, let's actually walk through what is happening in the sales agent class. So, in the code, you can see we start by loading our context by using the load context function we defined earlier. And this gives our agent access to all the product information, pricing, and objection handlers that we set up. So, and finally, I want to look at how we're implementing everything in code in terms of creating the actual sales agent. So there's way more of the code in the notebook, but as a high level um you want to start there's kind of four components.**

åœ¨ä½ è¿è¡Œä»»ä½•ä¸œè¥¿ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆçœ‹çœ‹é”€å”®ä»£ç†ç±»é‡Œé¢å‘ç”Ÿäº†ä»€ä¹ˆã€‚åœ¨ä»£ç ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ä¹‹å‰å®šä¹‰çš„ `load_context` å‡½æ•°æ¥åŠ è½½ä¸Šä¸‹æ–‡ã€‚è¿™è®©æˆ‘ä»¬çš„ä»£ç†èƒ½è®¿é—®æˆ‘ä»¬è®¾ç½®çš„æ‰€æœ‰äº§å“ä¿¡æ¯ã€å®šä»·å’Œå¼‚è®®å¤„ç†ç¨‹åºã€‚æœ€åï¼Œæˆ‘æƒ³çœ‹çœ‹æˆ‘ä»¬æ˜¯å¦‚ä½•åœ¨ä»£ç ä¸­å®ç°åˆ›å»ºå®é™…é”€å”®ä»£ç†çš„ã€‚notebook é‡Œæœ‰æ›´å¤šä»£ç ï¼Œä½†ä»é«˜å±‚æ¬¡æ¥çœ‹ï¼Œå¤§çº¦æœ‰å››ä¸ªç»„ä»¶ã€‚

è§£æï¼š
* **class**ï¼šç±»ï¼ˆç¼–ç¨‹æœ¯è¯­ï¼‰
* **load context**ï¼šåŠ è½½ä¸Šä¸‹æ–‡
* **objection handlers**ï¼šå¼‚è®®å¤„ç†ç¨‹åº
* **at a high level**ï¼šä»é«˜å±‚æ¬¡æ¥çœ‹

---

(21) [19:02-19:48] **So you want to start by you know telling your sales agent your voice agent communicating by voice um and give it proper rules like you know don't use bullet points because everything is spoken aloud. So you want to do um a bit of prompting and then most importantly only use information from the context that you provided. So you want to make be very careful especially with voice agents that you are not allowing um that you're reducing the risk of hallucinations as much as possible. And then the super call is what's initializing our agent and passes all of our configurations to the parent agent. And this is setting up our agent with the LLM, TTS, VAD and all the instructions working together.**

é¦–å…ˆä½ è¦å‘Šè¯‰ä½ çš„é”€å”®ä»£ç†ï¼Œä½ çš„è¯­éŸ³ä»£ç†æ˜¯é€šè¿‡è¯­éŸ³äº¤æµçš„ï¼Œå¹¶ç»™å®ƒé€‚å½“çš„è§„åˆ™ï¼Œæ¯”å¦‚ä¸è¦ä½¿ç”¨é¡¹ç›®ç¬¦å·ï¼Œå› ä¸ºæ‰€æœ‰å†…å®¹éƒ½æ˜¯å£å¤´è¯´å‡ºæ¥çš„ã€‚æ‰€ä»¥ä½ éœ€è¦åšä¸€äº›æç¤ºè¯å·¥ç¨‹ï¼Œç„¶åæœ€é‡è¦çš„æ˜¯åªä½¿ç”¨ä½ æä¾›çš„ä¸Šä¸‹æ–‡ä¸­çš„ä¿¡æ¯ã€‚ä½ è¦éå¸¸å°å¿ƒï¼Œç‰¹åˆ«æ˜¯å¯¹äºè¯­éŸ³ä»£ç†ï¼Œè¦å°½å¯èƒ½é™ä½å¹»è§‰çš„é£é™©ã€‚ç„¶å `super()` è°ƒç”¨æ˜¯åˆå§‹åŒ–æˆ‘ä»¬çš„ä»£ç†ï¼Œå¹¶å°†æ‰€æœ‰é…ç½®ä¼ é€’ç»™çˆ¶ä»£ç†ã€‚è¿™ä¼šè®¾ç½®æˆ‘ä»¬çš„ä»£ç†ï¼Œè®© **LLM**ã€**TTS**ã€**VAD** å’Œæ‰€æœ‰æŒ‡ä»¤ä¸€èµ·å·¥ä½œã€‚

è§£æï¼š
* **bullet points**ï¼šé¡¹ç›®ç¬¦å·
* **spoken aloud**ï¼šå£å¤´è¯´å‡ºæ¥
* **prompting**ï¼šæç¤ºè¯å·¥ç¨‹
* **super call**ï¼šsuper() è°ƒç”¨ï¼ˆPython ä¸­è°ƒç”¨çˆ¶ç±»çš„æ–¹æ³•ï¼‰
* **configurations**ï¼šé…ç½®

---

(22) [19:48-20:11] **And then the last thing that we're going to do is we're also going to define an on_enter method which is what's going to start the actual conversation. So, as soon as someone joins the conversation with the agent, instead of sitting in silence, it immediately um or this is triggered as soon as someone joins the conversation. So, instead of ever sitting in silence, you're going to immediately generate that greeting um and the good salesperson will help.**

ç„¶åæˆ‘ä»¬è¦åšçš„æœ€åä¸€ä»¶äº‹æ˜¯å®šä¹‰ä¸€ä¸ª `on_enter` æ–¹æ³•ï¼Œå®ƒä¼šå¯åŠ¨å®é™…çš„å¯¹è¯ã€‚ä¸€æ—¦æœ‰äººåŠ å…¥ä¸ä»£ç†çš„å¯¹è¯ï¼Œä»£ç†ä¸ä¼šæ²‰é»˜ç­‰å¾…ï¼Œè€Œæ˜¯ä¼šç«‹å³è§¦å‘è¿™ä¸ªæ–¹æ³•ã€‚æ‰€ä»¥ä»£ç†æ°¸è¿œä¸ä¼šæ²‰é»˜ç­‰å¾…ï¼Œè€Œæ˜¯ä¼šç«‹å³ç”Ÿæˆé—®å€™è¯­ï¼Œå°±åƒä¸€ä¸ªå¥½é”€å”®å‘˜ä¼šåšçš„é‚£æ ·ã€‚

è§£æï¼š
* **on_enter method**ï¼šè¿›å…¥æ–¹æ³•ï¼ˆäº‹ä»¶å¤„ç†å‡½æ•°ï¼‰
* **sitting in silence**ï¼šæ²‰é»˜ç­‰å¾…
* **triggered**ï¼šè¢«è§¦å‘
* **greeting**ï¼šé—®å€™è¯­

---

(23) [20:11-20:51] **Yeah. And then we're off to our step four. We're actually launching a session and running the agent. Um, think of this entire kind of uh entry point function as a start button to our agent. And when someone wants to have a conversation, obviously it kicks off everything and gets the agent ready to talk. So this entry point function is doing three main things. So it's connecting the agent to a virtual room where the conversation will happen. So it's like dialing into a conference call. Um, then it's going to create an instance of our sales agent with the setup that we just configured. And so finally, it's going to start a session that manages the back and forth conversations.**

ç„¶åæˆ‘ä»¬è¿›å…¥ç¬¬å››æ­¥ï¼Œå®é™…å¯åŠ¨ä¸€ä¸ªä¼šè¯å¹¶è¿è¡Œä»£ç†ã€‚æŠŠè¿™æ•´ä¸ªå…¥å£å‡½æ•°æƒ³è±¡æˆæˆ‘ä»¬ä»£ç†çš„å¯åŠ¨æŒ‰é’®ã€‚å½“æœ‰äººæƒ³è¦å¯¹è¯æ—¶ï¼Œå®ƒä¼šå¯åŠ¨ä¸€åˆ‡å¹¶è®©ä»£ç†å‡†å¤‡å¥½äº¤è°ˆã€‚è¿™ä¸ªå…¥å£å‡½æ•°åšä¸‰ä»¶ä¸»è¦çš„äº‹æƒ…ï¼šé¦–å…ˆï¼Œå®ƒæŠŠä»£ç†è¿æ¥åˆ°ä¸€ä¸ªè™šæ‹Ÿæˆ¿é—´ï¼Œå¯¹è¯å°†åœ¨é‚£é‡Œè¿›è¡Œï¼Œå°±åƒæ‹¨å…¥ä¸€ä¸ªç”µè¯ä¼šè®®ï¼›ç„¶åï¼Œå®ƒä¼šç”¨æˆ‘ä»¬åˆšé…ç½®çš„è®¾ç½®åˆ›å»ºä¸€ä¸ªé”€å”®ä»£ç†å®ä¾‹ï¼›æœ€åï¼Œå®ƒä¼šå¯åŠ¨ä¸€ä¸ªä¼šè¯æ¥ç®¡ç†æ¥å›çš„å¯¹è¯ã€‚

è§£æï¼š
* **entry point function** ğŸ”¥ï¼šå…¥å£å‡½æ•°
* **kick off**ï¼šå¯åŠ¨ã€å¼€å§‹
* **virtual room**ï¼šè™šæ‹Ÿæˆ¿é—´
* **dialing into a conference call**ï¼šæ‹¨å…¥ç”µè¯ä¼šè®®
* **instance**ï¼šå®ä¾‹ï¼ˆç¼–ç¨‹æœ¯è¯­ï¼‰
* **back and forth**ï¼šæ¥å›çš„

---

(24) [20:51-21:17] **And so that is it for the basis or like I guess the main framework for how you would set up a sales agent. But to make this project a little more robust, we're actually going to talk about one a few ways that you can expand your sales agent. So here's one example. Yeah. So one thing you can do um to expand our single agent into a multi-agent system is um to just you know if someone calls asking really deep technical questions about API integrations you really want them talking to your best technical person and not just your pricing specialist.**

è¿™å°±æ˜¯è®¾ç½®é”€å”®ä»£ç†çš„åŸºç¡€æˆ–è€…è¯´ä¸»è¦æ¡†æ¶ã€‚ä½†ä¸ºäº†è®©è¿™ä¸ªé¡¹ç›®æ›´å¥å£®ï¼Œæˆ‘ä»¬å®é™…ä¸Šè¦è®¨è®ºå‡ ç§æ‰©å±•é”€å”®ä»£ç†çš„æ–¹æ³•ã€‚è¿™æ˜¯ä¸€ä¸ªä¾‹å­ã€‚ä½ å¯ä»¥åšçš„ä¸€ä»¶äº‹æ˜¯æŠŠæˆ‘ä»¬çš„å•ä¸ªä»£ç†æ‰©å±•æˆä¸€ä¸ªå¤šä»£ç†ç³»ç»Ÿã€‚æ¯”å¦‚å¦‚æœæœ‰äººæ‰“ç”µè¯é—®å…³äº **API** é›†æˆçš„æ·±åº¦æŠ€æœ¯é—®é¢˜ï¼Œä½ çœŸçš„å¸Œæœ›ä»–ä»¬å’Œä½ æœ€å¥½çš„æŠ€æœ¯äººå‘˜äº¤è°ˆï¼Œè€Œä¸åªæ˜¯å®šä»·ä¸“å‘˜ã€‚

è§£æï¼š
* **robust**ï¼šå½¢å®¹è¯ï¼Œå¥å£®çš„ã€ç¨³å¥çš„
* **multi-agent system** ğŸ”¥ï¼šå¤šä»£ç†ç³»ç»Ÿ
* **API integrations**ï¼šAPI é›†æˆ

---

(25) [21:17-22:07] **Um again all LLMs have limited context windows which means that similar to people they have limits on the amount of things that they can actually specialize. Um and here are the three other agents in addition to that single agent that um the starter code has just helped you guys run. Um three of the different agents that we propose in this case are um greeting agents um our main sales agent who qualifies leads. We have a technical specialist agent as you can see on the left um who are obviously specialized in solving technical issues is the intent and then finally we have the pricing specialist agent on the right which handles budget ROI and also deal negotiations.**

å¦å¤–æ‰€æœ‰ **LLM** éƒ½æœ‰æœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£ï¼Œè¿™æ„å‘³ç€å’Œäººä¸€æ ·ï¼Œå®ƒä»¬èƒ½ä¸“ç²¾çš„äº‹æƒ…æ˜¯æœ‰é™çš„ã€‚è¿™é‡Œæ˜¯é™¤äº† starter code å¸®ä½ ä»¬è¿è¡Œçš„é‚£ä¸ªå•ä¸€ä»£ç†ä¹‹å¤–çš„å¦å¤–ä¸‰ä¸ªä»£ç†ã€‚æˆ‘ä»¬åœ¨è¿™ä¸ªæ¡ˆä¾‹ä¸­æå‡ºçš„ä¸‰ç§ä¸åŒä»£ç†æ˜¯ï¼šé—®å€™ä»£ç†ã€è´Ÿè´£ç­›é€‰æ½œåœ¨å®¢æˆ·çš„ä¸»é”€å”®ä»£ç†ã€å·¦è¾¹çš„æŠ€æœ¯ä¸“å®¶ä»£ç†ï¼ˆæ˜¾ç„¶ä¸“é—¨è§£å†³æŠ€æœ¯é—®é¢˜ï¼‰ï¼Œä»¥åŠå³è¾¹çš„å®šä»·ä¸“å®¶ä»£ç†ï¼ˆå¤„ç†é¢„ç®—ã€ROI å’Œäº¤æ˜“è°ˆåˆ¤ï¼‰ã€‚

è§£æï¼š
* **context window**ï¼šä¸Šä¸‹æ–‡çª—å£ï¼ˆLLM èƒ½å¤„ç†çš„æœ€å¤§æ–‡æœ¬é•¿åº¦ï¼‰
* **specialize**ï¼šåŠ¨è¯ï¼Œä¸“ç²¾ã€ä¸“é—¨ä»äº‹
* **qualifies leads** ğŸ”¥ï¼šç­›é€‰æ½œåœ¨å®¢æˆ·ï¼ˆé”€å”®æœ¯è¯­ï¼‰
* **ROI (Return on Investment)**ï¼šæŠ•èµ„å›æŠ¥ç‡
* **deal negotiations**ï¼šäº¤æ˜“è°ˆåˆ¤

---

(26) [22:07-22:32] **So the main thing that you want to think about here is you know on a real sales team you want or any like multi-agent system you want all of your agents to be able to do very different things. And so one of the key things in this um implementation is that we have a handoff. So our greeting agent is what figuring out what the customer actually needs and then being able to route to the um to the relevant sub agent.**

è¿™é‡Œä½ è¦è€ƒè™‘çš„ä¸»è¦äº‹æƒ…æ˜¯ï¼Œåœ¨ä¸€ä¸ªçœŸæ­£çš„é”€å”®å›¢é˜Ÿæˆ–ä»»ä½•å¤šä»£ç†ç³»ç»Ÿä¸­ï¼Œä½ å¸Œæœ›æ‰€æœ‰ä»£ç†èƒ½åšéå¸¸ä¸åŒçš„äº‹æƒ…ã€‚è¿™ä¸ªå®ç°ä¸­çš„ä¸€ä¸ªå…³é”®ç‚¹æ˜¯æˆ‘ä»¬æœ‰ä¸€ä¸ªäº¤æ¥æœºåˆ¶ã€‚æˆ‘ä»¬çš„é—®å€™ä»£ç†ä¼šå¼„æ¸…æ¥šå®¢æˆ·å®é™…éœ€è¦ä»€ä¹ˆï¼Œç„¶åèƒ½å¤Ÿè·¯ç”±åˆ°ç›¸å…³çš„å­ä»£ç†ã€‚

è§£æï¼š
* **handoff** ğŸ”¥ï¼šäº¤æ¥ï¼ˆæŠŠå¯¹è¯è½¬äº¤ç»™å¦ä¸€ä¸ªä»£ç†ï¼‰
* **route to**ï¼šè·¯ç”±åˆ°ã€è½¬æ¥åˆ°
* **sub agent**ï¼šå­ä»£ç†

---

(27) [22:32-23:07] **And the code for all of these different agents is fully fleshed out in the notebook as well. And then the last thing of course is you can is adding tool calling. So for example when a customer asks about technical details you know we can properly route and then this is also implemented as well in the code notebook. And that is it. So thank you guys so much for coming. Um all again all of the notebook with all the instructions and the step by step is in the notebook that we've provided and have built. Um and we'll be up here to answer any questions that you guys might have. Thank you guys.**

æ‰€æœ‰è¿™äº›ä¸åŒä»£ç†çš„ä»£ç åœ¨ notebook é‡Œéƒ½æœ‰å®Œæ•´å®ç°ã€‚æœ€åä¸€ä»¶äº‹å½“ç„¶æ˜¯æ·»åŠ å·¥å…·è°ƒç”¨ã€‚ä¾‹å¦‚å½“å®¢æˆ·é—®æŠ€æœ¯ç»†èŠ‚æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥æ­£ç¡®è·¯ç”±ï¼Œè¿™åœ¨ä»£ç  notebook é‡Œä¹Ÿæœ‰å®ç°ã€‚å°±æ˜¯è¿™æ ·äº†ï¼éå¸¸æ„Ÿè°¢å¤§å®¶çš„åˆ°æ¥ã€‚æ‰€æœ‰çš„ notebookã€æ‰€æœ‰çš„è¯´æ˜å’Œæ­¥éª¤éƒ½åœ¨æˆ‘ä»¬æä¾›å’Œæ„å»ºçš„ notebook é‡Œã€‚æˆ‘ä»¬ä¼šåœ¨è¿™é‡Œå›ç­”ä½ ä»¬å¯èƒ½æœ‰çš„ä»»ä½•é—®é¢˜ã€‚è°¢è°¢å¤§å®¶ï¼

è§£æï¼š
* **fleshed out** ğŸ”¥ï¼šå®Œæ•´å®ç°ã€å……å®å®Œå–„
* **tool calling**ï¼šå·¥å…·è°ƒç”¨ï¼ˆè®© LLM è°ƒç”¨å¤–éƒ¨å·¥å…·/å‡½æ•°ï¼‰
* **step by step**ï¼šä¸€æ­¥ä¸€æ­¥

---

## ğŸ“š æ®µè½å°ç»“

è¿™æ®µè§†é¢‘è¯¦ç»†è®²è§£äº†è¯­éŸ³ä»£ç†çš„ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼š**ç›‘å¬é˜¶æ®µ**ï¼ˆSTT + è½®æ¬¡æ£€æµ‹ï¼‰ã€**æ€è€ƒé˜¶æ®µ**ï¼ˆLLM æ¨ç†ï¼‰å’Œ**è¯´è¯é˜¶æ®µ**ï¼ˆTTS æµå¼è¾“å‡ºï¼‰ã€‚ä»‹ç»äº† **LiveKit** ä½œä¸ºå®æ—¶åŸºç¡€è®¾æ–½å¹³å°ï¼Œä½¿ç”¨ **WebRTC** åè®®å®ç°ä½äº 100ms å»¶è¿Ÿçš„è¯­éŸ³ä¼ è¾“ã€‚ç„¶åæ¼”ç¤ºäº†å¦‚ä½•é€šè¿‡åŠ è½½ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼ˆäº§å“ä¿¡æ¯ã€å®šä»·ã€å¼‚è®®å¤„ç†ï¼‰æ¥è®­ç»ƒé”€å”®ä»£ç†ï¼Œå¹¶è®²è§£äº†ä»£ç å®ç°çš„å››ä¸ªå…³é”®ç»„ä»¶ã€‚æœ€åæ‰©å±•åˆ°å¤šä»£ç†ç³»ç»Ÿæ¶æ„ï¼ŒåŒ…æ‹¬é—®å€™ä»£ç†ã€æŠ€æœ¯ä¸“å®¶ä»£ç†å’Œå®šä»·ä¸“å®¶ä»£ç†çš„åˆ†å·¥åä½œã€‚

### ğŸ”¥ æ ¸å¿ƒè¯æ±‡è¡¨

| è¯æ±‡/çŸ­è¯­ | å«ä¹‰ |
|---------|------|
| **STT/TTS** | è¯­éŸ³è½¬æ–‡å­— / æ–‡å­—è½¬è¯­éŸ³ |
| **VAD** | è¯­éŸ³æ´»åŠ¨æ£€æµ‹ |
| **utterance** | è¯è¯­ã€å‘è¨€ï¼ˆè¯­éŸ³å¤„ç†æœ¯è¯­ï¼‰ |
| **orchestration** | ç¼–æ’ã€åè°ƒ |
| **WebRTC** | ç½‘é¡µå®æ—¶é€šä¿¡åè®® |
| **hallucination** | å¹»è§‰ï¼ˆAI ç¼–é€ ä¿¡æ¯ï¼‰ |
| **objections** | å¼‚è®®ã€åå¯¹æ„è§ï¼ˆé”€å”®æœ¯è¯­ï¼‰ |
| **wire together** | è¿æ¥åœ¨ä¸€èµ· |
| **handoff** | äº¤æ¥ï¼ˆä»£ç†é—´è½¬æ¥ï¼‰ |
| **qualifies leads** | ç­›é€‰æ½œåœ¨å®¢æˆ· |
| **tool calling** | å·¥å…·è°ƒç”¨ |
| **fleshed out** | å®Œæ•´å®ç°ã€å……å®å®Œå–„ |
