# ğŸ¯ è¯­éŸ³ç«¯åˆ°ç«¯æ¨¡å‹çš„æŒ‘æˆ˜ä¸æœªæ¥ è‹±è¯­æ®µè½ç¿»è¯‘

æœ¬æ–‡å…± **26 ä¸ªè¯­ä¹‰å•å…ƒ**ï¼Œå°†å…¨éƒ¨ç¿»è¯‘ã€‚

---

(1) [10:42-11:00]

**{What's keeping people from [just deploying speech to speech everywhere] today?} {Yeah. So the main reason is â€” and we saw that (with Moshi).} {So the naturalness and the latency was impressive.} {The latency was (sometimes) negative.} {So [if the model will figure out (the end of your question)], you start answering [before you're done] â€” which was amazing and frustrating (for some people) because some people were confused, like they felt [it was a bit impolite].}**

æ˜¯ä»€ä¹ˆé˜»ç¢äº†äººä»¬ç°åœ¨å°±æŠŠç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹å¤§è§„æ¨¡éƒ¨ç½²å‘¢ï¼Ÿå—¯ï¼Œä¸»è¦åŸå› æ˜¯â€”â€”æˆ‘ä»¬åœ¨ **Moshi** ä¸Šå·²ç»çœ‹åˆ°äº†ã€‚å®ƒçš„è‡ªç„¶åº¦å’Œå»¶è¿Ÿè¡¨ç°ä»¤äººå°è±¡æ·±åˆ»ã€‚å»¶è¿Ÿæœ‰æ—¶å€™ç”šè‡³æ˜¯è´Ÿçš„â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œå¦‚æœæ¨¡å‹é¢„åˆ¤åˆ°äº†ä½ é—®é¢˜çš„ç»“å°¾ï¼Œå®ƒä¼šåœ¨ä½ è¯´å®Œä¹‹å‰å°±å¼€å§‹å›ç­”ã€‚è¿™è®©ä¸€äº›äººè§‰å¾—å¾ˆæƒŠè‰³ï¼Œä½†ä¹Ÿè®©ä¸€äº›äººæ„Ÿåˆ°å›°æƒ‘å’Œæ²®ä¸§ï¼Œè§‰å¾—è¿™æœ‰ç‚¹ä¸ç¤¼è²Œã€‚

è§£æï¼š
* **deploy** /dÉªËˆplÉ”Éª/ï¼šåŠ¨è¯ï¼Œéƒ¨ç½²ã€æŠ•å…¥ä½¿ç”¨ï¼ˆæŠ€æœ¯é¢†åŸŸå¸¸ç”¨ï¼‰
* **speech to speech**ï¼šç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹ï¼Œç›´æ¥ä»è¯­éŸ³è¾“å…¥åˆ°è¯­éŸ³è¾“å‡ºï¼Œä¸ç»è¿‡æ–‡æœ¬ä¸­é—´å±‚
* **latency** /ËˆleÉªtÉ™nsi/ï¼šåè¯ï¼Œå»¶è¿Ÿï¼ˆç³»ç»Ÿå“åº”æ—¶é—´ï¼‰
* **figure out** ğŸ”¥ï¼šçŸ­è¯­åŠ¨è¯ï¼Œå¼„æ˜ç™½ã€æ¨æ–­å‡ºï¼ˆè¿™é‡ŒæŒ‡æ¨¡å‹é¢„åˆ¤ï¼‰
* **impolite** /ËŒÉªmpÉ™ËˆlaÉªt/ï¼šå½¢å®¹è¯ï¼Œä¸ç¤¼è²Œçš„

---

(2) [11:00-11:23]

**{But what happened is [it was very hard to steer these models (in specific directions)]}, you know â€” {there is [updating the text backbone], you know, [the underlying intelligence basically], and being [the text backbone (where you start your training from)] â€” tool use, function calling, and so on.} {So it was a nice experience but [it didn't have [the same modularity] [as a cascaded system]].}**

ä½†é—®é¢˜åœ¨äºï¼Œè¿™ç±»æ¨¡å‹éå¸¸éš¾ä»¥å¼•å¯¼åˆ°ç‰¹å®šçš„æ–¹å‘â€”â€”ä½ çŸ¥é“çš„ï¼Œè¦æ›´æ–°æ–‡æœ¬éª¨å¹²ç½‘ç»œâ€”â€”ä¹Ÿå°±æ˜¯åº•å±‚çš„æ™ºèƒ½â€”â€”è€Œä¸”è¿™ä¸ªæ–‡æœ¬éª¨å¹²æ˜¯ä½ å¼€å§‹è®­ç»ƒçš„èµ·ç‚¹ï¼ŒåŒ…æ‹¬å·¥å…·è°ƒç”¨ã€å‡½æ•°è°ƒç”¨ç­‰ç­‰ã€‚æ‰€ä»¥ä½“éªŒæ˜¯ä¸é”™çš„ï¼Œä½†å®ƒä¸å…·å¤‡çº§è”ç³»ç»Ÿï¼ˆ**cascaded system**ï¼‰é‚£æ ·çš„æ¨¡å—åŒ–èƒ½åŠ›ã€‚

è§£æï¼š
* **steer** /stÉªr/ ğŸ”¥ï¼šåŠ¨è¯ï¼Œå¼•å¯¼ã€æ“æ§æ–¹å‘ï¼ˆåŸæ„æ˜¯é©¾é©¶æ–¹å‘ç›˜è½¬å‘ï¼‰
* **text backbone**ï¼šæ–‡æœ¬éª¨å¹²ç½‘ç»œï¼Œæ¨¡å‹ä¸­è´Ÿè´£æ ¸å¿ƒæ–‡æœ¬ç†è§£çš„éƒ¨åˆ†
* **underlying** /ËŒÊŒndÉ™rËˆlaÉªÉªÅ‹/ï¼šå½¢å®¹è¯ï¼Œåº•å±‚çš„ã€æ ¹æœ¬çš„
* **modularity** /ËŒmÉ’djÊŠËˆlÃ¦rÉªti/ï¼šåè¯ï¼Œæ¨¡å—åŒ–èƒ½åŠ›
* **cascaded system**ï¼šçº§è”ç³»ç»Ÿï¼ŒSTT â†’ LLM â†’ TTS å¤šæ¨¡å—ä¸²è”çš„æ¶æ„

---

(3) [11:23-11:47]

**{So a cascaded system has [a lot of limitations] (in my personal opinion).} {I think the worst is [voice activity and turn taking].} {But you know, [you have your voice agent (in production)], you can [easily swap the text backbone (with another one)].} {It's very easy [to control the output] because [it's much easier to filter [things (you don't want to say)] or judge (from text)], you know.}**

çº§è”ç³»ç»Ÿåœ¨æˆ‘ä¸ªäººçœ‹æ¥ä¹Ÿæœ‰å¾ˆå¤šå±€é™æ€§ï¼Œæˆ‘è®¤ä¸ºæœ€ä¸¥é‡çš„æ˜¯è¯­éŸ³æ´»åŠ¨æ£€æµ‹å’Œè½®æ¬¡ç®¡ç†ã€‚ä½†å¥½å¤„æ˜¯ï¼Œå½“ä½ çš„è¯­éŸ³ä»£ç†åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿è¡Œæ—¶ï¼Œä½ å¯ä»¥å¾ˆæ–¹ä¾¿åœ°æŠŠæ–‡æœ¬éª¨å¹²æ›¿æ¢æˆå¦ä¸€ä¸ªã€‚æ§åˆ¶è¾“å‡ºä¹Ÿå¾ˆå®¹æ˜“ï¼Œå› ä¸ºä»æ–‡æœ¬å±‚é¢å»è¿‡æ»¤ä½ ä¸æƒ³è¯´çš„å†…å®¹ã€åšåˆ¤æ–­ï¼Œè¦ç®€å•å¾—å¤šã€‚

è§£æï¼š
* **voice activity**ï¼šè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼ˆVADï¼‰ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰äººåœ¨è¯´è¯çš„æŠ€æœ¯
* **turn taking** ğŸ”¥ï¼šè½®æ¬¡ç®¡ç†ï¼Œå¯¹è¯ä¸­åŒæ–¹è½®æµå‘è¨€çš„æœºåˆ¶
* **in production**ï¼šçŸ­è¯­ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼ˆå·²ä¸Šçº¿éƒ¨ç½²ï¼‰
* **swap** /swÉ’p/ï¼šåŠ¨è¯ï¼Œæ›¿æ¢ã€äº¤æ¢
* **filter** /ËˆfÉªltÉ™r/ï¼šåŠ¨è¯ï¼Œè¿‡æ»¤ã€ç­›é€‰

---

(4) [11:47-12:10]

**{So, [if you have this text bottleneck (in the middle)], it's very easy [to filter words (you don't want)].} {It's to do function calling and so on and so forth.} {So, this is still very convenient.} {And the second thing I think is â€” not only [cascaded systems are more convenient] but [another limitation of speech to speech] is [it makes them less intelligent fundamentally] â€” [even if you ignore the fact (that it's less modular)], okay.}**

æ‰€ä»¥ï¼Œå¦‚æœä½ åœ¨ä¸­é—´æœ‰è¿™ä¸ªæ–‡æœ¬ç“¶é¢ˆå±‚ï¼Œè¿‡æ»¤æ‰ä¸æƒ³è¦çš„è¯ã€åšå‡½æ•°è°ƒç”¨ç­‰ç­‰éƒ½å¾ˆæ–¹ä¾¿ã€‚è¿™ä¾ç„¶æ˜¯éå¸¸å®ç”¨çš„ã€‚æˆ‘è§‰å¾—ç¬¬äºŒç‚¹æ˜¯â€”â€”ä¸ä»…ä»…æ˜¯çº§è”ç³»ç»Ÿæ›´æ–¹ä¾¿ï¼Œç«¯åˆ°ç«¯è¯­éŸ³çš„å¦ä¸€ä¸ªå±€é™æ˜¯ï¼šå®ƒä¼šä»æ ¹æœ¬ä¸Šé™ä½æ¨¡å‹çš„æ™ºèƒ½æ°´å¹³ï¼Œå³ä½¿ä½ ä¸åœ¨æ„å®ƒç¼ºä¹æ¨¡å—åŒ–ã€‚

è§£æï¼š
* **bottleneck** /ËˆbÉ’tlËŒnek/ ğŸ”¥ï¼šåè¯ï¼Œç“¶é¢ˆï¼ˆè¿™é‡ŒæŒ‡ä¸­é—´çš„æ–‡æœ¬å¤„ç†ç¯èŠ‚ï¼Œè™½æ˜¯é™åˆ¶ä½†ä¹Ÿæœ‰å¥½å¤„ï¼‰
* **function calling**ï¼šå‡½æ•°è°ƒç”¨ï¼ŒAI æ¨¡å‹è°ƒç”¨å¤–éƒ¨å·¥å…·/API çš„èƒ½åŠ›
* **and so on and so forth**ï¼šçŸ­è¯­ï¼Œç­‰ç­‰ã€è¯¸å¦‚æ­¤ç±»
* **fundamentally** /ËŒfÊŒndÉ™ËˆmentÉ™li/ï¼šå‰¯è¯ï¼Œä»æ ¹æœ¬ä¸Š

---

(5) [12:10-12:30]

**{And say okay, I'm happy, [I don't want to ever change my text backbone], [I'm going to train one] [I'm going to use (all my life)] â€” it will be [much dumber than [the original text model (you started from)]].} {And honestly [we don't know why exactly] â€” we have theories.} {I think [when you train on audio data], [the distribution of the audio data (in terms of content)] is [very different from text].}**

å°±ç®—ä½ è¯´"å¥½å§æˆ‘å¾ˆæ»¡æ„ï¼Œæˆ‘æ°¸è¿œä¸æƒ³æ¢æ–‡æœ¬éª¨å¹²ï¼Œæˆ‘è¦è®­ç»ƒä¸€ä¸ªç”¨ä¸€è¾ˆå­"â€”â€”å®ƒä¹Ÿä¼šæ¯”ä½ æœ€åˆçš„æ–‡æœ¬æ¨¡å‹ç¬¨å¾—å¤šã€‚è¯´å®è¯æˆ‘ä»¬å¹¶ä¸ç¡®åˆ‡çŸ¥é“ä¸ºä»€ä¹ˆï¼Œä½†æœ‰ä¸€äº›ç†è®ºã€‚æˆ‘è®¤ä¸ºå½“ä½ åœ¨éŸ³é¢‘æ•°æ®ä¸Šè®­ç»ƒæ—¶ï¼ŒéŸ³é¢‘æ•°æ®åœ¨å†…å®¹åˆ†å¸ƒä¸Šå’Œæ–‡æœ¬æœ‰å¾ˆå¤§å·®å¼‚ã€‚

è§£æï¼š
* **dumb** /dÊŒm/ï¼šå½¢å®¹è¯ï¼Œï¼ˆå£è¯­ï¼‰ç¬¨çš„ã€ä¸èªæ˜çš„ï¼ˆè¿™é‡Œå½¢å®¹æ¨¡å‹æ™ºèƒ½ä¸‹é™ï¼‰
* **distribution** /ËŒdÉªstrÉªËˆbjuËÊƒn/ï¼šåè¯ï¼Œåˆ†å¸ƒï¼ˆç»Ÿè®¡å­¦æ¦‚å¿µï¼‰
* **in terms of** ğŸ”¥ï¼šçŸ­è¯­ï¼Œåœ¨â€¦â€¦æ–¹é¢ã€å°±â€¦â€¦è€Œè¨€

---

(6) [12:30-12:48]

**{You don't have things like [Wikipedia or Stack Overflow and so on] (in audio form).} {It's mostly [people chatting with one another] like daily conversations and so on.} {So [what we've seen â€” and everybody sees this (in industry)] â€” like speech to speech models, they fall [a lot] (in intelligence) [when you go from text to speech].}**

éŸ³é¢‘é¢†åŸŸæ²¡æœ‰ **Wikipedia** æˆ– **Stack Overflow** è¿™æ ·çš„é«˜è´¨é‡çŸ¥è¯†èµ„æºã€‚éŸ³é¢‘ä¸»è¦æ˜¯äººä»¬æ—¥å¸¸èŠå¤©ã€é—²è°ˆä¹‹ç±»çš„å†…å®¹ã€‚æ‰€ä»¥æˆ‘ä»¬çœ‹åˆ°çš„â€”â€”ä¸šç•Œä¹Ÿéƒ½çœ‹åˆ°äº†â€”â€”ç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹ä»æ–‡æœ¬è½¬åˆ°è¯­éŸ³æ—¶ï¼Œæ™ºèƒ½æ°´å¹³ä¼šå¤§å¹…ä¸‹é™ã€‚

è§£æï¼š
* **in audio form**ï¼šä»¥éŸ³é¢‘å½¢å¼å­˜åœ¨ï¼ˆå¯¹æ¯”æ–‡æœ¬å½¢å¼çš„ç»“æ„åŒ–çŸ¥è¯†ï¼‰
* **chat with one another**ï¼šäº’ç›¸é—²èŠ
* **fall in intelligence** ğŸ”¥ï¼šæ™ºèƒ½æ°´å¹³ä¸‹é™ï¼ˆfall åœ¨è¿™é‡Œæ˜¯"ä¸‹é™"çš„æ„æ€ï¼‰

---

(7) [12:48-13:05]

**{So one open question [we are working on] is [how do you reduce that gap] and [how do you eventually make it so thin [that there is no measurable loss of competence] [when you go from your text model to the speech model]].} {But even if [you know how to train to turn your text model into a speech model (that is smart)] â€” because you always do that, right â€” your speech to speech model you never train it from scratch.}**

æ‰€ä»¥æˆ‘ä»¬æ­£åœ¨ç ”ç©¶çš„ä¸€ä¸ªå¼€æ”¾æ€§é—®é¢˜æ˜¯ï¼šå¦‚ä½•ç¼©å°è¿™ä¸ªå·®è·ï¼Ÿå¦‚ä½•æœ€ç»ˆè®©è¿™ä¸ªå·®è·å°åˆ°ä»æ–‡æœ¬æ¨¡å‹è½¬åˆ°è¯­éŸ³æ¨¡å‹æ—¶æ²¡æœ‰å¯è¡¡é‡çš„èƒ½åŠ›æŸå¤±ï¼Ÿä½†å³ä½¿ä½ çŸ¥é“æ€ä¹ˆæŠŠæ–‡æœ¬æ¨¡å‹è®­ç»ƒæˆä¸€ä¸ªèªæ˜çš„è¯­éŸ³æ¨¡å‹â€”â€”å› ä¸ºä½ æ€»æ˜¯è¿™ä¹ˆåšâ€”â€”ç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹ä»æ¥ä¸ä¼šä»é›¶å¼€å§‹è®­ç»ƒã€‚

è§£æï¼š
* **open question**ï¼šå¼€æ”¾æ€§é—®é¢˜ï¼Œå°šæœªè§£å†³çš„ç ”ç©¶é—®é¢˜
* **measurable** /ËˆmeÊ’É™rÉ™bl/ï¼šå½¢å®¹è¯ï¼Œå¯è¡¡é‡çš„
* **competence** /ËˆkÉ’mpÉªtÉ™ns/ï¼šåè¯ï¼Œèƒ½åŠ›ã€èƒœä»»åŠ›
* **from scratch** ğŸ”¥ï¼šçŸ­è¯­ï¼Œä»é›¶å¼€å§‹ã€ä»å¤´å¼€å§‹

---

(8) [13:05-13:23]

**{It's impossible [to make an intelligent model] [just by listening to conversation].} {So you always start from [knowledge acquired from text] and then you train it [to learn how to speak].} {But even if we do that, then there is still something [that is a bit annoying] (in terms of real applications for developers) â€” is [let's say you have a new text model and you want to turn it into a speech model].}**

ä»…ä»…é å¬å¯¹è¯æ˜¯ä¸å¯èƒ½è®­ç»ƒå‡ºä¸€ä¸ªæ™ºèƒ½æ¨¡å‹çš„ã€‚æ‰€ä»¥ä½ æ€»æ˜¯ä»æ–‡æœ¬è·å–çš„çŸ¥è¯†å‡ºå‘ï¼Œç„¶åå†è®­ç»ƒæ¨¡å‹å­¦ä¼šè¯´è¯ã€‚ä½†å³ä½¿æˆ‘ä»¬åšåˆ°äº†è¿™ç‚¹ï¼Œå¯¹å¼€å‘è€…çš„å®é™…åº”ç”¨æ¥è¯´ï¼Œè¿˜æœ‰ä¸€ä¸ªæ¯”è¾ƒçƒ¦äººçš„é—®é¢˜â€”â€”å‡è®¾ä½ æœ‰ä¸€ä¸ªæ–°çš„æ–‡æœ¬æ¨¡å‹ï¼Œæƒ³æŠŠå®ƒè½¬åŒ–ä¸ºè¯­éŸ³æ¨¡å‹ã€‚

è§£æï¼š
* **acquire** /É™ËˆkwaÉªÉ™r/ï¼šåŠ¨è¯ï¼Œè·å–ã€ä¹ å¾—
* **in terms of** ğŸ”¥ï¼šçŸ­è¯­ï¼Œåœ¨â€¦â€¦æ–¹é¢ï¼ˆå†æ¬¡å‡ºç°ï¼Œé«˜é¢‘è¡¨è¾¾ï¼‰
* **annoying** /É™ËˆnÉ”ÉªÉªÅ‹/ï¼šå½¢å®¹è¯ï¼Œçƒ¦äººçš„ã€ä»¤äººæ¼ç«çš„
* **let's say**ï¼šçŸ­è¯­ï¼Œå‡è®¾è¯´ã€æ¯”æ–¹è¯´ï¼ˆå£è¯­ä¸­å¼•å‡ºå‡è®¾åœºæ™¯ï¼‰

---

(9) [13:23-13:46]

**{You're going to need [to fine-tune it] (over significant amounts of data) and so on.} {So basically the end goal is [the same advantages of cascaded systems] â€” [which is mostly the modularity and how steerable they are] â€” but with [the naturalness of a full duplex model] â€” and that's the kind of problem [we're working on].}**

ä½ éœ€è¦åœ¨å¤§é‡æ•°æ®ä¸Šå¯¹å®ƒè¿›è¡Œå¾®è°ƒç­‰ç­‰ã€‚æ‰€ä»¥åŸºæœ¬ä¸Šæœ€ç»ˆç›®æ ‡æ˜¯ï¼šæ—¢æ‹¥æœ‰çº§è”ç³»ç»Ÿçš„ä¼˜åŠ¿â€”â€”ä¸»è¦æ˜¯æ¨¡å—åŒ–å’Œå¯æ§æ€§â€”â€”åˆå…·å¤‡å…¨åŒå·¥æ¨¡å‹çš„è‡ªç„¶åº¦ã€‚è¿™å°±æ˜¯æˆ‘ä»¬æ­£åœ¨æ”»å…‹çš„é—®é¢˜ã€‚

è§£æï¼š
* **fine-tune** ğŸ”¥ï¼šåŠ¨è¯ï¼Œå¾®è°ƒï¼ˆåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸Šç”¨ç‰¹å®šæ•°æ®ç»§ç»­è®­ç»ƒï¼‰
* **significant amounts of**ï¼šå¤§é‡çš„
* **steerable** /ËˆstÉªÉ™rÉ™bl/ï¼šå½¢å®¹è¯ï¼Œå¯æ“æ§çš„ã€å¯å¼•å¯¼çš„ï¼ˆæ¥è‡ª steerï¼‰
* **full duplex** ğŸ”¥ï¼šå…¨åŒå·¥ï¼ŒåŒæ–¹å¯ä»¥åŒæ—¶è¯´è¯å’Œå¬çš„é€šä¿¡æ¨¡å¼

---

(10) [13:46-14:15]

**{Yeah, that's super interesting.} {So in the data problem â€” is it because the data, it's hard to get the data, or like what is keeping people from [being able to create (really high quality) data sets] today and then feed those into the model?} {Is it [that there's still too much information for the models to be paying attention to [the logic pieces of it]]] or is it [that that data doesn't exist]?} {Yeah. Where are the gaps?}**

å—¯ï¼Œè¿™ä¸ªå¤ªæœ‰æ„æ€äº†ã€‚é‚£å…³äºæ•°æ®é—®é¢˜â€”â€”æ˜¯å› ä¸ºæ•°æ®éš¾ä»¥è·å–å—ï¼Ÿè¿˜æ˜¯è¯´æ˜¯ä»€ä¹ˆé˜»ç¢äº†äººä»¬åˆ›å»ºçœŸæ­£é«˜è´¨é‡çš„æ•°æ®é›†å¹¶è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼Ÿæ˜¯å› ä¸ºä¿¡æ¯å¤ªå¤šå¯¼è‡´æ¨¡å‹éš¾ä»¥å…³æ³¨åˆ°é€»è¾‘éƒ¨åˆ†ï¼Œè¿˜æ˜¯è¯´è¿™äº›æ•°æ®æ ¹æœ¬å°±ä¸å­˜åœ¨ï¼Ÿæ˜¯å•Šï¼Œå·®è·åˆ°åº•åœ¨å“ªé‡Œï¼Ÿ

è§£æï¼š
* **data set**ï¼šæ•°æ®é›†ï¼ˆæ¨¡å‹è®­ç»ƒç”¨çš„æ•°æ®é›†åˆï¼‰
* **feed into** ğŸ”¥ï¼šçŸ­è¯­ï¼Œè¾“å…¥åˆ°ã€å–‚ç»™ï¼ˆå¸¸ç”¨äºæè¿°ç»™æ¨¡å‹æä¾›æ•°æ®ï¼‰
* **pay attention to**ï¼šçŸ­è¯­ï¼Œå…³æ³¨ã€æ³¨æ„ï¼ˆæ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶æ¦‚å¿µï¼‰
* **gap** /É¡Ã¦p/ï¼šåè¯ï¼Œå·®è·ã€ç¼ºå£

---

(11) [14:15-14:43]

**{So [if you look at the number of tokens [that are used to train a text language model]], it's like trillions of tokens.} {So [if you look at the size of training sets for text LLM (which is in trillions of tokens)], the equivalent for audio language models will be [hundreds of millions of hours to billions of hours] of speech data.} {So good luck (on creating this data).}**

å¦‚æœä½ çœ‹è®­ç»ƒæ–‡æœ¬è¯­è¨€æ¨¡å‹ç”¨çš„ **token** æ•°é‡ï¼Œé‚£æ˜¯æ•°ä¸‡äº¿çº§åˆ«çš„ã€‚æ‰€ä»¥å¦‚æœæ–‡æœ¬å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒé›†è§„æ¨¡æ˜¯ä¸‡äº¿ **token** é‡çº§ï¼Œé‚£ä¹ˆéŸ³é¢‘è¯­è¨€æ¨¡å‹çš„ç­‰ä»·è§„æ¨¡å°†æ˜¯æ•°äº¿åˆ°æ•°åäº¿å°æ—¶çš„è¯­éŸ³æ•°æ®ã€‚ç¥ä½ å¥½è¿å»åˆ›å»ºè¿™äº›æ•°æ®å§ï¼ˆç¬‘ï¼‰ã€‚

è§£æï¼š
* **trillion** /ËˆtrÉªljÉ™n/ï¼šæ•°è¯ï¼Œä¸‡äº¿ï¼ˆ1,000,000,000,000ï¼‰
* **equivalent** /ÉªËˆkwÉªvÉ™lÉ™nt/ ğŸ”¥ï¼šåè¯/å½¢å®¹è¯ï¼Œç­‰ä»·ç‰©ã€ç­‰åŒçš„
* **good luck on**ï¼šçŸ­è¯­ï¼Œç¥å¥½è¿ï¼ˆè¿™é‡Œæ˜¯åè®½è¯­æ°”ï¼Œè¡¨ç¤ºå‡ ä¹ä¸å¯èƒ½ï¼‰

---

(12) [14:43-15:07]

**{But at the same time, you know, we have [the intelligence from the text], right? So it would be a shame [not to leverage it].} {So I think the main idea is [to find the right data [that will minimize [how much speech data you need] [to turn your text model into speech model]]]} and there are [a lot of ways to think about it] â€” one is curation, one is synthetic data, and then you combine it with [reinforcement learning] [to try to realign your model (with its original behavior)].}**

ä½†åŒæ—¶ï¼Œæˆ‘ä»¬å·²ç»æœ‰æ¥è‡ªæ–‡æœ¬çš„æ™ºèƒ½äº†ï¼Œä¸æ˜¯å—ï¼Ÿä¸å»åˆ©ç”¨å®ƒå°±å¤ªå¯æƒœäº†ã€‚æ‰€ä»¥æˆ‘è®¤ä¸ºæ ¸å¿ƒæ€è·¯æ˜¯æ‰¾åˆ°åˆé€‚çš„æ•°æ®ï¼Œå°½é‡å‡å°‘å°†æ–‡æœ¬æ¨¡å‹è½¬åŒ–ä¸ºè¯­éŸ³æ¨¡å‹æ‰€éœ€çš„è¯­éŸ³æ•°æ®é‡ã€‚æœ‰å¾ˆå¤šæ€è·¯å¯ä»¥å°è¯•â€”â€”ä¸€ä¸ªæ˜¯æ•°æ®ç²¾é€‰ï¼Œä¸€ä¸ªæ˜¯åˆæˆæ•°æ®ï¼Œç„¶åå†ç»“åˆå¼ºåŒ–å­¦ä¹ æ¥æŠŠæ¨¡å‹é‡æ–°å¯¹é½å›åŸæ¥çš„è¡Œä¸ºã€‚

è§£æï¼š
* **leverage** /ËˆlevÉ™rÉªdÊ’/ ğŸ”¥ï¼šåŠ¨è¯ï¼Œåˆ©ç”¨ã€å‘æŒ¥æ æ†ä½œç”¨
* **it would be a shame**ï¼šçŸ­è¯­ï¼Œé‚£å°±å¤ªå¯æƒœäº†
* **curation** /kjÊŠËˆreÉªÊƒn/ï¼šåè¯ï¼Œç²¾é€‰ã€ç­–å±•ï¼ˆè¿™é‡ŒæŒ‡ç²¾å¿ƒæŒ‘é€‰è®­ç»ƒæ•°æ®ï¼‰
* **synthetic data**ï¼šåˆæˆæ•°æ®ï¼Œäººå·¥ç”Ÿæˆçš„è®­ç»ƒæ•°æ®
* **reinforcement learning**ï¼šå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œé€šè¿‡å¥–åŠ±ä¿¡å·è®­ç»ƒæ¨¡å‹
* **realign** /ËŒriËÉ™ËˆlaÉªn/ï¼šåŠ¨è¯ï¼Œé‡æ–°å¯¹é½ã€é‡æ–°æ ¡å‡†

---

(13) [15:07-15:25]

**{So there are solutions.} {I'm very optimistic about it.} {It's just that it's still an ongoing problem.} {I have no doubt [about the fact that it's going to work out] and that hopefully (in the coming few years) we'll see [the current cascade of voice agents] as archaic and brittle and so on.}**

æ‰€ä»¥æ˜¯æœ‰è§£å†³æ–¹æ¡ˆçš„ã€‚æˆ‘å¯¹æ­¤éå¸¸ä¹è§‚ã€‚åªæ˜¯è¿™ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­è¿›è¡Œä¸­çš„ç ”ç©¶é—®é¢˜ã€‚æˆ‘æ¯«ä¸æ€€ç–‘è¿™æœ€ç»ˆä¼šè¡Œå¾—é€šï¼Œå¸Œæœ›åœ¨æœªæ¥å‡ å¹´å†…ï¼Œæˆ‘ä»¬ä¼šè§‰å¾—å½“å‰çš„çº§è”å¼è¯­éŸ³ä»£ç†éå¸¸è¿‡æ—¶ã€éå¸¸è„†å¼±ã€‚

è§£æï¼š
* **ongoing** /ËˆÉ’nÉ¡oÊŠÉªÅ‹/ï¼šå½¢å®¹è¯ï¼ŒæŒç»­è¿›è¡Œä¸­çš„
* **work out** ğŸ”¥ï¼šçŸ­è¯­åŠ¨è¯ï¼ŒæˆåŠŸã€è¡Œå¾—é€š
* **archaic** /É‘ËrËˆkeÉªÉªk/ï¼šå½¢å®¹è¯ï¼Œè¿‡æ—¶çš„ã€é™ˆæ—§çš„
* **brittle** /ËˆbrÉªtl/ï¼šå½¢å®¹è¯ï¼Œè„†å¼±çš„ã€æ˜“ç¢çš„ï¼ˆå½¢å®¹ç³»ç»Ÿä¸å¤Ÿé²æ£’ï¼‰

---

(14) [15:25-15:52]

**{What I'm seeing is â€” you're more expert than me (in terms of the adoption of voice agents) â€” but my take is [there was like a parallel maturation of voice [becoming more accurate (on the transcription side)] and [more expressive (on the TTS side)]], but also [the underlying LLMs being more useful].} {Right now they can do actual actions.} {They can book a meeting.} {They can go and query a database to just be [actually a useful agent].}**

æˆ‘çœ‹åˆ°çš„æ˜¯â€”â€”ä½ åœ¨è¯­éŸ³ä»£ç†çš„åº”ç”¨æ–¹é¢æ¯”æˆ‘æ›´æœ‰ç»éªŒâ€”â€”ä½†æˆ‘çš„çœ‹æ³•æ˜¯ï¼Œè¿™æ˜¯ä¸€ä¸ªå¹¶è¡Œæˆç†Ÿçš„è¿‡ç¨‹ï¼šè¯­éŸ³åœ¨è½¬å½•ç«¯å˜å¾—æ›´å‡†ç¡®ã€åœ¨ **TTS** ç«¯å˜å¾—æ›´æœ‰è¡¨ç°åŠ›ï¼ŒåŒæ—¶åº•å±‚çš„å¤§è¯­è¨€æ¨¡å‹ä¹Ÿå˜å¾—æ›´å®ç”¨äº†ã€‚ç°åœ¨å®ƒä»¬å¯ä»¥æ‰§è¡Œå®é™…æ“ä½œäº†â€”â€”é¢„è®¢ä¼šè®®ã€æŸ¥è¯¢æ•°æ®åº“ï¼ŒçœŸæ­£æˆä¸ºä¸€ä¸ªæœ‰ç”¨çš„ä»£ç†ã€‚

è§£æï¼š
* **my take is** ğŸ”¥ï¼šçŸ­è¯­ï¼Œæˆ‘çš„çœ‹æ³•/è§‚ç‚¹æ˜¯ï¼ˆå£è¯­åŒ–è¡¨è¾¾ï¼‰
* **parallel maturation**ï¼šå¹¶è¡Œæˆç†Ÿï¼Œå¤šä¸ªé¢†åŸŸåŒæ­¥å‘å±•è¿›æ­¥
* **transcription** /trÃ¦nËˆskrÉªpÊƒn/ï¼šåè¯ï¼Œè½¬å½•ï¼ˆè¯­éŸ³è½¬æ–‡å­—ï¼‰
* **expressive** /ÉªkËˆspresÉªv/ï¼šå½¢å®¹è¯ï¼Œå¯Œæœ‰è¡¨ç°åŠ›çš„
* **query** /ËˆkwÉªri/ï¼šåŠ¨è¯ï¼ŒæŸ¥è¯¢

---

(15) [15:52-16:10]

**{But at the same time, there are [a lot of use cases] [where it still breaks].} {One example I like is robotics because voice agents are, I think, in [a kind of a controlled setting] [when you're on the phone].} {But now imagine [that you are in a factory and you have a robot and you want them to interact with [a lot of people (around them)]]...}**

ä½†ä¸æ­¤åŒæ—¶ï¼Œåœ¨å¾ˆå¤šä½¿ç”¨åœºæ™¯ä¸‹å®ƒä»ç„¶ä¼šå´©æºƒã€‚æˆ‘å–œæ¬¢ä¸¾çš„ä¸€ä¸ªä¾‹å­æ˜¯æœºå™¨äººé¢†åŸŸâ€”â€”å› ä¸ºè¯­éŸ³ä»£ç†åœ¨ä½ æ‰“ç”µè¯æ—¶å…¶å®æ˜¯åœ¨ä¸€ç§å—æ§ç¯å¢ƒä¸­ã€‚ä½†ç°åœ¨æƒ³è±¡ä¸€ä¸‹ï¼Œä½ åœ¨ä¸€ä¸ªå·¥å‚é‡Œï¼Œæœ‰ä¸€ä¸ªæœºå™¨äººï¼Œä½ æƒ³è®©å®ƒå’Œå‘¨å›´å¾ˆå¤šäººäº’åŠ¨â€¦â€¦

è§£æï¼š
* **use case** ğŸ”¥ï¼šä½¿ç”¨åœºæ™¯ã€ç”¨ä¾‹
* **break**ï¼šåŠ¨è¯ï¼Œï¼ˆç³»ç»Ÿï¼‰å´©æºƒã€å‡ºé—®é¢˜ï¼ˆå£è¯­ç”¨æ³•ï¼‰
* **robotics** /roÊŠËˆbÉ’tÉªks/ï¼šåè¯ï¼Œæœºå™¨äººå­¦/é¢†åŸŸ
* **controlled setting**ï¼šå—æ§ç¯å¢ƒ

---

(16) [16:10-16:28]

**{...and there are machines and there's background noise and people talking (from various positions) (to the same robot) and [the robot has to figure out [what the hell is going on]].} {You know, that's â€” there is no framework for that.} {There is no model [that addresses this kind of challenging environment].}**

â€¦â€¦å‘¨å›´è¿˜æœ‰æœºå™¨è®¾å¤‡ã€èƒŒæ™¯å™ªéŸ³ï¼Œä¸åŒä½ç½®çš„äººå¯¹ç€åŒä¸€ä¸ªæœºå™¨äººè¯´è¯ï¼Œè€Œæœºå™¨äººéœ€è¦ææ¸…æ¥šåˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆã€‚ä½ çŸ¥é“çš„ï¼Œç›®å‰æ²¡æœ‰ä»»ä½•æ¡†æ¶èƒ½å¤„ç†è¿™ç§åœºæ™¯ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•æ¨¡å‹èƒ½åº”å¯¹è¿™ç§é«˜æŒ‘æˆ˜æ€§çš„ç¯å¢ƒã€‚

è§£æï¼š
* **background noise**ï¼šèƒŒæ™¯å™ªéŸ³
* **what the hell is going on** ğŸ”¥ï¼šåˆ°åº•å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆåŠ  the hell è¡¨ç¤ºå¼ºè°ƒå’Œå›°æƒ‘ï¼‰
* **framework** /ËˆfreÉªmwÉœËrk/ï¼šåè¯ï¼Œæ¡†æ¶ï¼ˆæŠ€æœ¯é¢†åŸŸçš„åŸºç¡€æ¶æ„æˆ–å·¥å…·é›†ï¼‰
* **address** /É™Ëˆdres/ï¼šåŠ¨è¯ï¼Œè§£å†³ã€å¤„ç†ï¼ˆæ­£å¼ç”¨æ³•ï¼‰

---

(17) [16:28-16:52]

**{I'm interested in robotics as well because we are talking with companies [that try to make robots [that can be in your home]].} {And [when they are in your home] they are not on the phone with you â€” you may want to be [walking in a room] and [shouting from far] and so on.} {All of this breaks completely [the speech to text and the turn taking] and whatever.}**

æˆ‘å¯¹æœºå™¨äººé¢†åŸŸä¹Ÿå¾ˆæ„Ÿå…´è¶£ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨å’Œä¸€äº›å…¬å¸äº¤æµï¼Œå®ƒä»¬è¯•å›¾åˆ¶é€ èƒ½è¿›å…¥å®¶åº­çš„æœºå™¨äººã€‚å½“æœºå™¨äººåœ¨ä½ å®¶é‡Œæ—¶ï¼Œå®ƒä¸æ˜¯åœ¨è·Ÿä½ æ‰“ç”µè¯â€”â€”ä½ å¯èƒ½åœ¨æˆ¿é—´é‡Œèµ°æ¥èµ°å»ã€ä»å¾ˆè¿œçš„åœ°æ–¹å¤§å£°å–Šè¯ç­‰ç­‰ã€‚è¿™äº›æƒ…å†µä¼šå®Œå…¨æ‰“ç ´è¯­éŸ³è½¬æ–‡å­—å’Œè½®æ¬¡ç®¡ç†çš„æœºåˆ¶ã€‚

è§£æï¼š
* **talk with companies**ï¼šå’Œå…¬å¸äº¤æµã€åˆä½œæ´½è°ˆ
* **shout from far**ï¼šä»è¿œå¤„å¤§å£°å–Š
* **break completely**ï¼šå®Œå…¨æ‰“ç ´ã€å½»åº•ç ´åï¼ˆç³»ç»Ÿæ— æ³•æ­£å¸¸å·¥ä½œï¼‰

---

(18) [16:52-17:06]

**{You know, I think [a lot of use cases] are still [just non-existent] today and are going to be [major applications of voice].} {And it's really, you know, there are [a lot of technical challenges to address] [before we reach that point].}**

æˆ‘è§‰å¾—å¾ˆå¤šä½¿ç”¨åœºæ™¯ç°åœ¨æ ¹æœ¬è¿˜ä¸å­˜åœ¨ï¼Œä½†å®ƒä»¬æœªæ¥å°†æˆä¸ºè¯­éŸ³æŠ€æœ¯çš„é‡å¤§åº”ç”¨æ–¹å‘ã€‚è€Œä¸”ç¡®å®ï¼Œåœ¨æˆ‘ä»¬è¾¾åˆ°é‚£ä¸ªé˜¶æ®µä¹‹å‰ï¼Œè¿˜æœ‰å¾ˆå¤šæŠ€æœ¯æŒ‘æˆ˜éœ€è¦æ”»å…‹ã€‚

è§£æï¼š
* **non-existent** /ËŒnÉ’nÉªÉ¡ËˆzÉªstÉ™nt/ï¼šå½¢å®¹è¯ï¼Œä¸å­˜åœ¨çš„
* **major application**ï¼šé‡å¤§åº”ç”¨
* **reach that point**ï¼šè¾¾åˆ°é‚£ä¸ªé˜¶æ®µ/æ°´å¹³

---

(19) [17:06-17:23]

**{Totally. Yeah.} {And I think [people discount [just how different you speak (in different environments)]].} {There's like [the 3D aspect of sound] [that we totally don't take into account today].} {Like if someone's speaking (from farther away), that's probably not [the one (that you're listening to)] â€” except for the fact [that if everyone's looking at that person], now that is [the person (you should be thinking about)].}**

å®Œå…¨åŒæ„ã€‚æˆ‘è§‰å¾—äººä»¬ä½ä¼°äº†åœ¨ä¸åŒç¯å¢ƒä¸‹è¯´è¯æ–¹å¼çš„å·®å¼‚æœ‰å¤šå¤§ã€‚å£°éŸ³æœ‰ä¸€ä¸ªä¸‰ç»´çš„ç©ºé—´ç‰¹æ€§ï¼Œè€Œæˆ‘ä»¬ä»Šå¤©å®Œå…¨æ²¡æœ‰è€ƒè™‘åˆ°ã€‚æ¯”å¦‚å¦‚æœæœ‰äººä»è¾ƒè¿œçš„åœ°æ–¹è¯´è¯ï¼Œé‚£å¯èƒ½ä¸æ˜¯ä½ åœ¨å¬çš„å¯¹è±¡â€”â€”ä½†å¦‚æœæ‰€æœ‰äººéƒ½åœ¨çœ‹é‚£ä¸ªäººï¼Œé‚£ä»–æ‰æ˜¯ä½ åº”è¯¥å…³æ³¨çš„äººã€‚

è§£æï¼š
* **discount** /dÉªsËˆkaÊŠnt/ ğŸ”¥ï¼šåŠ¨è¯ï¼Œä½ä¼°ã€å¿½è§†ï¼ˆä¸æ˜¯"æ‰“æŠ˜"çš„æ„æ€ï¼ï¼‰
* **3D aspect of sound**ï¼šå£°éŸ³çš„ä¸‰ç»´ç©ºé—´ç‰¹æ€§
* **take into account** ğŸ”¥ï¼šçŸ­è¯­ï¼Œè€ƒè™‘åˆ°ã€çº³å…¥è€ƒé‡
* **farther away**ï¼šæ›´è¿œçš„åœ°æ–¹

---

(20) [17:23-17:39]

**{Or [if there's something in the background [that's louder than the person speaking]], but it sounds like a TV â€” as a human, you naturally filter this out.} {So there's that aspect, but then there's also the aspect of [there's lots of different ways [in which people speak (in different environments)]].}**

æˆ–è€…èƒŒæ™¯ä¸­æœ‰æ¯”è¯´è¯äººæ›´å“çš„å£°éŸ³ï¼Œä½†å¬èµ·æ¥åƒç”µè§†â€”â€”ä½œä¸ºäººç±»ï¼Œä½ ä¼šè‡ªç„¶åœ°è¿‡æ»¤æ‰è¿™äº›ã€‚é™¤äº†è¿™ä¸ªæ–¹é¢ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªæ–¹é¢æ˜¯ï¼šäººä»¬åœ¨ä¸åŒç¯å¢ƒä¸‹çš„è¯´è¯æ–¹å¼æœ‰å¾ˆå¤šç§å·®å¼‚ã€‚

è§£æï¼š
* **filter out** ğŸ”¥ï¼šçŸ­è¯­åŠ¨è¯ï¼Œè¿‡æ»¤æ‰ã€æ’é™¤ï¼ˆäººç±»è‡ªç„¶çš„å¬è§‰å¤„ç†èƒ½åŠ›ï¼‰
* **aspect** /ËˆÃ¦spekt/ï¼šåè¯ï¼Œæ–¹é¢ã€å±‚é¢

---

(21) [17:39-17:57]

**{And I think Notebook LLM is a great example of this â€” where [the speech (that comes out of Notebook LLM)] is so cool because it sounds so much like a podcast} {and so different than a customer service call, [which is so different than [just reading text out loud (from like Wikipedia)]].} {Even the phrasing, etc.}**

æˆ‘è§‰å¾— **Notebook LLM** å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­â€”â€”å®ƒç”Ÿæˆçš„è¯­éŸ³éå¸¸é…·ï¼Œå› ä¸ºå¬èµ·æ¥çœŸçš„å¾ˆåƒæ’­å®¢ï¼Œå’Œå®¢æœç”µè¯çš„å£°éŸ³å®Œå…¨ä¸åŒï¼Œè€Œå®¢æœåˆå’Œç›´æ¥å¤§å£°æœ—è¯» **Wikipedia** çš„æ–‡æœ¬å®Œå…¨ä¸åŒã€‚è¿æªè¾æ–¹å¼éƒ½ä¸ä¸€æ ·ã€‚

è§£æï¼š
* **Notebook LLM**ï¼šGoogle çš„éŸ³é¢‘æ‘˜è¦äº§å“ï¼Œèƒ½æŠŠæ–‡æ¡£è½¬åŒ–ä¸ºæ’­å®¢å¼å¯¹è¯
* **phrasing** /ËˆfreÉªzÉªÅ‹/ ğŸ”¥ï¼šåè¯ï¼Œæªè¾ã€è¡¨è¾¾æ–¹å¼
* **customer service call**ï¼šå®¢æœç”µè¯
* **read out loud**ï¼šå¤§å£°æœ—è¯»

---

(22) [17:57-18:17]

**{And I think the same would be true of YouTube â€” like how a YouTuber speaks.} {"Guys, welcome back to my channel" â€” and you instantly know [that that's a YouTuber], not like someone on the phone, or a news anchor, or, you know, all these different environments.} {I think [being able to create speech models (for those different environments)] is really, really interesting.}**

æˆ‘è§‰å¾— **YouTube** ä¹Ÿæ˜¯ä¸€æ ·â€”â€”æ¯”å¦‚ YouTuber çš„è¯´è¯æ–¹å¼ã€‚"å˜¿å¤§å®¶å¥½ï¼Œæ¬¢è¿å›åˆ°æˆ‘çš„é¢‘é“"â€”â€”ä½ ç«‹åˆ»å°±çŸ¥é“é‚£æ˜¯ä¸ª YouTuberï¼Œè€Œä¸æ˜¯æ‰“ç”µè¯çš„äººã€ä¹Ÿä¸æ˜¯æ–°é—»ä¸»æ’­ã€‚ä½ çŸ¥é“çš„ï¼Œè¿™äº›ä¸åŒçš„ç¯å¢ƒã€‚æˆ‘è§‰å¾—èƒ½å¤Ÿä¸ºè¿™äº›ä¸åŒç¯å¢ƒåˆ›å»ºè¯­éŸ³æ¨¡å‹çœŸçš„éå¸¸æœ‰è¶£ã€‚

è§£æï¼š
* **YouTuber**ï¼šYouTube å†…å®¹åˆ›ä½œè€…
* **news anchor** /ËˆÃ¦Å‹kÉ™r/ï¼šæ–°é—»ä¸»æ’­
* **instantly** /ËˆÉªnstÉ™ntli/ï¼šå‰¯è¯ï¼Œç«‹å³ã€ç¬é—´

---

(23) [18:17-18:37]

**{Yeah. So, I think this one is [one of the main challenges right now] (in particular already on the TTS side).} {[If we forget about the whole dynamics of the conversation], just having models [that are able to express appropriate emotions (at the right time)], [the same way a human will do], it's a strong limitation.}**

æ˜¯çš„ã€‚æˆ‘è®¤ä¸ºè¿™æ˜¯ç›®å‰çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€ï¼Œç‰¹åˆ«æ˜¯åœ¨ **TTS** æ–¹é¢ã€‚å¦‚æœæˆ‘ä»¬å…ˆä¸ç®¡å¯¹è¯çš„æ•´ä½“åŠ¨æ€ï¼Œå…‰æ˜¯è®©æ¨¡å‹èƒ½å¤Ÿåœ¨æ­£ç¡®çš„æ—¶é—´è¡¨è¾¾æ°å½“çš„æƒ…ç»ªâ€”â€”åƒäººç±»é‚£æ ·â€”â€”å°±å·²ç»æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„å±€é™äº†ã€‚

è§£æï¼š
* **TTS**ï¼šText-to-Speechï¼Œæ–‡æœ¬è½¬è¯­éŸ³
* **dynamics** /daÉªËˆnÃ¦mÉªks/ï¼šåè¯ï¼ŒåŠ¨æ€ã€åŠ¨åŠ›å­¦ï¼ˆè¿™é‡ŒæŒ‡å¯¹è¯çš„åŠ¨æ€å˜åŒ–ï¼‰
* **appropriate** /É™ËˆproÊŠpriÉ™t/ ğŸ”¥ï¼šå½¢å®¹è¯ï¼Œæ°å½“çš„ã€åˆé€‚çš„
* **limitation** /ËŒlÉªmÉªËˆteÉªÊƒn/ï¼šåè¯ï¼Œå±€é™ã€é™åˆ¶

---

(24) [18:37-19:01]

**{It's very interesting â€” something we have documented and will post soon about â€” it's mainly due to voice cloning.} {So [when you do voice cloning], you basically [train your model to be [as faithful as possible] (to the original voice)].} {But (from the point of view of the model and its loss function) [for which it's trained and that it tries to minimize], [replicating consistently the emotion (that is in its original voice sample)] is like a successful [just doing its job] as voice cloning.}**

è¿™éå¸¸æœ‰è¶£â€”â€”æˆ‘ä»¬å·²ç»æœ‰ç›¸å…³è®°å½•ï¼Œå¾ˆå¿«ä¼šå‘å¸ƒã€‚è¿™ä¸»è¦æ˜¯ç”±äºå£°éŸ³å…‹éš†ã€‚å½“ä½ åšå£°éŸ³å…‹éš†æ—¶ï¼Œä½ åŸºæœ¬ä¸Šæ˜¯è®­ç»ƒæ¨¡å‹å°½å¯èƒ½å¿ å®åœ°è¿˜åŸåŸå§‹å£°éŸ³ã€‚ä½†ä»æ¨¡å‹çš„è§†è§’å’Œå®ƒè¦æœ€å°åŒ–çš„æŸå¤±å‡½æ•°æ¥çœ‹ï¼Œå§‹ç»ˆå¦‚ä¸€åœ°å¤åˆ¶åŸå§‹å£°éŸ³æ ·æœ¬ä¸­çš„æƒ…ç»ªï¼Œå°±ç­‰äºæˆåŠŸå®Œæˆäº†å£°éŸ³å…‹éš†çš„ä»»åŠ¡ã€‚

è§£æï¼š
* **voice cloning** ğŸ”¥ï¼šå£°éŸ³å…‹éš†ï¼Œå¤åˆ¶æŸäººå£°éŸ³ç‰¹å¾çš„æŠ€æœ¯
* **faithful** /ËˆfeÉªÎ¸fl/ï¼šå½¢å®¹è¯ï¼Œå¿ å®çš„ã€å¿ äºåŸç‰ˆçš„
* **loss function**ï¼šæŸå¤±å‡½æ•°ï¼ˆæ¨¡å‹è®­ç»ƒä¸­è¡¡é‡é¢„æµ‹ä¸çœŸå®å€¼å·®è·çš„å‡½æ•°ï¼‰
* **replicate** /ËˆreplÉªkeÉªt/ï¼šåŠ¨è¯ï¼Œå¤åˆ¶ã€å†ç°
* **consistently** /kÉ™nËˆsÉªstÉ™ntli/ï¼šå‰¯è¯ï¼Œå§‹ç»ˆå¦‚ä¸€åœ°

---

(25) [19:01-19:24]

**{So what this means is that â€” that explains [why all models at the moment], [if you put a voice (that is very serious)], are going to typically speak [steadily in a serious tone].} {Or [if it's a very enthusiastic voice], they are going to speak with [that enthusiasm] â€” because the model feels like [it's just solving its task], like [it's replicating the voice (from the original sample)].}**

è¿™å°±è§£é‡Šäº†ä¸ºä»€ä¹ˆç›®å‰æ‰€æœ‰çš„æ¨¡å‹ï¼Œå¦‚æœä½ è¾“å…¥ä¸€ä¸ªå¾ˆä¸¥è‚ƒçš„å£°éŸ³ï¼Œå®ƒé€šå¸¸å°±ä¼šä¸€ç›´ä»¥ä¸¥è‚ƒç¨³é‡çš„è¯­è°ƒè¯´è¯ã€‚æˆ–è€…å¦‚æœæ˜¯ä¸€ä¸ªå¾ˆçƒ­æƒ…çš„å£°éŸ³ï¼Œå®ƒä»¬å°±ä¼šä¸€ç›´ç”¨é‚£ç§çƒ­æƒ…çš„æ–¹å¼è¯´è¯â€”â€”å› ä¸ºæ¨¡å‹è§‰å¾—å®ƒåªæ˜¯åœ¨å®Œæˆä»»åŠ¡ã€åœ¨å¤åˆ¶åŸå§‹æ ·æœ¬ä¸­çš„å£°éŸ³ç‰¹å¾ã€‚

è§£æï¼š
* **steadily** /ËˆstedÉªli/ï¼šå‰¯è¯ï¼Œç¨³å®šåœ°ã€æŒç»­åœ°
* **tone** /toÊŠn/ï¼šåè¯ï¼Œè¯­è°ƒã€éŸ³è°ƒ
* **enthusiastic** /ÉªnËŒÎ¸juËziËˆÃ¦stÉªk/ ğŸ”¥ï¼šå½¢å®¹è¯ï¼Œçƒ­æƒ…çš„ã€å……æ»¡çƒ­å¿±çš„
* **enthusiasm** /ÉªnËˆÎ¸juËziÃ¦zÉ™m/ï¼šåè¯ï¼Œçƒ­æƒ…ã€çƒ­å¿±

---

(26) [19:24-19:50]

**{However, ideally [I would clone your voice (in an arbitrary emotion)], you know, and then be able to express [the natural variability of emotion, intonations, interrogation, exclamation and so on] [while replicating your voice].} {So what this means is [disentangling [what are the intrinsic characteristics of someone] and [what is very specific to the sentence (that we used to do the cloning)]].}**

ä½†ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘æƒ³ä»¥ä»»æ„ä¸€ç§æƒ…ç»ªæ¥å…‹éš†ä½ çš„å£°éŸ³ï¼Œç„¶ååœ¨å¤åˆ¶ä½ çš„å£°éŸ³çš„åŒæ—¶ï¼Œèƒ½è¡¨è¾¾æƒ…ç»ªçš„è‡ªç„¶å˜åŒ–â€”â€”è¯­è°ƒã€ç–‘é—®ã€æƒŠå¹ç­‰ç­‰ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦è§£è€¦ä¸¤ä»¶äº‹ï¼šä¸€ä¸ªäººå£°éŸ³çš„å†…åœ¨å›ºæœ‰ç‰¹å¾ï¼Œä»¥åŠæˆ‘ä»¬ç”¨æ¥åšå…‹éš†çš„é‚£ä¸ªç‰¹å®šå¥å­ä¸­çš„æƒ…ç»ªç‰¹å¾ã€‚

è§£æï¼š
* **arbitrary** /ËˆÉ‘ËrbÉªtreri/ ğŸ”¥ï¼šå½¢å®¹è¯ï¼Œä»»æ„çš„ã€éšæœºçš„
* **variability** /ËŒveÉ™riÉ™ËˆbÉªlÉªti/ï¼šåè¯ï¼Œå˜åŒ–æ€§ã€å¯å˜æ€§
* **intonation** /ËŒÉªntÉ™ËˆneÉªÊƒn/ï¼šåè¯ï¼Œè¯­è°ƒã€å£°è°ƒå˜åŒ–
* **interrogation** /ÉªnËŒterÉ™ËˆÉ¡eÉªÊƒn/ï¼šåè¯ï¼Œç–‘é—®ï¼ˆè¯­è°ƒï¼‰
* **disentangle** /ËŒdÉªsÉªnËˆtÃ¦Å‹É¡l/ ğŸ”¥ï¼šåŠ¨è¯ï¼Œè§£è€¦ã€è§£å¼€çº ç¼ ï¼ˆæœºå™¨å­¦ä¹ ä¸­çš„é‡è¦æ¦‚å¿µï¼‰
* **intrinsic** /ÉªnËˆtrÉªnzÉªk/ï¼šå½¢å®¹è¯ï¼Œå†…åœ¨çš„ã€å›ºæœ‰çš„

---

(27) [19:50-20:16]

**{But this one I think is very interesting because we see it right now (in TTS) as a main limitation.} {And it's a very interesting AI problem because it's about data.} {So you need to have [the right data (with the right annotations)] but also [this kind of data, it's hard to create].} {So you have to be [very smart about [how you train efficiently your model (for that)]]} â€” which I love because that's exactly [the kind of problem [where we have an edge]] â€” is because [we always find interesting ways of [taking the best out of our training data]].}**

ä½†æˆ‘è§‰å¾—è¿™ä¸ªé—®é¢˜éå¸¸æœ‰è¶£ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨å°±åœ¨ **TTS** é¢†åŸŸæŠŠå®ƒè§†ä¸ºä¸€ä¸ªä¸»è¦å±€é™ã€‚è¿™æ˜¯ä¸€ä¸ªéå¸¸æœ‰è¶£çš„ AI é—®é¢˜ï¼Œå› ä¸ºå®ƒå…³ä¹æ•°æ®ã€‚ä½ éœ€è¦æœ‰æ­£ç¡®çš„æ•°æ®å’Œæ­£ç¡®çš„æ ‡æ³¨ï¼Œä½†è¿™ç±»æ•°æ®åˆå¾ˆéš¾åˆ›å»ºã€‚æ‰€ä»¥ä½ å¿…é¡»éå¸¸èªæ˜åœ°æ€è€ƒå¦‚ä½•é«˜æ•ˆåœ°è®­ç»ƒæ¨¡å‹â€”â€”è€Œæˆ‘å¾ˆå–œæ¬¢è¿™ç‚¹ï¼Œå› ä¸ºè¿™æ°æ°æ˜¯æˆ‘ä»¬æœ‰ä¼˜åŠ¿çš„é‚£ç±»é—®é¢˜ï¼Œæˆ‘ä»¬æ€»èƒ½æ‰¾åˆ°æœ‰è¶£çš„æ–¹æ³•æ¥æœ€å¤§åŒ–åˆ©ç”¨è®­ç»ƒæ•°æ®ã€‚

è§£æï¼š
* **annotation** /ËŒÃ¦nÉ™ËˆteÉªÊƒn/ ğŸ”¥ï¼šåè¯ï¼Œæ ‡æ³¨ï¼ˆç»™æ•°æ®æ·»åŠ æ ‡ç­¾å’Œæè¿°ä¿¡æ¯ï¼‰
* **have an edge** ğŸ”¥ï¼šçŸ­è¯­ï¼Œæœ‰ä¼˜åŠ¿ã€å ä¸Šé£
* **take the best out of**ï¼šçŸ­è¯­ï¼Œä»â€¦â€¦ä¸­è·å–æœ€å¤§ä»·å€¼ã€æœ€å¤§åŒ–åˆ©ç”¨
* **efficiently** /ÉªËˆfÉªÊƒntli/ï¼šå‰¯è¯ï¼Œé«˜æ•ˆåœ°

---

## ğŸ“š æ®µè½å°ç»“

è¿™æ®µè®¿è°ˆæ·±å…¥æ¢è®¨äº†ç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹ï¼ˆspeech to speechï¼‰çš„ç°çŠ¶ä¸æŒ‘æˆ˜ã€‚ä¸»è¦è®¨è®ºäº†ä¸‰å¤§æ ¸å¿ƒé—®é¢˜ï¼š**ä¸€æ˜¯** S2S æ¨¡å‹ä¸çº§è”ç³»ç»Ÿçš„æƒè¡¡â€”â€”S2S æ›´è‡ªç„¶ä½†éš¾ä»¥æ§åˆ¶ä¸”æ™ºèƒ½ä¸‹é™ï¼Œçº§è”ç³»ç»Ÿæ¨¡å—åŒ–å¥½ä½†è‡ªç„¶åº¦å·®ï¼›**äºŒæ˜¯** æ•°æ®ç“¶é¢ˆâ€”â€”éŸ³é¢‘è®­ç»ƒæ•°æ®åœ¨è´¨é‡å’Œè§„æ¨¡ä¸Šéƒ½è¿œä¸åŠæ–‡æœ¬æ•°æ®ï¼Œéœ€è¦é€šè¿‡æ•°æ®ç²¾é€‰ã€åˆæˆæ•°æ®å’Œå¼ºåŒ–å­¦ä¹ æ¥å¼¥è¡¥ï¼›**ä¸‰æ˜¯** TTS é¢†åŸŸçš„æƒ…ç»ªè¡¨è¾¾é—®é¢˜â€”â€”å£°éŸ³å…‹éš†å¯¼è‡´æ¨¡å‹é”å®šåœ¨å•ä¸€æƒ…ç»ªä¸Šï¼Œéœ€è¦è§£è€¦è¯´è¯äººçš„å›ºæœ‰å£°éŸ³ç‰¹å¾å’Œæƒ…ç»ªç‰¹å¾ã€‚æ­¤å¤–è¿˜è®¨è®ºäº†æœºå™¨äººã€ä¸åŒè¯´è¯ç¯å¢ƒç­‰æœªæ¥åº”ç”¨åœºæ™¯çš„æŠ€æœ¯æŒ‘æˆ˜ã€‚

### ğŸ”¥ æ ¸å¿ƒè¯æ±‡è¡¨

| è¯æ±‡/çŸ­è¯­ | å«ä¹‰ |
|---------|------|
| **speech to speech** | ç«¯åˆ°ç«¯è¯­éŸ³æ¨¡å‹ï¼ˆç›´æ¥è¯­éŸ³è¾“å…¥â†’è¯­éŸ³è¾“å‡ºï¼‰ |
| **cascaded system** | çº§è”ç³»ç»Ÿï¼ˆSTT â†’ LLM â†’ TTS ä¸²è”æ¶æ„ï¼‰ |
| **steer** | å¼•å¯¼ã€æ“æ§æ¨¡å‹æ–¹å‘ |
| **modularity** | æ¨¡å—åŒ–èƒ½åŠ› |
| **turn taking** | è½®æ¬¡ç®¡ç†ï¼ˆå¯¹è¯ä¸­çš„å‘è¨€è½®æ¢ï¼‰ |
| **bottleneck** | ç“¶é¢ˆ |
| **full duplex** | å…¨åŒå·¥ï¼ˆåŒæ–¹åŒæ—¶æ”¶å‘ï¼‰ |
| **fine-tune** | å¾®è°ƒï¼ˆåŸºäºé¢„è®­ç»ƒæ¨¡å‹ç»§ç»­è®­ç»ƒï¼‰ |
| **leverage** | åˆ©ç”¨ã€å‘æŒ¥æ æ†æ•ˆåº” |
| **from scratch** | ä»é›¶å¼€å§‹ |
| **discount** | ä½ä¼°ã€å¿½è§†ï¼ˆä¸æ˜¯æ‰“æŠ˜ï¼ï¼‰ |
| **take into account** | è€ƒè™‘åˆ°ã€çº³å…¥è€ƒé‡ |
| **voice cloning** | å£°éŸ³å…‹éš† |
| **loss function** | æŸå¤±å‡½æ•° |
| **disentangle** | è§£è€¦ã€è§£å¼€çº ç¼  |
| **intrinsic** | å†…åœ¨çš„ã€å›ºæœ‰çš„ |
| **annotation** | æ ‡æ³¨ï¼ˆæ•°æ®æ ‡ç­¾ï¼‰ |
| **have an edge** | æœ‰ä¼˜åŠ¿ã€å ä¸Šé£ |
| **my take is** | æˆ‘çš„çœ‹æ³•æ˜¯ï¼ˆå£è¯­è¡¨è¾¾ï¼‰ |
| **filter out** | è¿‡æ»¤æ‰ |
| **feed into** | è¾“å…¥åˆ°ã€å–‚ç»™æ¨¡å‹ |
| **archaic** | è¿‡æ—¶çš„ã€é™ˆæ—§çš„ |
| **phrasing** | æªè¾ã€è¡¨è¾¾æ–¹å¼ |
