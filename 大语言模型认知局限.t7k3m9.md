# 🎯 大语言模型认知局限 英语段落翻译

本文共 **3 个语义单元**，将全部翻译。

---

(1) [0:00-0:08]

**{The thing [about large language models] is that they're really good [at understanding context].} {They can take in [a huge amount of text] and figure out [what's relevant].}**

大语言模型的厉害之处在于，它们非常擅长理解上下文。它们能处理大量文本，然后找出哪些是相关的。

解析：
* **large language model**：名词短语，大语言模型（简称 **LLM**）
* **take in** 🔥：短语动词，接收、吸收（这里指处理/接收信息）
* **figure out** 🔥：短语动词，弄明白、搞清楚
* **relevant** /ˈreləvənt/：形容词，相关的、有关联的

---

(2) [0:15-0:38]

**{But here's [the catch], right?} {They don't [actually] know anything.} {They're just [predicting (the next) token].} {So when [people say (AI understands things)], that's not [quite accurate].} {It's more like [pattern matching (on steroids)].}**

但问题来了，对吧？它们实际上什么都不知道，只是在预测下一个 **token**。所以当人们说 AI 能"理解"事物时，这并不太准确。它更像是加强版的模式匹配。

解析：
* **here's the catch** 🔥：惯用语，"问题是/关键是"，用来引出一个出人意料的限制或缺点
* **token** /ˈtoʊkən/：名词，（AI 术语）文本的最小处理单元
* **accurate** /ˈækjərət/：形容词，准确的、精确的
* **pattern matching**：名词短语，模式匹配（计算机术语）
* **on steroids** 🔥：惯用语，字面意思"打了类固醇的"，引申为"加强版的、超级的"

---

(3) [0:38]

**{And that's [why you get (hallucinations)].} {The model is [confident but wrong], because it's [optimizing for (plausibility), not (truth)].}**

这就是为什么会出现"幻觉"。模型表现得很自信，但其实是错的，因为它优化的目标是合理性，而不是真实性。

解析：
* **hallucination** /həˌluːsɪˈneɪʃən/ 🔥：名词，幻觉（AI 术语：模型生成看似合理但实际错误的内容）
* **confident** /ˈkɑːnfɪdənt/：形容词，自信的、有把握的
* **optimize for** 🔥：短语，针对……进行优化
* **plausibility** /ˌplɔːzəˈbɪləti/：名词，合理性、可信度
* **plausibility vs truth**：本句的核心对比——模型追求"听起来合理"，而非"事实正确"

---

## 📚 段落小结

这段内容解释了大语言模型的核心矛盾：它们擅长理解上下文和处理文本，但本质上只是在做 token 预测，并不真正"理解"任何东西。这种"优化合理性而非真实性"的特性，正是 AI 幻觉产生的根本原因。

### 🔥 核心词汇表

| 词汇/短语 | 含义 |
|---------|------|
| **take in** | 接收、吸收 |
| **figure out** | 弄明白、搞清楚 |
| **here's the catch** | 问题是/关键是 |
| **on steroids** | 加强版的、超级的 |
| **hallucination** | 幻觉（AI 术语） |
| **optimize for** | 针对……进行优化 |
| **plausibility** | 合理性、可信度 |
