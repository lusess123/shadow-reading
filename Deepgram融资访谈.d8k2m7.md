# ğŸ¯ Deepgram Cè½®èèµ„è®¿è°ˆ è‹±è¯­æ®µè½ç¿»è¯‘

æœ¬æ–‡å…± **56 ä¸ªè¯­ä¹‰å•å…ƒ**ï¼Œå°†å…¨éƒ¨ç¿»è¯‘ã€‚

---

(1) [0:00-0:10] **Congratulations on your big announcement. Um, what's happening today? Thanks, Brooke. Yeah, we we just raised uh our series C. It's $130 million.**

æ­å–œä½ ä»¬è¿™ä¸ªå¤§æ¶ˆæ¯ï¼ä»Šå¤©å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿè°¢è°¢ä½ ï¼Œ**Brooke**ã€‚æ˜¯çš„ï¼Œæˆ‘ä»¬åˆšåˆšå®Œæˆäº† **Series C**ï¼ˆC è½®èèµ„ï¼‰ï¼Œ1.3 äº¿ç¾å…ƒã€‚

è§£æï¼š
* **announcement** /É™ËˆnaÊŠnsmÉ™nt/ï¼šåè¯ï¼Œå…¬å‘Šã€å®£å¸ƒ
* **series C**ï¼šC è½®èèµ„ï¼ˆåˆåˆ›å…¬å¸èèµ„é˜¶æ®µï¼šç§å­è½® â†’ A è½® â†’ B è½® â†’ C è½®...ï¼‰
* **raise**ï¼šåŠ¨è¯ï¼Œåœ¨èèµ„è¯­å¢ƒä¸­è¡¨ç¤º"ç­¹é›†èµ„é‡‘" ğŸ”¥

---

(2) [0:10-0:27] **Led by ABP and with participation from a bunch of folks like Black Rock and Tiger and um Alion and Princeville and Madrona and Wing and a whole bunch of backers of Deepgram YC2.**

ç”± **ABP** é¢†æŠ•ï¼Œè¿˜æœ‰ä¸€å¤§ç¾¤æŠ•èµ„è€…å‚ä¸ï¼Œæ¯”å¦‚ **Black Rock**ã€**Tiger**ã€**Alion**ã€**Princeville**ã€**Madrona**ã€**Wing**ï¼Œä»¥åŠå¾ˆå¤š **Deepgram** å’Œ **YC** çš„è€æ”¯æŒè€…ã€‚

è§£æï¼š
* **led by**ï¼šç”±...é¢†æŠ• ğŸ”¥ï¼ˆèèµ„å¸¸ç”¨è¡¨è¾¾ï¼‰
* **with participation from**ï¼šæœ‰...çš„å‚ä¸ï¼ˆèèµ„å¸¸ç”¨è¡¨è¾¾ï¼‰
* **a bunch of folks**ï¼šä¸€ç¾¤äººï¼ˆå£è¯­åŒ–è¡¨è¾¾ï¼‰
* **backers**ï¼šåè¯ï¼Œæ”¯æŒè€…ã€æŠ•èµ„äºº

---

(3) [0:25-0:43] **Um but uh yeah, it's it's been a few years since we've raised. Deepgram is an extremely efficient company and uh but this is a this is a big one. Um uh $130 million on a 1.3 billion valuation.**

è·ç¦»æˆ‘ä»¬ä¸Šæ¬¡èèµ„å·²ç»å¥½å‡ å¹´äº†ã€‚**Deepgram** æ˜¯ä¸€å®¶æå…¶é«˜æ•ˆçš„å…¬å¸ï¼Œä½†è¿™æ¬¡èèµ„å¾ˆå¤§ã€‚1.3 äº¿ç¾å…ƒï¼Œä¼°å€¼ 13 äº¿ç¾å…ƒã€‚

è§£æï¼š
* **it's been a few years since**ï¼šè·ç¦»...å·²ç»å¥½å‡ å¹´äº†
* **efficient** /ÉªËˆfÉªÊƒnt/ï¼šå½¢å®¹è¯ï¼Œé«˜æ•ˆçš„
* **valuation** /ËŒvÃ¦ljuËˆeÉªÊƒn/ï¼šåè¯ï¼Œä¼°å€¼ ğŸ”¥

---

(4) [0:39-1:04] **And uh we are set to expand our core offering um expand globally um and to uh make some strategic acquisitions of both uh hardware and um companies. And we just announced with the $130 million raise, the acquisition of a company uh of One, which is a leader in technology for voice ordering at uh drive-throughs.**

æˆ‘ä»¬å‡†å¤‡æ‰©å±•æ ¸å¿ƒäº§å“ã€è¿›è¡Œå…¨çƒæ‰©å¼ ï¼Œå¹¶è¿›è¡Œä¸€äº›æˆ˜ç•¥æ€§æ”¶è´­ï¼ŒåŒ…æ‹¬ç¡¬ä»¶å’Œå…¬å¸ã€‚æˆ‘ä»¬åˆšåˆšå®£å¸ƒï¼Œä¼´éšè¿™ 1.3 äº¿ç¾å…ƒçš„èèµ„ï¼Œæ”¶è´­äº†ä¸€å®¶å« **One** çš„å…¬å¸ï¼Œå®ƒæ˜¯å¾—æ¥é€Ÿè¯­éŸ³ç‚¹é¤æŠ€æœ¯çš„é¢†å¯¼è€…ã€‚

è§£æï¼š
* **be set to**ï¼šå‡†å¤‡è¦...ã€å³å°†...
* **core offering**ï¼šæ ¸å¿ƒäº§å“/æœåŠ¡
* **strategic acquisitions**ï¼šæˆ˜ç•¥æ€§æ”¶è´­ ğŸ”¥
* **drive-through**ï¼šå¾—æ¥é€Ÿï¼Œæ±½è½¦å…ä¸‹è½¦æœåŠ¡çª—å£

---

(5) [1:04-1:22] **So, yeah, it's an exciting day for us. That's super exciting. And what prompted the raise? I know that you guys I mean pretty much every voice AI company out there is using you guys. Um I clearly like you're scaling. What kind of prompted the raise and like what are you hoping to do with it?**

æ‰€ä»¥ä»Šå¤©å¯¹æˆ‘ä»¬æ¥è¯´æ˜¯æ¿€åŠ¨äººå¿ƒçš„ä¸€å¤©ã€‚å¤ªæ£’äº†ï¼æ˜¯ä»€ä¹ˆä¿ƒä½¿ä½ ä»¬è¿›è¡Œè¿™æ¬¡èèµ„ï¼Ÿæˆ‘çŸ¥é“å‡ ä¹å¸‚é¢ä¸Šæ¯å®¶è¯­éŸ³ AI å…¬å¸éƒ½åœ¨ç”¨ä½ ä»¬çš„æœåŠ¡ã€‚å¾ˆæ˜æ˜¾ä½ ä»¬åœ¨æ‰©å¼ ã€‚æ˜¯ä»€ä¹ˆä¿ƒä½¿ä½ ä»¬èèµ„ï¼Œä½ ä»¬å¸Œæœ›ç”¨è¿™ç¬”é’±åšä»€ä¹ˆï¼Ÿ

è§£æï¼š
* **prompt** /prÉ‘Ëmpt/ï¼šåŠ¨è¯ï¼Œä¿ƒä½¿ã€å¼•å‘ ğŸ”¥
* **pretty much**ï¼šå‡ ä¹ã€å·®ä¸å¤š
* **scale** /skeÉªl/ï¼šåŠ¨è¯ï¼Œæ‰©å¼ ã€æ‰©å¤§è§„æ¨¡ ğŸ”¥

---

(6) [1:22-1:46] **Yeah, we weren't we weren't out looking. Um but we have a lot of uh strategic and or like users but then investor strategic investors that were asking us um uh when are we going to raise when are we going to raise and so for instance that's like uh Twilio um City uh ServiceNow.**

å—¯ï¼Œæˆ‘ä»¬å…¶å®å¹¶æ²¡æœ‰ä¸»åŠ¨å»æ‰¾ï¼ˆæŠ•èµ„ï¼‰ã€‚ä½†æˆ‘ä»¬æœ‰å¾ˆå¤šæˆ˜ç•¥ç”¨æˆ·å’Œæˆ˜ç•¥æŠ•èµ„è€…ä¸€ç›´åœ¨é—®æˆ‘ä»¬ï¼šä½ ä»¬ä»€ä¹ˆæ—¶å€™èèµ„ï¼Ÿæ¯”å¦‚åƒ **Twilio**ã€**City**ã€**ServiceNow** è¿™äº›å…¬å¸ã€‚

è§£æï¼š
* **out looking**ï¼šä¸»åŠ¨å¯»æ‰¾ï¼ˆè¿™é‡ŒæŒ‡ä¸»åŠ¨å¯»æ‰¾æŠ•èµ„ï¼‰
* **strategic investors**ï¼šæˆ˜ç•¥æŠ•èµ„è€… ğŸ”¥
* **for instance**ï¼šä¾‹å¦‚

---

(7) [1:46-2:03] **And uh I was like that's a good point. And then um it but this is because voice AI was going mainstream over the last year you know you saw this people watching this know this. It's like a year ago, two years ago, people were still thinking like, I don't know, is voice AI actually going to work or whatever.**

æˆ‘æƒ³ï¼Œè¿™ç¡®å®æ˜¯ä¸ªå¥½é—®é¢˜ã€‚è¿™æ˜¯å› ä¸ºè¯­éŸ³ AI åœ¨è¿‡å»ä¸€å¹´é‡Œé€æ¸æˆä¸ºä¸»æµï¼Œçœ‹è¿™ä¸ªè§†é¢‘çš„äººåº”è¯¥éƒ½çŸ¥é“ã€‚ä¸€ä¸¤å¹´å‰ï¼Œäººä»¬è¿˜åœ¨æƒ³ï¼šæˆ‘ä¸çŸ¥é“ï¼Œè¯­éŸ³ AI çœŸçš„èƒ½è¡Œå—ï¼Ÿ

è§£æï¼š
* **that's a good point**ï¼šè¿™æ˜¯ä¸ªå¥½é—®é¢˜/è§‚ç‚¹
* **go mainstream**ï¼šæˆä¸ºä¸»æµ ğŸ”¥
* **or whatever**ï¼šæˆ–è€…åˆ«çš„ä»€ä¹ˆï¼ˆå£è¯­åŒ–è¡¨è¾¾ï¼‰

---

(8) [2:03-2:24] **You know, over the last year, that drastically changed. Everybody's mind was changed. They're like, oh, I get it. It's happening. It's here. Now, it's just a question of how and how fast and that type of thing. Um, so these companies like Twilio, ServiceNow, City, um, they're thinking, okay, what's their voice strategy, right?**

ä½†åœ¨è¿‡å»ä¸€å¹´ï¼Œæƒ…å†µå‘ç”Ÿäº†å·¨å¤§å˜åŒ–ã€‚æ¯ä¸ªäººçš„æƒ³æ³•éƒ½æ”¹å˜äº†ã€‚ä»–ä»¬è¯´ï¼šå“¦ï¼Œæˆ‘æ˜ç™½äº†ï¼Œå®ƒæ­£åœ¨å‘ç”Ÿï¼Œå®ƒå·²ç»æ¥äº†ã€‚ç°åœ¨çš„é—®é¢˜åªæ˜¯æ€ä¹ˆåšã€å¤šå¿«èƒ½åšåˆ°ã€‚æ‰€ä»¥è¿™äº›å…¬å¸ï¼Œåƒ **Twilio**ã€**ServiceNow**ã€**City**ï¼Œä»–ä»¬åœ¨æƒ³ï¼šæˆ‘ä»¬çš„è¯­éŸ³æˆ˜ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ

è§£æï¼š
* **drastically** /ËˆdrÃ¦stÉªkli/ï¼šå‰¯è¯ï¼Œå‰§çƒˆåœ°ã€å¤§å¹…åº¦åœ° ğŸ”¥
* **I get it**ï¼šæˆ‘æ˜ç™½äº†ï¼ˆå£è¯­ï¼‰
* **voice strategy**ï¼šè¯­éŸ³æˆ˜ç•¥

---

(9) [2:24-2:44] **And they're um building on top of Deepgram. They have their voice infrastructure provider um with us and uh they want to know like you know what how are you arming yourself in the war basically in the battle you know. And I'm like yeah it's a good that's a good question.**

ä»–ä»¬åœ¨ **Deepgram** ä¹‹ä¸Šæ„å»ºäº§å“ï¼Œæˆ‘ä»¬æ˜¯ä»–ä»¬çš„è¯­éŸ³åŸºç¡€è®¾æ–½æä¾›å•†ã€‚ä»–ä»¬æƒ³çŸ¥é“ï¼šä½ ä»¬åœ¨è¿™åœºæˆ˜äº‰ã€è¿™åœºæˆ˜æ–—ä¸­æ˜¯æ€ä¹ˆæ­¦è£…è‡ªå·±çš„ï¼Ÿæˆ‘è¯´æ˜¯çš„ï¼Œè¿™æ˜¯ä¸ªå¥½é—®é¢˜ã€‚

è§£æï¼š
* **build on top of**ï¼šåœ¨...ä¹‹ä¸Šæ„å»º ğŸ”¥ï¼ˆæŠ€æœ¯é¢†åŸŸå¸¸ç”¨ï¼‰
* **infrastructure provider**ï¼šåŸºç¡€è®¾æ–½æä¾›å•† ğŸ”¥
* **arm yourself**ï¼šæ­¦è£…è‡ªå·±

---

(10) [2:44-3:06] **And um we have some other really great investors that were uh talking to us that hadn't invested in Deepgram yet. This is ABP and some others um and they came to us kind of all at the same time just with a thesis on voice AI and how Deepgram is positioned how efficient AI companies are going to be the winners.**

æˆ‘ä»¬è¿˜æœ‰ä¸€äº›å¾ˆæ£’çš„æŠ•èµ„è€…åœ¨è·Ÿæˆ‘ä»¬æ¥è§¦ï¼Œä»–ä»¬ä¹‹å‰æ²¡æŠ•è¿‡ **Deepgram**ï¼Œæ¯”å¦‚ **ABP** ç­‰ã€‚ä»–ä»¬å‡ ä¹åŒæ—¶æ‰¾åˆ°æˆ‘ä»¬ï¼Œå¸¦ç€å…³äºè¯­éŸ³ AI çš„æŠ•èµ„è®ºç‚¹ï¼š**Deepgram** çš„å®šä½å¦‚ä½•ï¼Œé«˜æ•ˆçš„ AI å…¬å¸å°†ä¼šæˆä¸ºèµ¢å®¶ã€‚

è§£æï¼š
* **thesis** /ËˆÎ¸iËsÉªs/ï¼šåè¯ï¼Œè®ºç‚¹ã€è®ºé¢˜ï¼ˆè¿™é‡ŒæŒ‡æŠ•èµ„è®ºç‚¹ï¼‰ğŸ”¥
* **be positioned**ï¼šå®šä½
* **the winners**ï¼šèµ¢å®¶

---

(11) [3:01-3:21] **How real-time AI is undervalued um which is something we could get into uh where there's uh batch mode um interactive mode but then real time and most tokens are just batch mode or interactive mode and not real time yet voice AI is the use case and it's still a small percentage of tokens.**

å®æ—¶ AI è¢«ä½ä¼°äº†â€”â€”æˆ‘ä»¬å¯ä»¥æ·±å…¥è®¨è®ºè¿™ä¸ªè¯é¢˜â€”â€”ç›®å‰æœ‰æ‰¹å¤„ç†æ¨¡å¼ã€äº¤äº’æ¨¡å¼ï¼Œè¿˜æœ‰å®æ—¶æ¨¡å¼ã€‚å¤§å¤šæ•° token è¿˜åªæ˜¯æ‰¹å¤„ç†æˆ–äº¤äº’æ¨¡å¼ï¼Œè¿˜ä¸æ˜¯å®æ—¶çš„ã€‚ç„¶è€Œè¯­éŸ³ AI å°±æ˜¯å®æ—¶çš„ä½¿ç”¨åœºæ™¯ï¼Œç›®å‰å®ƒåªå  token çš„å¾ˆå°æ¯”ä¾‹ã€‚

è§£æï¼š
* **undervalued** /ËŒÊŒndÉ™rËˆvÃ¦ljuËd/ï¼šå½¢å®¹è¯ï¼Œè¢«ä½ä¼°çš„ ğŸ”¥
* **batch mode**ï¼šæ‰¹å¤„ç†æ¨¡å¼ï¼ˆä¸€æ¬¡æ€§å¤„ç†å¤§é‡æ•°æ®ï¼‰
* **interactive mode**ï¼šäº¤äº’æ¨¡å¼
* **use case**ï¼šä½¿ç”¨åœºæ™¯ ğŸ”¥

---

(12) [3:21-3:42] **And uh how that's going to transform into like maybe you know 70 80% of tokens will be real time in 5 years. And so uh they're all noticing this at the same time and uh we announced about a year ago that Deepgram was uh cash flow positive.**

æœªæ¥ 5 å¹´ï¼Œå¯èƒ½ 70-80% çš„ token éƒ½ä¼šæ˜¯å®æ—¶çš„ã€‚æ‰€ä»¥ä»–ä»¬åŒæ—¶éƒ½æ³¨æ„åˆ°äº†è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬å¤§çº¦ä¸€å¹´å‰å®£å¸ƒ **Deepgram** å®ç°äº†æ­£å‘ç°é‡‘æµã€‚

è§£æï¼š
* **transform into**ï¼šè½¬å˜æˆ
* **cash flow positive**ï¼šæ­£å‘ç°é‡‘æµ ğŸ”¥ï¼ˆæ”¶å…¥ > æ”¯å‡ºï¼‰

---

(13) [3:38-3:56] **So we weren't like in need of money like most AI companies most frontier AI companies are burning money like crazy you know they have uh negative margins they're just going to town lighting money on fire. That's not the situation that Deepgram was in.**

æ‰€ä»¥æˆ‘ä»¬ä¸åƒå¤§å¤šæ•° AI å…¬å¸é‚£æ ·æ€¥éœ€èµ„é‡‘ã€‚å¤§å¤šæ•°å‰æ²¿ AI å…¬å¸éƒ½åœ¨ç–¯ç‹‚çƒ§é’±ï¼Œä»–ä»¬çš„åˆ©æ¶¦ç‡æ˜¯è´Ÿçš„ï¼Œç®€ç›´å°±æ˜¯åœ¨ä½¿åŠ²çƒ§é’±ã€‚**Deepgram** ä¸æ˜¯é‚£ç§æƒ…å†µã€‚

è§£æï¼š
* **in need of**ï¼šéœ€è¦
* **frontier AI companies**ï¼šå‰æ²¿ AI å…¬å¸
* **burn money**ï¼šçƒ§é’± ğŸ”¥
* **negative margins**ï¼šè´Ÿåˆ©æ¶¦ç‡
* **go to town**ï¼šæ‹¼å‘½åšæŸäº‹ï¼ˆå£è¯­ï¼‰

---

(14) [3:53-4:14] **Um but when uh our strategic partners are coming to us and saying, "Hey, we want to go bigger with you guys." And when um folks are coming to us with the thesis, like basically pitching Deepgram back to me better than I could pitch to them, I'm like, "Okay, this is uh these people understand the business."**

ä½†å½“æˆ‘ä»¬çš„æˆ˜ç•¥åˆä½œä¼™ä¼´æ¥æ‰¾æˆ‘ä»¬è¯´ï¼š"å˜¿ï¼Œæˆ‘ä»¬æƒ³å’Œä½ ä»¬åšæ›´å¤§çš„äº‹ã€‚"å½“æŠ•èµ„è€…å¸¦ç€æŠ•èµ„è®ºç‚¹æ¥æ‰¾æˆ‘ä»¬ï¼Œè€Œä¸”ä»–ä»¬å‘æˆ‘æ¨é”€ **Deepgram** æ¯”æˆ‘å‘ä»–ä»¬æ¨é”€è¿˜å¥½çš„æ—¶å€™ï¼Œæˆ‘å°±æƒ³ï¼šå¥½çš„ï¼Œè¿™äº›äººçœŸçš„æ‡‚è¿™ä¸ªä¸šåŠ¡ã€‚

è§£æï¼š
* **go bigger**ï¼šåšæ›´å¤§ã€æ‰©å¤§è§„æ¨¡
* **pitch** /pÉªtÊƒ/ï¼šåŠ¨è¯ï¼Œæ¨é”€ã€æ¨ä»‹ ğŸ”¥
* **understand the business**ï¼šæ‡‚ä¸šåŠ¡

---

(15) [4:09-4:27] **And um if we raise, you know, another a little over $100 million, so it's $130 million raise. Um then we can cement the future for us to where we might not have to raise before going public again. Um so that's what that's the thought process behind it.**

å¦‚æœæˆ‘ä»¬å†èä¸€äº¿å¤šç¾å…ƒï¼Œä¹Ÿå°±æ˜¯è¿™æ¬¡ 1.3 äº¿ç¾å…ƒçš„èèµ„ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±èƒ½å·©å›ºæœªæ¥ï¼Œå¯èƒ½åœ¨ä¸Šå¸‚ä¹‹å‰ä¸éœ€è¦å†èèµ„äº†ã€‚è¿™å°±æ˜¯èƒŒåçš„æ€è€ƒè¿‡ç¨‹ã€‚

è§£æï¼š
* **cement** /sÉªËˆment/ï¼šåŠ¨è¯ï¼Œå·©å›ºã€åŠ å¼º ğŸ”¥
* **go public**ï¼šä¸Šå¸‚ï¼ˆå…¬å¸è‚¡ç¥¨å…¬å¼€äº¤æ˜“ï¼‰ğŸ”¥
* **thought process**ï¼šæ€è€ƒè¿‡ç¨‹

---

(16) [4:24-4:47] **And um the raise though is for those three things. It's to expand our core product um to work on Neuroplex to um to keep developing our perception models and our voice generation models um but then to expand to 100 languages and dialects both in speech generation and in perception.**

è¿™æ¬¡èèµ„æ˜¯ä¸ºäº†ä¸‰ä»¶äº‹ï¼šæ‰©å±•æˆ‘ä»¬çš„æ ¸å¿ƒäº§å“ï¼Œç»§ç»­å¼€å‘ **Neuroplex**ã€æˆ‘ä»¬çš„æ„ŸçŸ¥æ¨¡å‹å’Œè¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼›ç„¶åæ‰©å±•åˆ° 100 ç§è¯­è¨€å’Œæ–¹è¨€ï¼ŒåŒ…æ‹¬è¯­éŸ³ç”Ÿæˆå’Œæ„ŸçŸ¥ä¸¤ä¸ªæ–¹é¢ã€‚

è§£æï¼š
* **perception models**ï¼šæ„ŸçŸ¥æ¨¡å‹ï¼ˆè¯­éŸ³è¯†åˆ«ç­‰ï¼‰
* **voice generation models**ï¼šè¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼ˆTTS ç­‰ï¼‰
* **dialects** /ËˆdaÉªÉ™lekts/ï¼šåè¯ï¼Œæ–¹è¨€

---

(17) [4:47-5:07] **And then to um acquire the compute and uh complements to our platform uh that will you know that will put us in a great position. So all those things came together at once. Um, it's helpful though that voice AI went mainstream and then everybody sort of recognized the value here.**

æœ€åæ˜¯è·å–ç®—åŠ›å’Œå¹³å°çš„è¡¥å……èƒ½åŠ›ï¼Œè¿™ä¼šè®©æˆ‘ä»¬å¤„äºéå¸¸æœ‰åˆ©çš„ä½ç½®ã€‚æ‰€ä»¥æ‰€æœ‰è¿™äº›äº‹æƒ…åŒæ—¶å‘ç”Ÿäº†ã€‚è¯­éŸ³ AI èµ°å‘ä¸»æµç¡®å®å¾ˆæœ‰å¸®åŠ©ï¼Œç„¶åå¤§å®¶éƒ½è®¤è¯†åˆ°äº†è¿™é‡Œçš„ä»·å€¼ã€‚

è§£æï¼š
* **compute**ï¼šåè¯ï¼Œç®—åŠ› ğŸ”¥ï¼ˆAI é¢†åŸŸå¸¸ç”¨ï¼‰
* **complements**ï¼šåè¯ï¼Œè¡¥å……ã€é…å¥—
* **come together**ï¼šèšé›†ã€æ±‡åˆ

---

(18) [5:02-5:24] **Yeah, what a time to pour fuel on the fire. I think that's something I've always admired about Deepgram is that you guys have like had this vision for the last eight or nine years of um really like how do you get like voice AI into production mainstream.**

æ˜¯å•Šï¼Œæ­£æ˜¯ç«ä¸Šæµ‡æ²¹çš„å¥½æ—¶æœºã€‚æˆ‘ä¸€ç›´å¾ˆä½©æœ **Deepgram** çš„ä¸€ç‚¹æ˜¯ï¼Œä½ ä»¬è¿‡å»å…«ä¹å¹´ä¸€ç›´æœ‰è¿™ä¸ªæ„¿æ™¯ï¼šå¦‚ä½•è®©è¯­éŸ³ AI çœŸæ­£è¿›å…¥ç”Ÿäº§ä¸»æµã€‚

è§£æï¼š
* **pour fuel on the fire**ï¼šç«ä¸Šæµ‡æ²¹ï¼ˆè¿™é‡Œæ˜¯æ­£é¢æ„æ€ï¼šæŠ“ä½æ—¶æœºåŠ å¤§æŠ•å…¥ï¼‰ğŸ”¥
* **admire** /É™dËˆmaÉªr/ï¼šåŠ¨è¯ï¼Œé’¦ä½©ã€ä½©æœ
* **vision**ï¼šåè¯ï¼Œæ„¿æ™¯

---

(19) [5:18-5:39] **And that this is going to be the mode of like how we interface with computers and you guys have been at it for the past nine years and so your fundamentals are so strong and I think the research is really there and that's just an amazing part of your team.**

è¿™å°†æˆä¸ºæˆ‘ä»¬ä¸è®¡ç®—æœºäº¤äº’çš„æ–¹å¼ï¼Œä½ ä»¬å·²ç»åšäº†ä¹å¹´äº†ï¼Œæ‰€ä»¥ä½ ä»¬çš„åŸºæœ¬åŠŸéå¸¸æ‰å®ï¼Œç ”ç©¶å®åŠ›ç¡®å®å¾ˆå¼ºï¼Œè¿™æ˜¯ä½ ä»¬å›¢é˜Ÿéå¸¸äº†ä¸èµ·çš„åœ°æ–¹ã€‚

è§£æï¼š
* **interface with**ï¼šä¸...äº¤äº’ ğŸ”¥
* **fundamentals**ï¼šåè¯ï¼ŒåŸºæœ¬åŠŸã€åŸºç¡€
* **be at it**ï¼šä¸€ç›´åœ¨åšæŸäº‹

---

(20) [5:32-5:54] **Yeah, thanks. Yeah, the research team is awesome. At Deepgram, we also have an amazing engineering and applied engineering team that just takes the frontier pushing that we're doing, the first principles work that's happening in our research team and then makes it real and viable for full scale production.**

è°¢è°¢ã€‚æ˜¯çš„ï¼Œç ”ç©¶å›¢é˜Ÿå¾ˆæ£’ã€‚åœ¨ **Deepgram**ï¼Œæˆ‘ä»¬è¿˜æœ‰ä¸€ä¸ªå‡ºè‰²çš„å·¥ç¨‹å’Œåº”ç”¨å·¥ç¨‹å›¢é˜Ÿï¼Œä»–ä»¬æŠŠæˆ‘ä»¬ç ”ç©¶å›¢é˜Ÿæ­£åœ¨åšçš„å‰æ²¿æ¢ç´¢å’Œç¬¬ä¸€æ€§åŸç†å·¥ä½œå˜æˆç°å®ï¼Œä½¿å…¶èƒ½å¤ŸçœŸæ­£å¤§è§„æ¨¡ç”Ÿäº§è½åœ°ã€‚

è§£æï¼š
* **frontier pushing**ï¼šå‰æ²¿æ¢ç´¢
* **first principles**ï¼šç¬¬ä¸€æ€§åŸç†ï¼ˆä»æ ¹æœ¬åŸç†å‡ºå‘æ€è€ƒï¼‰ğŸ”¥
* **viable** /ËˆvaÉªÉ™bl/ï¼šå½¢å®¹è¯ï¼Œå¯è¡Œçš„
* **full scale production**ï¼šå¤§è§„æ¨¡ç”Ÿäº§

---

(21) [5:54-6:18] **Um, you know, it's funny. A lot of companies build on top of Deepgram and they'll come to us like years later and say um so we're wondering about this architecture design because we haven't even built error handling into our API calls to Deepgram because they fail so infrequently.**

è¿™å¾ˆæœ‰è¶£ã€‚å¾ˆå¤šå…¬å¸åœ¨ **Deepgram** ä¹‹ä¸Šæ„å»ºäº§å“ï¼Œå‡ å¹´åä»–ä»¬æ¥æ‰¾æˆ‘ä»¬è¯´ï¼šæˆ‘ä»¬åœ¨è€ƒè™‘è¿™ä¸ªæ¶æ„è®¾è®¡ï¼Œå› ä¸ºæˆ‘ä»¬ç”šè‡³æ²¡æœ‰ä¸ºè°ƒç”¨ **Deepgram** çš„ API æ„å»ºé”™è¯¯å¤„ç†æœºåˆ¶ï¼Œå› ä¸ºå®ƒä»¬å¾ˆå°‘å¤±è´¥ã€‚

è§£æï¼š
* **error handling**ï¼šé”™è¯¯å¤„ç†ï¼ˆç¼–ç¨‹æœ¯è¯­ï¼‰
* **infrequently** /ÉªnËˆfriËkwÉ™ntli/ï¼šå‰¯è¯ï¼Œå¾ˆå°‘åœ°

---

(22) [6:16-6:40] **And I'm just like guys you got to use like standard engineering practices here. Our systems are way more reliable than other um AI systems, especially speech systems. But that is just a testament to the underlying models that are built and the engineering that is done at Deepgram and just how reliable the system is.**

æˆ‘å°±è¯´ï¼šä¼™è®¡ä»¬ï¼Œä½ ä»¬è¿˜æ˜¯å¾—éµå¾ªæ ‡å‡†å·¥ç¨‹å®è·µå•Šã€‚æˆ‘ä»¬çš„ç³»ç»Ÿæ¯”å…¶ä»– AI ç³»ç»Ÿå¯é å¾—å¤šï¼Œå°¤å…¶æ˜¯è¯­éŸ³ç³»ç»Ÿã€‚ä½†è¿™æ°æ°è¯æ˜äº† **Deepgram** åº•å±‚æ¨¡å‹å’Œå·¥ç¨‹çš„è´¨é‡ï¼Œä»¥åŠç³»ç»Ÿæœ‰å¤šå¯é ã€‚

è§£æï¼š
* **standard engineering practices**ï¼šæ ‡å‡†å·¥ç¨‹å®è·µ
* **way more**ï¼š...å¾—å¤šï¼ˆå£è¯­å¼ºè°ƒï¼‰
* **testament** /ËˆtestÉ™mÉ™nt/ï¼šåè¯ï¼Œè¯æ˜ã€è¯æ® ğŸ”¥
* **underlying**ï¼šå½¢å®¹è¯ï¼Œåº•å±‚çš„

---

(23) [6:40-7:02] **Um but I think that's what's needed in order to be the backbone of this next generation of products. So I look at the world there's 8 billion people in it. There's just a tiny bit of penetration right now with voice as the user interface. It's going to 100x or more.**

ä½†æˆ‘è®¤ä¸ºè¿™æ­£æ˜¯æˆä¸ºä¸‹ä¸€ä»£äº§å“éª¨å¹²æ‰€éœ€è¦çš„ã€‚ä¸–ç•Œä¸Šæœ‰ 80 äº¿äººï¼Œç›®å‰è¯­éŸ³ä½œä¸ºç”¨æˆ·ç•Œé¢çš„æ¸—é€ç‡è¿˜éå¸¸ä½ï¼Œæœªæ¥å°†å¢é•¿ 100 å€ç”šè‡³æ›´å¤šã€‚

è§£æï¼š
* **backbone**ï¼šåè¯ï¼Œéª¨å¹²ã€æ”¯æŸ± ğŸ”¥
* **penetration** /ËŒpenÉ™ËˆtreÉªÊƒn/ï¼šåè¯ï¼Œæ¸—é€ç‡ ğŸ”¥
* **100x**ï¼š100 å€

---

(24) [7:00-7:26] **And uh if we're standing around saying uh we have to build 500 billion dollar data centers in the center of Texas in order to do this like I that doesn't make sense to me. Um there you can supply this without burning up all of the energy and water in the world. Deepgram's models and platform is a demonstration of this.**

å¦‚æœæˆ‘ä»¬è¯´å¿…é¡»åœ¨å¾·å…‹è¨æ–¯å·ä¸­å¿ƒå»ºé€  5000 äº¿ç¾å…ƒçš„æ•°æ®ä¸­å¿ƒæ‰èƒ½åšåˆ°è¿™ä¸€ç‚¹ï¼Œæˆ‘è§‰å¾—è¿™ä¸åˆç†ã€‚ä½ å¯ä»¥åœ¨ä¸è€—å°½ä¸–ç•Œä¸Šæ‰€æœ‰èƒ½æºå’Œæ°´èµ„æºçš„æƒ…å†µä¸‹æä¾›è¿™ç§æœåŠ¡ã€‚**Deepgram** çš„æ¨¡å‹å’Œå¹³å°å°±æ˜¯è¿™ä¸€ç‚¹çš„è¯æ˜ã€‚

è§£æï¼š
* **data center**ï¼šæ•°æ®ä¸­å¿ƒ
* **burn up**ï¼šè€—å°½ã€çƒ§å…‰
* **demonstration**ï¼šåè¯ï¼Œè¯æ˜ã€æ¼”ç¤º

---

(25) [7:18-7:42] **And I think this raise and our partners validate that too. They get the best models and access to low latency and high throughput and really reliable products. But by the way our models are the most efficient and they're the most friendly to the environment and they also make sense from a business perspective.**

æˆ‘è®¤ä¸ºè¿™æ¬¡èèµ„å’Œæˆ‘ä»¬çš„åˆä½œä¼™ä¼´ä¹ŸéªŒè¯äº†è¿™ä¸€ç‚¹ã€‚ä»–ä»¬è·å¾—äº†æœ€å¥½çš„æ¨¡å‹ã€ä½å»¶è¿Ÿã€é«˜ååé‡å’ŒçœŸæ­£å¯é çš„äº§å“ã€‚é¡ºä¾¿è¯´ä¸€ä¸‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯æœ€é«˜æ•ˆçš„ï¼Œå¯¹ç¯å¢ƒæœ€å‹å¥½ï¼Œä»å•†ä¸šè§’åº¦ä¹Ÿå¾ˆæœ‰æ„ä¹‰ã€‚

è§£æï¼š
* **validate** /ËˆvÃ¦lÉªdeÉªt/ï¼šåŠ¨è¯ï¼ŒéªŒè¯ ğŸ”¥
* **low latency**ï¼šä½å»¶è¿Ÿ ğŸ”¥
* **high throughput**ï¼šé«˜ååé‡ ğŸ”¥
* **make sense**ï¼šæœ‰æ„ä¹‰ã€åˆç†

---

(26) [7:42-8:05] **So I think there's a new brand of company that will be coming out from an AI company perspective that puts all of those together like all the complaints that people have about AI right now. I think you can actually address all of them. I mean, I can tell you you already can in voice this is what we do at Deepgram.**

æ‰€ä»¥æˆ‘è®¤ä¸ºä¼šå‡ºç°ä¸€ç§æ–°ç±»å‹çš„ AI å…¬å¸ï¼ŒæŠŠæ‰€æœ‰è¿™äº›ç»“åˆåœ¨ä¸€èµ·ï¼Œè§£å†³äººä»¬ç›®å‰å¯¹ AI çš„æ‰€æœ‰æŠ±æ€¨ã€‚æˆ‘å¯ä»¥å‘Šè¯‰ä½ ï¼Œåœ¨è¯­éŸ³é¢†åŸŸå·²ç»å¯ä»¥åšåˆ°äº†ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬åœ¨ **Deepgram** åšçš„äº‹æƒ…ã€‚

è§£æï¼š
* **a new brand of**ï¼šä¸€ç§æ–°ç±»å‹çš„
* **address**ï¼šåŠ¨è¯ï¼Œè§£å†³ï¼ˆé—®é¢˜ï¼‰ğŸ”¥
* **complaints**ï¼šåè¯ï¼ŒæŠ±æ€¨

---

(27) [8:01-8:23] **But there's going to be a different mode of operation for companies instead of just build bigger, burn faster, burn bright. There's a sustainable AI company business model out there and I'm happy that we're doing really well with it. Yeah. No, and I think that's where like the testament of working on this problem and knowing it so deeply that you have that maturity of the products.**

å…¬å¸å°†æœ‰ä¸€ç§ä¸åŒçš„è¿è¥æ¨¡å¼ï¼Œè€Œä¸æ˜¯åªè¿½æ±‚"å»ºå¾—æ›´å¤§ã€çƒ§å¾—æ›´å¿«ã€çƒ§å¾—æ›´äº®"ã€‚å¯æŒç»­çš„ AI å…¬å¸å•†ä¸šæ¨¡å¼æ˜¯å­˜åœ¨çš„ï¼Œæˆ‘å¾ˆé«˜å…´æˆ‘ä»¬åšå¾—å¾ˆå¥½ã€‚æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºè¿™å°±æ˜¯æ·±è€•è¿™ä¸ªé—®é¢˜çš„ä»·å€¼æ‰€åœ¨ï¼Œå› ä¸ºä½ ä»¬å¯¹å®ƒäº†è§£å¾—å¦‚æ­¤æ·±åˆ»ï¼Œäº§å“æ‰æœ‰è¿™ç§æˆç†Ÿåº¦ã€‚

è§£æï¼š
* **mode of operation**ï¼šè¿è¥æ¨¡å¼
* **sustainable** /sÉ™ËˆsteÉªnÉ™bl/ï¼šå½¢å®¹è¯ï¼Œå¯æŒç»­çš„ ğŸ”¥
* **maturity** /mÉ™ËˆtjÊŠrÉ™ti/ï¼šåè¯ï¼Œæˆç†Ÿåº¦ ğŸ”¥

---

(28) [8:24-8:57] **I mean we see this in our benchmarks the reliability. We do continuous monitoring of all these different models and I think Deepgram consistently has some of the most consistent performance across all which again with real time if you have many turns reliability is only like exploding in terms of how important that reliability is because you're not just making one API call like when you Google search you have to get it right that one time but with voice AI you have to get it right a hundred times within a call and so yeah that reliability just totally compounds.**

æˆ‘ä»¬åœ¨åŸºå‡†æµ‹è¯•ä¸­çœ‹åˆ°äº†è¿™ç§å¯é æ€§ã€‚æˆ‘ä»¬å¯¹æ‰€æœ‰è¿™äº›ä¸åŒçš„æ¨¡å‹è¿›è¡ŒæŒç»­ç›‘æ§ï¼Œ**Deepgram** å§‹ç»ˆæ‹¥æœ‰æœ€ä¸€è‡´çš„æ€§èƒ½è¡¨ç°ã€‚åœ¨å®æ—¶åœºæ™¯ä¸­ï¼Œå¦‚æœä½ æœ‰å¾ˆå¤šè½®å¯¹è¯ï¼Œå¯é æ€§çš„é‡è¦æ€§å°±å‘ˆçˆ†ç‚¸å¼å¢é•¿ã€‚å› ä¸ºä½ ä¸æ˜¯åªå‘ä¸€æ¬¡ API è°ƒç”¨ï¼Œåƒ Google æœç´¢é‚£æ ·åªéœ€è¦é‚£ä¸€æ¬¡æ­£ç¡®å°±è¡Œã€‚ä½†è¯­éŸ³ AIï¼Œä½ éœ€è¦åœ¨ä¸€é€šç”µè¯ä¸­åšå¯¹ä¸€ç™¾æ¬¡ã€‚æ‰€ä»¥å¯é æ€§ç¡®å®æ˜¯å®Œå…¨å¤åˆç´¯ç§¯çš„ã€‚

è§£æï¼š
* **benchmarks**ï¼šåè¯ï¼ŒåŸºå‡†æµ‹è¯• ğŸ”¥
* **continuous monitoring**ï¼šæŒç»­ç›‘æ§
* **consistent performance**ï¼šä¸€è‡´çš„æ€§èƒ½
* **compound** /kÉ™mËˆpaÊŠnd/ï¼šåŠ¨è¯ï¼Œå¤åˆã€ç´¯ç§¯ ğŸ”¥

---

(29) [8:57-9:26] **Yeah it's nuts. What do you um what are you seeing out there uh from like what we're seeing that for sure that like you reduce your um you know go from three nines to four nines or go from two nines to three nines or whatever. Because you're compounding um you like the user experience gets so much better. As you reduce latency too the that latency stacks up linearly etc. like all these things being worked on at once um is making the experience better.**

æ˜¯çš„ï¼Œå¤ªç–¯ç‹‚äº†ã€‚ä½ ä»¬çœ‹åˆ°å¤–é¢æ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿæˆ‘ä»¬ç¡®å®çœ‹åˆ°ï¼Œå½“ä½ æŠŠå¯ç”¨æ€§ä»ä¸‰ä¸ªä¹æå‡åˆ°å››ä¸ªä¹ï¼Œæˆ–è€…ä»ä¸¤ä¸ªä¹æå‡åˆ°ä¸‰ä¸ªä¹ï¼Œå› ä¸ºæ˜¯å¤åˆæ•ˆåº”ï¼Œç”¨æˆ·ä½“éªŒä¼šå˜å¾—å¥½å¾ˆå¤šã€‚å½“ä½ é™ä½å»¶è¿Ÿæ—¶ï¼Œå»¶è¿Ÿä¹Ÿæ˜¯çº¿æ€§ç´¯åŠ çš„ã€‚æ‰€æœ‰è¿™äº›åŒæ—¶æ”¹è¿›ï¼Œæ­£åœ¨è®©ä½“éªŒå˜å¾—æ›´å¥½ã€‚

è§£æï¼š
* **three nines / four nines**ï¼šä¸‰ä¸ªä¹ / å››ä¸ªä¹ï¼ˆå¯ç”¨æ€§æŒ‡æ ‡ï¼Œ99.9% / 99.99%ï¼‰ğŸ”¥
* **stack up**ï¼šç´¯åŠ 
* **linearly** /ËˆlÉªniÉ™rli/ï¼šå‰¯è¯ï¼Œçº¿æ€§åœ°

---

(30) [9:29-9:55] **But you see so many different people building and testing you know, how's it going? What's the state of voice AI interfaces right now? Yeah, I mean definitely latency like to your point or all of these things when you make gains at one turn then they compound either negatively or positively. Like if you cut latency by 10% on any one turn, that adds up across the whole conversation. So now you can cut the entire length of the conversation.**

ä½†ä½ ä»¬çœ‹åˆ°è¿™ä¹ˆå¤šäººåœ¨æ„å»ºå’Œæµ‹è¯•ï¼Œç°åœ¨çš„æƒ…å†µæ€ä¹ˆæ ·ï¼Ÿè¯­éŸ³ AI ç•Œé¢ç°åœ¨æ˜¯ä»€ä¹ˆçŠ¶æ€ï¼Ÿæ˜¯çš„ï¼Œå°±åƒä½ è¯´çš„ï¼Œå»¶è¿Ÿç¡®å®â€”â€”æ‰€æœ‰è¿™äº›ä¸œè¥¿ï¼Œå½“ä½ åœ¨ä¸€è½®å¯¹è¯ä¸­è·å¾—æå‡ï¼Œå®ƒä»¬ä¼šæ­£å‘æˆ–è´Ÿå‘å¤åˆã€‚å¦‚æœä½ åœ¨ä»»ä½•ä¸€è½®å¯¹è¯ä¸­å‡å°‘ 10% çš„å»¶è¿Ÿï¼Œè¿™ä¼šåœ¨æ•´ä¸ªå¯¹è¯ä¸­ç´¯åŠ èµ·æ¥ã€‚è¿™æ ·ä½ å°±å¯ä»¥ç¼©çŸ­æ•´ä¸ªå¯¹è¯çš„æ—¶é•¿ã€‚

è§£æï¼š
* **what's the state of**ï¼š...ç°åœ¨æ˜¯ä»€ä¹ˆçŠ¶æ€
* **make gains**ï¼šè·å¾—æå‡
* **add up**ï¼šç´¯åŠ 

---

(31) [9:55-10:21] **And then I think what's been really cool recently is just how reliable these models have gotten, how low latency has become less of an issue. We've seen that over the course of the last year and a half. I think a year and a half ago just getting a voice model to have a conversation that was not incredibly high latency was really really hard.**

æœ€è¿‘çœŸæ­£é…·çš„æ˜¯è¿™äº›æ¨¡å‹å˜å¾—å¤šä¹ˆå¯é ï¼Œå»¶è¿Ÿå·²ç»ä¸å†æ˜¯é‚£ä¹ˆå¤§çš„é—®é¢˜ã€‚è¿‡å»ä¸€å¹´åŠæˆ‘ä»¬çœ‹åˆ°äº†è¿™ä¸€ç‚¹ã€‚ä¸€å¹´åŠå‰ï¼Œè®©è¯­éŸ³æ¨¡å‹è¿›è¡Œä¸€æ¬¡å»¶è¿Ÿä¸é‚£ä¹ˆé«˜çš„å¯¹è¯çœŸçš„å¾ˆéš¾ã€‚

è§£æï¼š
* **over the course of**ï¼šåœ¨...æœŸé—´
* **become less of an issue**ï¼šä¸å†æ˜¯é‚£ä¹ˆå¤§çš„é—®é¢˜ ğŸ”¥

---

(32) [10:21-10:43] **And I think today now people are focusing a lot more on these complex architectures of how can I have failover mechanisms to get to those multiple nines of reliability or how can I have background agents to add guardrails? How can I be doing even more like pushing the bounds of what voice agents can do I think will always be there. So we'll always be fighting latency.**

æˆ‘è®¤ä¸ºä»Šå¤©äººä»¬æ›´å¤šåœ°å…³æ³¨è¿™äº›å¤æ‚æ¶æ„ï¼šå¦‚ä½•å®ç°æ•…éšœè½¬ç§»æœºåˆ¶æ¥è¾¾åˆ°å¤šä¸ªä¹çš„å¯é æ€§ï¼Œå¦‚ä½•ç”¨åå°ä»£ç†æ·»åŠ æŠ¤æ ï¼Œå¦‚ä½•åšæ›´å¤šæ¥çªç ´è¯­éŸ³ä»£ç†èƒ½åšä»€ä¹ˆçš„è¾¹ç•Œâ€”â€”æˆ‘è®¤ä¸ºè¿™äº›è¿½æ±‚ä¼šä¸€ç›´å­˜åœ¨ã€‚æ‰€ä»¥æˆ‘ä»¬å°†æ°¸è¿œåœ¨ä¸å»¶è¿Ÿä½œæˆ˜ã€‚

è§£æï¼š
* **failover mechanisms**ï¼šæ•…éšœè½¬ç§»æœºåˆ¶ ğŸ”¥
* **guardrails**ï¼šåè¯ï¼ŒæŠ¤æ ï¼ˆAI é¢†åŸŸæŒ‡å®‰å…¨é™åˆ¶ï¼‰ğŸ”¥
* **background agents**ï¼šåå°ä»£ç†
* **push the bounds**ï¼šçªç ´è¾¹ç•Œ

---

(33) [10:38-11:00] **Um, but what people can do is much more along those lines. I think with Neuroplex, um, I'm really excited about like your vision of Neuroplex, but how do you think that this raise is going to help you guys to invest even more in like which models do you think you'll be spending even more energy on other than you guys are obviously very known for transcription? Um, where do you think you guys are going next?**

ä½†äººä»¬èƒ½åšçš„äº‹æƒ…åœ¨è¿™äº›æ–¹é¢å¤šäº†å¾ˆå¤šã€‚è¯´åˆ° **Neuroplex**ï¼Œæˆ‘å¯¹ä½ ä»¬çš„ **Neuroplex** æ„¿æ™¯çœŸçš„å¾ˆå…´å¥‹ã€‚ä½ è§‰å¾—è¿™æ¬¡èèµ„ä¼šå¦‚ä½•å¸®åŠ©ä½ ä»¬åŠ å¤§æŠ•å…¥ï¼Ÿé™¤äº†ä½ ä»¬æ˜¾ç„¶æœ€çŸ¥åçš„è½¬å½•ä¹‹å¤–ï¼Œä½ ä»¬è®¤ä¸ºä¼šåœ¨å“ªäº›æ¨¡å‹ä¸ŠæŠ•å…¥æ›´å¤šç²¾åŠ›ï¼Ÿä½ ä»¬ä¸‹ä¸€æ­¥è¦å¾€å“ªä¸ªæ–¹å‘èµ°ï¼Ÿ

è§£æï¼š
* **along those lines**ï¼šæ²¿ç€é‚£äº›æ–¹å‘ã€åœ¨é‚£æ–¹é¢ ğŸ”¥
* **transcription** /trÃ¦nËˆskrÉªpÊƒn/ï¼šåè¯ï¼Œè½¬å½•ï¼ˆè¯­éŸ³è½¬æ–‡å­—ï¼‰ğŸ”¥
* **be known for**ï¼šå› ...è€Œé—»å ğŸ”¥

---

(34) [11:29-11:51] **Um, and when you are when you're perceiving something, so for instance, like listening to audio, there's a portion of your brain that is doing that perception, but then it sort of hands that off, but through a it's it's not transcribing it in text. I can tell you that, and then handing it off to another part of your brain.**

å½“ä½ åœ¨æ„ŸçŸ¥æŸäº›ä¸œè¥¿çš„æ—¶å€™ï¼Œæ¯”å¦‚å¬éŸ³é¢‘ï¼Œä½ å¤§è„‘çš„æŸä¸ªéƒ¨åˆ†åœ¨åšæ„ŸçŸ¥ï¼Œç„¶åå®ƒä¼šæŠŠè¿™ä¸ªä¿¡æ¯ä¼ é€’å‡ºå»ã€‚ä½†æˆ‘å¯ä»¥å‘Šè¯‰ä½ ï¼Œå®ƒä¸æ˜¯æŠŠéŸ³é¢‘è½¬å½•æˆæ–‡å­—ï¼Œç„¶åå†ä¼ é€’ç»™å¤§è„‘çš„å¦ä¸€ä¸ªéƒ¨åˆ†ã€‚

è§£æï¼š
* **perceive** /pÉ™rËˆsiËv/ï¼šåŠ¨è¯ï¼Œæ„ŸçŸ¥
* **portion**ï¼šåè¯ï¼Œéƒ¨åˆ†
* **hand off**ï¼šä¼ é€’ã€äº¤æ¥ ğŸ”¥
* **transcribe**ï¼šåŠ¨è¯ï¼Œè½¬å½•

---

(35) [11:46-12:03] **It's giving it this like uh this impression through the only thing that I could equate it to in deep learning is uh like a rich embedding. It's passing over this like rich embedding to another part of your brain through the white matter and then that part of your brain is processing that.**

å®ƒä¼ é€’çš„æ˜¯ä¸€ç§"å°è±¡"â€”â€”åœ¨æ·±åº¦å­¦ä¹ ä¸­æˆ‘èƒ½ç±»æ¯”çš„å”¯ä¸€ä¸œè¥¿å°±æ˜¯ä¸€ä¸ªä¸°å¯Œçš„åµŒå…¥å‘é‡ã€‚å®ƒé€šè¿‡ç™½è´¨æŠŠè¿™ä¸ªä¸°å¯Œçš„åµŒå…¥å‘é‡ä¼ é€’ç»™å¤§è„‘çš„å¦ä¸€ä¸ªéƒ¨åˆ†ï¼Œç„¶åé‚£ä¸ªéƒ¨åˆ†å¤„ç†å®ƒã€‚

è§£æï¼š
* **equate to**ï¼šç­‰åŒäºã€ç±»æ¯”ä¸º ğŸ”¥
* **rich embedding**ï¼šä¸°å¯Œçš„åµŒå…¥å‘é‡
* **white matter**ï¼šç™½è´¨ï¼ˆå¤§è„‘ç¥ç»çº¤ç»´ï¼‰
* **pass over**ï¼šä¼ é€’

---

(36) [12:01-12:22] **And you know thinking deeply oh what should I respond with oh maybe they mean this maybe they mean that etc. Oh okay actually now now I know what to do and then that hands it off to another part of your brain where uh you generate your vocal movements push out the air say what you're going to say or move your hands or click a button and send something etc.**

ç„¶åæ·±å…¥æ€è€ƒï¼šå“¦ï¼Œæˆ‘åº”è¯¥æ€ä¹ˆå›åº”ï¼Ÿä¹Ÿè®¸ä»–ä»¬æ˜¯è¿™ä¸ªæ„æ€ï¼Œä¹Ÿè®¸æ˜¯é‚£ä¸ªæ„æ€ç­‰ç­‰ã€‚å¥½çš„ï¼Œç°åœ¨æˆ‘çŸ¥é“è¯¥æ€ä¹ˆåšäº†ã€‚ç„¶åå®ƒå†æŠŠä¿¡æ¯ä¼ é€’ç»™å¤§è„‘çš„å¦ä¸€ä¸ªéƒ¨åˆ†ï¼Œåœ¨é‚£é‡Œä½ ç”Ÿæˆå£°å¸¦è¿åŠ¨ã€æ¨å‡ºç©ºæ°”ã€è¯´å‡ºä½ è¦è¯´çš„è¯ï¼Œæˆ–è€…ç§»åŠ¨æ‰‹ã€ç‚¹å‡»æŒ‰é’®å‘é€æ¶ˆæ¯ç­‰ç­‰ã€‚

è§£æï¼š
* **respond with**ï¼šç”¨...å›åº”
* **vocal movements**ï¼šå£°å¸¦è¿åŠ¨
* **push out the air**ï¼šæ¨å‡ºç©ºæ°”ï¼ˆå‘å£°è¿‡ç¨‹ï¼‰

---

(37) [12:26-12:49] **And um I think that you know we should use that biology inspired um architecture in building efficient systems. You know we already have human brains that run on like 25 to 50 watts and can do this and uh do an extremely complicated task uh multitask you know do all these things and understand context have obviously a humanlike conversation.**

æˆ‘è®¤ä¸ºæˆ‘ä»¬åº”è¯¥ç”¨è¿™ç§å—ç”Ÿç‰©å­¦å¯å‘çš„æ¶æ„æ¥æ„å»ºé«˜æ•ˆç³»ç»Ÿã€‚äººç±»å¤§è„‘åªç”¨ 25 åˆ° 50 ç“¦çš„åŠŸç‡å°±èƒ½åšåˆ°è¿™äº›ï¼Œèƒ½æ‰§è¡Œæå…¶å¤æ‚çš„ä»»åŠ¡ã€å¤šä»»åŠ¡å¤„ç†ã€ç†è§£ä¸Šä¸‹æ–‡ã€è¿›è¡Œç±»äººå¯¹è¯ã€‚

è§£æï¼š
* **biology inspired**ï¼šå—ç”Ÿç‰©å­¦å¯å‘çš„ ğŸ”¥
* **run on X watts**ï¼šä»¥ X ç“¦åŠŸç‡è¿è¡Œ
* **multitask**ï¼šåŠ¨è¯ï¼Œå¤šä»»åŠ¡å¤„ç†
* **humanlike**ï¼šå½¢å®¹è¯ï¼Œç±»äººçš„

---

(38) [12:46-13:06] **This is what humans do. Um so you have an example proof already. So let's use that. And this is what Neuroplex is all about. Um so it's not just speech to text plus an LLM plus text to speech. Um it's uh context passing throughout all of it, but it's a modular architecture that you uh that is not a blackbox.**

è¿™å°±æ˜¯äººç±»åšçš„äº‹æƒ…ã€‚æ‰€ä»¥ä½ å·²ç»æœ‰äº†ä¸€ä¸ªç°æˆçš„è¯æ˜ã€‚è®©æˆ‘ä»¬åˆ©ç”¨å®ƒã€‚è¿™å°±æ˜¯ **Neuroplex** çš„æ ¸å¿ƒã€‚å®ƒä¸åªæ˜¯è¯­éŸ³è½¬æ–‡å­—åŠ  LLM åŠ æ–‡å­—è½¬è¯­éŸ³ã€‚å®ƒæ˜¯åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¼ é€’ä¸Šä¸‹æ–‡ï¼Œè€Œä¸”æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¶æ„ï¼Œä¸æ˜¯é»‘ç›’ã€‚

è§£æï¼š
* **example proof**ï¼šç°æˆçš„è¯æ˜
* **speech to text / text to speech**ï¼šè¯­éŸ³è½¬æ–‡å­— / æ–‡å­—è½¬è¯­éŸ³ï¼ˆSTT/TTSï¼‰
* **context passing**ï¼šä¸Šä¸‹æ–‡ä¼ é€’ ğŸ”¥
* **modular architecture**ï¼šæ¨¡å—åŒ–æ¶æ„ ğŸ”¥
* **blackbox**ï¼šé»‘ç›’ï¼ˆæ— æ³•ç†è§£å†…éƒ¨è¿ä½œï¼‰

---

(39) [13:06-13:27] **This is another key feature actually to um a silicon brain rather than a carbon based brain. Um our carbon based brains it's really hard to measure the embeddings. It's really hard to know exactly what somebody is thinking. etc. But with these silicon brains, you actually if you form them the right way and this is what Neuroplex is about.**

è¿™å®é™…ä¸Šæ˜¯ç¡…åŸºå¤§è„‘ç›¸å¯¹äºç¢³åŸºå¤§è„‘çš„å¦ä¸€ä¸ªå…³é”®ç‰¹æ€§ã€‚æˆ‘ä»¬çš„ç¢³åŸºå¤§è„‘ï¼ŒçœŸçš„å¾ˆéš¾æµ‹é‡åµŒå…¥å‘é‡ï¼Œå¾ˆéš¾ç¡®åˆ‡çŸ¥é“æŸäººåœ¨æƒ³ä»€ä¹ˆã€‚ä½†å¯¹äºè¿™äº›ç¡…åŸºå¤§è„‘ï¼Œå¦‚æœä½ ä»¥æ­£ç¡®çš„æ–¹å¼æ„å»ºå®ƒä»¬â€”â€”è¿™æ­£æ˜¯ **Neuroplex** è¦åšçš„â€”â€”

è§£æï¼š
* **silicon brain**ï¼šç¡…åŸºå¤§è„‘ï¼ˆAI ç³»ç»Ÿï¼‰ğŸ”¥
* **carbon based brain**ï¼šç¢³åŸºå¤§è„‘ï¼ˆäººè„‘ï¼‰
* **measure the embeddings**ï¼šæµ‹é‡åµŒå…¥å‘é‡

---

(40) [13:25-13:48] **And we have a white paper out there so you can um look at that. But uh if you form them the right way, they then you can actually inspect like what is that brain thinking? Um what did it think it heard? Um what does it think its next move should be? And then this also gives you an opportunity to put guardrails in to say whoa whoa whoa, you know, maybe don't do that.**

æˆ‘ä»¬æœ‰ä¸€ç¯‡ç™½çš®ä¹¦ï¼Œä½ å¯ä»¥å»çœ‹çœ‹ã€‚å¦‚æœä½ ä»¥æ­£ç¡®çš„æ–¹å¼æ„å»ºå®ƒä»¬ï¼Œä½ å°±å¯ä»¥çœŸæ­£æ£€æŸ¥è¿™ä¸ªå¤§è„‘åœ¨æƒ³ä»€ä¹ˆï¼Œå®ƒè®¤ä¸ºå®ƒå¬åˆ°äº†ä»€ä¹ˆï¼Œå®ƒè®¤ä¸ºä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆã€‚è¿™ä¹Ÿç»™äº†ä½ æ·»åŠ æŠ¤æ çš„æœºä¼šï¼Œè¯´"å“‡å“‡å“‡ï¼Œä¹Ÿè®¸åˆ«è¿™æ ·åš"ã€‚

è§£æï¼š
* **white paper**ï¼šç™½çš®ä¹¦ï¼ˆæŠ€æœ¯æ–‡æ¡£ï¼‰ğŸ”¥
* **inspect**ï¼šåŠ¨è¯ï¼Œæ£€æŸ¥ã€å®¡è§†
* **next move**ï¼šä¸‹ä¸€æ­¥è¡ŒåŠ¨
* **put guardrails in**ï¼šæ·»åŠ æŠ¤æ 

---

(41) [13:48-14:10] **Yeah. So um but also you know are opening up that new type of framework or architecture there will be challenges with it too um and I think people see this in speech to speech models now. I'm basically I'm just describing a speech to speech model I'm describing a different way to build a speech to speech model but uh the current speech to speech models are black boxes you can't control them as much etc.**

æ˜¯çš„ã€‚å½“ç„¶ï¼Œå¼€æ”¾è¿™ç§æ–°å‹æ¡†æ¶æˆ–æ¶æ„ä¹Ÿä¼šæœ‰æŒ‘æˆ˜ã€‚æˆ‘è®¤ä¸ºäººä»¬åœ¨ç°åœ¨çš„è¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹ä¸­çœ‹åˆ°äº†è¿™ä¸€ç‚¹ã€‚æˆ‘åŸºæœ¬ä¸Šå°±æ˜¯åœ¨æè¿°ä¸€ä¸ªè¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹ï¼Œåªæ˜¯æè¿°äº†ä¸€ç§ä¸åŒçš„æ„å»ºæ–¹å¼ã€‚ä½†ç›®å‰çš„è¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹æ˜¯é»‘ç›’ï¼Œä½ æ— æ³•å¾ˆå¥½åœ°æ§åˆ¶å®ƒä»¬ã€‚

è§£æï¼š
* **speech to speech model**ï¼šè¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹ ğŸ”¥
* **open up**ï¼šå¼€æ”¾ã€å¼€å¯
* **black box**ï¼šé»‘ç›’

---

(42) [14:10-14:31] **And so if you look at B2B adoption of um of the real-time speech to speech models that are out there they're uh it it's typically really low um because they it can't it can't control it as well, can't debug it as well. Um it can't guardrail it as well. Also, just reliability is typically worse. Latency is worse, you know, all these things.**

æ‰€ä»¥å¦‚æœä½ çœ‹çœ‹å¸‚é¢ä¸Šå®æ—¶è¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹çš„ B2B é‡‡ç”¨ç‡ï¼Œé€šå¸¸éå¸¸ä½ã€‚å› ä¸ºæ— æ³•å¾ˆå¥½åœ°æ§åˆ¶å®ƒï¼Œæ— æ³•å¾ˆå¥½åœ°è°ƒè¯•å®ƒï¼Œæ— æ³•å¾ˆå¥½åœ°æ·»åŠ æŠ¤æ ã€‚è€Œä¸”å¯é æ€§é€šå¸¸æ›´å·®ï¼Œå»¶è¿Ÿä¹Ÿæ›´å·®ï¼Œæ‰€æœ‰è¿™äº›é—®é¢˜ã€‚

è§£æï¼š
* **B2B adoption**ï¼šä¼ä¸šå¯¹ä¼ä¸šé‡‡ç”¨ç‡ ğŸ”¥
* **debug** /diËËˆbÊŒÉ¡/ï¼šåŠ¨è¯ï¼Œè°ƒè¯•
* **reliability**ï¼šåè¯ï¼Œå¯é æ€§

---

(43) [14:31-14:56] **Um but the uh Neuroplex architecture is addressing all these at once. Um but this is a big research project at Deepgram. So it's uh it means more people, more compute, more data, uh more testing with um uh you know with partners and customers. Um and our product team loves uh talking with folks about this.**

ä½† **Neuroplex** æ¶æ„æ­£åœ¨ä¸€æ¬¡æ€§è§£å†³æ‰€æœ‰è¿™äº›é—®é¢˜ã€‚ä½†è¿™æ˜¯ **Deepgram** çš„ä¸€ä¸ªå¤§å‹ç ”ç©¶é¡¹ç›®ã€‚æ‰€ä»¥è¿™æ„å‘³ç€éœ€è¦æ›´å¤šçš„äººã€æ›´å¤šçš„ç®—åŠ›ã€æ›´å¤šçš„æ•°æ®ã€æ›´å¤šä¸åˆä½œä¼™ä¼´å’Œå®¢æˆ·çš„æµ‹è¯•ã€‚æˆ‘ä»¬çš„äº§å“å›¢é˜Ÿå¾ˆå–œæ¬¢å’Œå¤§å®¶è®¨è®ºè¿™ä¸ªè¯é¢˜ã€‚

è§£æï¼š
* **address**ï¼šåŠ¨è¯ï¼Œè§£å†³ï¼ˆé—®é¢˜ï¼‰
* **at once**ï¼šä¸€æ¬¡æ€§ã€åŒæ—¶
* **research project**ï¼šç ”ç©¶é¡¹ç›®

---

(44) [14:53-15:20] **Um uh actually another part of our raise is uh starting a uh a collaboration hub learning center in San Francisco. So it'll be uh downtown right near Salesforce Park. We want to invite our partners, customers, anybody curious about voice to go there, look at talks, look at the next generation of voice, um, and see like some before it's released demos of Neuroplex and that type of thing where our researchers and engineers are showing off what they're working on. Um, so I'm excited about that.**

å®é™…ä¸Šï¼Œè¿™æ¬¡èèµ„çš„å¦ä¸€éƒ¨åˆ†æ˜¯åœ¨æ—§é‡‘å±±å¯åŠ¨ä¸€ä¸ªåä½œä¸­å¿ƒå­¦ä¹ ä¸­å¿ƒã€‚å®ƒä¼šåœ¨å¸‚ä¸­å¿ƒï¼Œå°±åœ¨ **Salesforce Park** é™„è¿‘ã€‚æˆ‘ä»¬æƒ³é‚€è¯·æˆ‘ä»¬çš„åˆä½œä¼™ä¼´ã€å®¢æˆ·ã€ä»»ä½•å¯¹è¯­éŸ³æ„Ÿå…´è¶£çš„äººæ¥é‚£é‡Œï¼Œçœ‹æ¼”è®²ï¼Œçœ‹ä¸‹ä¸€ä»£è¯­éŸ³æŠ€æœ¯ï¼Œçœ‹ä¸€äº› **Neuroplex** å‘å¸ƒå‰çš„æ¼”ç¤ºï¼Œæˆ‘ä»¬çš„ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆä¼šå±•ç¤ºä»–ä»¬æ­£åœ¨åšçš„ä¸œè¥¿ã€‚æˆ‘å¯¹æ­¤å¾ˆå…´å¥‹ã€‚

è§£æï¼š
* **collaboration hub**ï¼šåä½œä¸­å¿ƒ ğŸ”¥
* **learning center**ï¼šå­¦ä¹ ä¸­å¿ƒ
* **before it's released**ï¼šå‘å¸ƒå‰çš„
* **show off**ï¼šå±•ç¤º

---

(45) [15:20-15:43] **That's awesome. Yeah. And I'm especially excited because I think even short term like long-term like this vision of Neuroplex, but I think even how that manifests into systems today is very similar to how autonomy and self-driving was able to get ahead is by having these models that are able to talk to each other and having this comm's layer where you can hear a siren and then also see like what's happening around me via LIDAR, via cameras.**

å¤ªæ£’äº†ã€‚æˆ‘ç‰¹åˆ«å…´å¥‹ï¼Œå› ä¸ºä¸ç®¡æ˜¯çŸ­æœŸè¿˜æ˜¯é•¿æœŸçš„ **Neuroplex** æ„¿æ™¯ï¼Œæˆ‘è®¤ä¸ºå®ƒåœ¨ä»Šå¤©ç³»ç»Ÿä¸­çš„ä½“ç°æ–¹å¼ï¼Œéå¸¸ç±»ä¼¼äºè‡ªåŠ¨é©¾é©¶èƒ½å¤Ÿå–å¾—é¢†å…ˆçš„æ–¹å¼â€”â€”é€šè¿‡è®©è¿™äº›æ¨¡å‹èƒ½å¤Ÿç›¸äº’é€šä¿¡ï¼Œæœ‰ä¸€ä¸ªé€šä¿¡å±‚ï¼Œä½ å¯ä»¥å¬åˆ°è­¦ç¬›ï¼ŒåŒæ—¶é€šè¿‡æ¿€å…‰é›·è¾¾ã€æ‘„åƒå¤´çœ‹åˆ°å‘¨å›´å‘ç”Ÿçš„äº‹æƒ…ã€‚

è§£æï¼š
* **manifest into**ï¼šä½“ç°ä¸ºã€è¡¨ç°ä¸º ğŸ”¥
* **autonomy**ï¼šåè¯ï¼Œè‡ªä¸»æ€§
* **self-driving**ï¼šè‡ªåŠ¨é©¾é©¶
* **comm's layer**ï¼šé€šä¿¡å±‚ï¼ˆcommunication layerï¼‰
* **LIDAR**ï¼šæ¿€å…‰é›·è¾¾

---

(46) [15:43-15:57] **And have all of these sensory inputs to then make decisions around what do I think this person is going to do next or where should the car go next? And I think that's really what we need in voice AI is to have that next level of autonomy.**

æ‹¥æœ‰æ‰€æœ‰è¿™äº›æ„Ÿå®˜è¾“å…¥ï¼Œç„¶ååšå‡ºå†³ç­–ï¼šè¿™ä¸ªäººä¸‹ä¸€æ­¥ä¼šåšä»€ä¹ˆï¼Ÿè½¦åº”è¯¥å¾€å“ªé‡Œèµ°ï¼Ÿæˆ‘è®¤ä¸ºè¿™æ­£æ˜¯è¯­éŸ³ AI éœ€è¦çš„â€”â€”æ‹¥æœ‰ä¸‹ä¸€ä¸ªå±‚æ¬¡çš„è‡ªä¸»æ€§ã€‚

è§£æï¼š
* **sensory inputs**ï¼šæ„Ÿå®˜è¾“å…¥ ğŸ”¥
* **make decisions around**ï¼šå›´ç»•...åšå†³ç­–
* **next level of**ï¼šä¸‹ä¸€ä¸ªå±‚æ¬¡çš„

---

(47) [15:57-16:17] **You need to have parallel systems because you don't when you're a human walking through the world, you don't take one step forward and say, "Okay, let me reassess what I'm going to do next. Now, I'm going to take another step forward." And the same is true as you're speaking. I'm constantly thinking about what I'm going to say next.**

ä½ éœ€è¦æœ‰å¹¶è¡Œç³»ç»Ÿã€‚å› ä¸ºå½“ä½ ä½œä¸ºäººç±»è¡Œèµ°åœ¨ä¸–ç•Œä¸Šæ—¶ï¼Œä½ ä¸ä¼šèµ°ä¸€æ­¥ç„¶åè¯´"å¥½ï¼Œè®©æˆ‘é‡æ–°è¯„ä¼°ä¸€ä¸‹ä¸‹ä¸€æ­¥è¦åšä»€ä¹ˆï¼Œç°åœ¨æˆ‘å†èµ°ä¸€æ­¥"ã€‚è¯´è¯ä¹Ÿæ˜¯ä¸€æ ·ã€‚æˆ‘ä¸€ç›´åœ¨æƒ³æ¥ä¸‹æ¥è¦è¯´ä»€ä¹ˆã€‚

è§£æï¼š
* **parallel systems**ï¼šå¹¶è¡Œç³»ç»Ÿ ğŸ”¥
* **reassess** /ËŒriËÉ™Ëˆses/ï¼šåŠ¨è¯ï¼Œé‡æ–°è¯„ä¼°
* **constantly**ï¼šå‰¯è¯ï¼Œä¸æ–­åœ°

---

(48) [16:10-16:31] **Thinking about like lots of background ideas, kind of also at the same time listening to what you're saying. And so I think I'm really excited about this vision from at least as a nerd in self-driving that this is definitely like a direction that I'm really bullish on bringing us just like that next leap forward, not just incrementally forward.**

åŒæ—¶æ€è€ƒå¾ˆå¤šèƒŒæ™¯æƒ³æ³•ï¼Œä¹Ÿåœ¨åŒæ—¶å¬ä½ åœ¨è¯´ä»€ä¹ˆã€‚ä½œä¸ºä¸€ä¸ªè‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„æŠ€æœ¯å®…ï¼Œæˆ‘å¯¹è¿™ä¸ªæ„¿æ™¯çœŸçš„å¾ˆå…´å¥‹ã€‚æˆ‘éå¸¸çœ‹å¥½è¿™ä¸ªæ–¹å‘èƒ½å¸¦ç»™æˆ‘ä»¬ä¸‹ä¸€ä¸ªé£è·ƒï¼Œè€Œä¸åªæ˜¯æ¸è¿›å¼å‰è¿›ã€‚

è§£æï¼š
* **background ideas**ï¼šèƒŒæ™¯æƒ³æ³•
* **nerd**ï¼šåè¯ï¼ŒæŠ€æœ¯å®…ã€æå®¢
* **bullish on**ï¼šçœ‹å¥½ã€çœ‹æ¶¨ ğŸ”¥
* **leap forward**ï¼šé£è·ƒ
* **incrementally**ï¼šå‰¯è¯ï¼Œæ¸è¿›åœ°

---

(49) [16:31-17:00] **Yeah. And yeah, it's we can just look at robotics systems and how they progressed and how they had to work in the real world and how they had the different levels and uh you don't have to reinvent the wheel here uh in order to in order to predict the future of what's going to happen in voice AI. Um uh you just look at the different systems in those different levels and try to build in the redundancy.**

æ˜¯çš„ã€‚æˆ‘ä»¬å¯ä»¥çœ‹çœ‹æœºå™¨äººç³»ç»Ÿæ˜¯å¦‚ä½•å‘å±•çš„ï¼Œå®ƒä»¬å¦‚ä½•åœ¨ç°å®ä¸–ç•Œä¸­å·¥ä½œï¼Œå¦‚ä½•æœ‰ä¸åŒçš„å±‚çº§ã€‚ä½ ä¸éœ€è¦é‡æ–°å‘æ˜è½®å­æ¥é¢„æµ‹è¯­éŸ³ AI çš„æœªæ¥ä¼šå‘ç”Ÿä»€ä¹ˆã€‚åªéœ€è¦çœ‹çœ‹è¿™äº›ä¸åŒå±‚çº§ä¸­çš„ä¸åŒç³»ç»Ÿï¼Œå°è¯•æ„å»ºå†—ä½™æ€§ã€‚

è§£æï¼š
* **robotics systems**ï¼šæœºå™¨äººç³»ç»Ÿ
* **reinvent the wheel**ï¼šé‡æ–°å‘æ˜è½®å­ï¼ˆåšä¸å¿…è¦çš„é‡å¤å·¥ä½œï¼‰ğŸ”¥
* **redundancy** /rÉªËˆdÊŒndÉ™nsi/ï¼šåè¯ï¼Œå†—ä½™æ€§

---

(50) [16:57-17:21] **And they're fairly common architectures to do that. Um so yeah um but I'll tell you like building in voice AI right now um and just in AI in general but you know from a frontier perspective there are so many like stones to flip over and look under um and there's the prevalent um story is just go just go bigger build bigger more data more more more uh more GPUs more data um larger models more memory etc.**

è¿™äº›éƒ½æ˜¯ç›¸å½“å¸¸è§çš„æ¶æ„ã€‚ä½†æˆ‘å‘Šè¯‰ä½ ï¼Œç°åœ¨åœ¨è¯­éŸ³ AI é¢†åŸŸæ„å»ºï¼Œä»å‰æ²¿è§’åº¦æ¥è¯´ï¼Œæœ‰å¤ªå¤šçŸ³å¤´å¯ä»¥ç¿»å¼€å»æ¢ç´¢ã€‚è€Œä¸»æµå™äº‹å°±æ˜¯"åšå¤§ã€å»ºæ›´å¤§ã€æ›´å¤šæ•°æ®ã€æ›´å¤š GPUã€æ›´å¤§æ¨¡å‹ã€æ›´å¤šå†…å­˜"ç­‰ç­‰ã€‚

è§£æï¼š
* **fairly common**ï¼šç›¸å½“å¸¸è§
* **stones to flip over**ï¼šå¯ä»¥ç¿»å¼€æ¢ç´¢çš„çŸ³å¤´ï¼ˆæ¯”å–»å¾…å‘ç°çš„æœºä¼šï¼‰ğŸ”¥
* **prevalent** /ËˆprevÉ™lÉ™nt/ï¼šå½¢å®¹è¯ï¼Œæµè¡Œçš„ã€ä¸»æµçš„
* **GPUs**ï¼šå›¾å½¢å¤„ç†å™¨

---

(51) [17:34-18:05] **Um, and that's kind of a band-aid. Uh, like it does get you advances, but like your expenses are compounding like with n squared. It's not an efficient way to go about solving the problem. Um, and when you build the system in this other way where you have a few compartmentalized smart pieces of design in there to handle different planning tasks and that type of thing, then you just took your compute load that you needed and maybe divided by 100.**

é‚£æœ‰ç‚¹åƒåˆ›å¯è´´ã€‚å®ƒç¡®å®èƒ½è®©ä½ è¿›æ­¥ï¼Œä½†ä½ çš„å¼€æ”¯æ˜¯ä»¥ n çš„å¹³æ–¹åœ¨å¤åˆå¢é•¿ã€‚è¿™ä¸æ˜¯è§£å†³é—®é¢˜çš„é«˜æ•ˆæ–¹å¼ã€‚å½“ä½ ç”¨å¦ä¸€ç§æ–¹å¼æ„å»ºç³»ç»Ÿâ€”â€”ç”¨å‡ ä¸ªæ¨¡å—åŒ–çš„æ™ºèƒ½è®¾è®¡æ¥å¤„ç†ä¸åŒçš„è§„åˆ’ä»»åŠ¡â€”â€”ä½ å°±å¯ä»¥æŠŠæ‰€éœ€çš„ç®—åŠ›è´Ÿè½½é™¤ä»¥ 100ã€‚

è§£æï¼š
* **band-aid**ï¼šåˆ›å¯è´´ï¼ˆæ¯”å–»ä¸´æ—¶è§£å†³æ–¹æ¡ˆï¼‰ğŸ”¥
* **n squared**ï¼šn çš„å¹³æ–¹
* **compartmentalized**ï¼šå½¢å®¹è¯ï¼Œæ¨¡å—åŒ–çš„ã€åˆ†éš”çš„ ğŸ”¥
* **compute load**ï¼šç®—åŠ›è´Ÿè½½

---

(52) [18:05-18:38] **Um and it's yeah it this is how things will advance and actually it's an interesting thing I think it's tempting for folks to think yeah but compute will get so cheap that it won't matter. And I don't know maybe 20 years from now 10 years from now something like that. But there's an assumed equivalence that isn't real here because if you reduce your compute needed in order to do a task, now you can use smarter components. Um so it always wins to have the componentized approach as long as it's as expressive as the mega model.**

è¿™å°±æ˜¯äº‹æƒ…å°†å¦‚ä½•å‘å±•ã€‚æœ‰è¶£çš„æ˜¯ï¼Œäººä»¬å¾ˆå®¹æ˜“æƒ³"ä½†æ˜¯ç®—åŠ›ä¼šå˜å¾—å¾ˆä¾¿å®œï¼Œè¿™å°±ä¸é‡è¦äº†"ã€‚ä¹Ÿè®¸ 10 å¹´ 20 å¹´åå§ã€‚ä½†è¿™é‡Œæœ‰ä¸€ä¸ªå‡è®¾çš„ç­‰ä»·æ€§å…¶å®ä¸æˆç«‹ï¼šå¦‚æœä½ å‡å°‘å®Œæˆä»»åŠ¡æ‰€éœ€çš„ç®—åŠ›ï¼Œä½ å°±å¯ä»¥ä½¿ç”¨æ›´æ™ºèƒ½çš„ç»„ä»¶ã€‚æ‰€ä»¥åªè¦æ¨¡å—åŒ–æ–¹æ³•å’Œå¤§æ¨¡å‹ä¸€æ ·å…·æœ‰è¡¨è¾¾åŠ›ï¼Œå®ƒå°±æ€»æ˜¯æ›´èƒœä¸€ç­¹ã€‚

è§£æï¼š
* **tempting**ï¼šå½¢å®¹è¯ï¼Œè¯±äººçš„ã€ä»¤äººæƒ³è¦çš„
* **assumed equivalence**ï¼šå‡è®¾çš„ç­‰ä»·æ€§
* **componentized approach**ï¼šæ¨¡å—åŒ–æ–¹æ³• ğŸ”¥
* **expressive**ï¼šå½¢å®¹è¯ï¼Œå…·æœ‰è¡¨è¾¾åŠ›çš„
* **mega model**ï¼šè¶…å¤§æ¨¡å‹

---

(53) [18:38-19:01] **Um so yeah but it's just more complex to have the like sort of component view of the world. Um how do you get them all to work together? Yeah, totally. And heuristics can also take you so far as well as like getting more determinism and more like controllability of those models.**

æ˜¯çš„ï¼Œä½†æ‹¥æœ‰è¿™ç§æ¨¡å—åŒ–çš„ä¸–ç•Œè§‚æ›´å¤æ‚ã€‚ä½ å¦‚ä½•è®©å®ƒä»¬å…¨éƒ¨ååŒå·¥ä½œï¼Ÿå®Œå…¨åŒæ„ã€‚å¯å‘å¼æ–¹æ³•ä¹Ÿèƒ½å¸¦ä½ èµ°å¾ˆè¿œï¼Œè¿˜èƒ½è·å¾—æ›´å¤šç¡®å®šæ€§å’Œå¯¹è¿™äº›æ¨¡å‹æ›´å¤šçš„å¯æ§æ€§ã€‚

è§£æï¼š
* **component view**ï¼šæ¨¡å—åŒ–è§†è§’
* **work together**ï¼šååŒå·¥ä½œ
* **heuristics** /hjuËËˆrÉªstÉªks/ï¼šåè¯ï¼Œå¯å‘å¼æ–¹æ³• ğŸ”¥
* **determinism**ï¼šåè¯ï¼Œç¡®å®šæ€§
* **controllability**ï¼šåè¯ï¼Œå¯æ§æ€§

---

(54) [19:10-19:38] **Yeah. It's an interesting bet like you can put a lot of money and put it in one area and you'll get amazing artifacts that come out of it and they will be useful. Um but after a while you're like wait a minute this has to be deployed at scale in billions of conversations you know multiple times per day and like how just how much are we wasting how much are we destroying the environment etc if we do it that way.**

æ˜¯çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ‰è¶£çš„èµŒæ³¨ã€‚ä½ å¯ä»¥åœ¨ä¸€ä¸ªé¢†åŸŸæŠ•å…¥å¤§é‡èµ„é‡‘ï¼Œä¼šå¾—åˆ°æƒŠäººçš„æˆæœï¼Œå®ƒä»¬ä¹Ÿä¼šæœ‰ç”¨ã€‚ä½†è¿‡ä¸€æ®µæ—¶é—´ä½ ä¼šæƒ³ï¼šç­‰ç­‰ï¼Œè¿™å¿…é¡»å¤§è§„æ¨¡éƒ¨ç½²åœ¨æ•°åäº¿æ¬¡å¯¹è¯ä¸­ï¼Œæ¯å¤©å¤šæ¬¡ã€‚å¦‚æœæˆ‘ä»¬è¿™æ ·åšï¼Œæˆ‘ä»¬æµªè´¹äº†å¤šå°‘ï¼Œç ´åäº†å¤šå°‘ç¯å¢ƒï¼Ÿ

è§£æï¼š
* **bet**ï¼šåè¯ï¼ŒèµŒæ³¨ã€æŠ¼æ³¨
* **artifacts**ï¼šåè¯ï¼Œäº§ç‰©ã€æˆæœ ğŸ”¥
* **deployed at scale**ï¼šå¤§è§„æ¨¡éƒ¨ç½²
* **destroy the environment**ï¼šç ´åç¯å¢ƒ

---

(55) [19:35-20:00] **And that's something we think about all the time and also just you know you can see the sort of eye watering numbers that most frontier AI companies are putting up where they're saying hey look at my ARR yes it's big but then look at how much I burned and it's like a hundred times more and it's like whoa these I can see why people are worried about a bubble if that's what companies are talking about.**

è¿™æ˜¯æˆ‘ä»¬ä¸€ç›´åœ¨æ€è€ƒçš„äº‹æƒ…ã€‚ä½ ä¹Ÿå¯ä»¥çœ‹åˆ°å¤§å¤šæ•°å‰æ²¿ AI å…¬å¸å…¬å¸ƒçš„é‚£äº›ä»¤äººç ç›®çš„æ•°å­—â€”â€”ä»–ä»¬è¯´"çœ‹çœ‹æˆ‘çš„ ARRï¼Œæ˜¯çš„å¾ˆå¤§"ï¼Œä½†å†çœ‹çœ‹ä»–ä»¬çƒ§äº†å¤šå°‘é’±ï¼Œæ˜¯ ARR çš„ä¸€ç™¾å€ã€‚éš¾æ€ªäººä»¬æ‹…å¿ƒæ³¡æ²«ï¼Œå¦‚æœè¿™å°±æ˜¯å…¬å¸ä»¬åœ¨è°ˆè®ºçš„ä¸œè¥¿ã€‚

è§£æï¼š
* **eye watering**ï¼šä»¤äººç ç›®çš„ã€æƒŠäººçš„ ğŸ”¥
* **ARR**ï¼šå¹´åº¦ç»å¸¸æ€§æ”¶å…¥ï¼ˆAnnual Recurring Revenueï¼‰ğŸ”¥
* **burn**ï¼šåŠ¨è¯ï¼Œçƒ§é’±
* **bubble**ï¼šåè¯ï¼Œæ³¡æ²«ï¼ˆç»æµæœ¯è¯­ï¼‰

---

(56) [20:00-20:12] **Totally cool. Well, Scott, congratulations again. I'm super excited for everything that Deepgram has in store. So, uh yeah, congratulations on the big day. Yeah, thank you so much.**

å¤ªé…·äº†ã€‚**Scott**ï¼Œå†æ¬¡ç¥è´ºä½ ã€‚æˆ‘å¯¹ **Deepgram** çš„ä¸€åˆ‡è®¡åˆ’éƒ½è¶…çº§å…´å¥‹ã€‚æ­å–œä½ ä»¬è¿™ä¸ªå¤§æ—¥å­ã€‚éå¸¸æ„Ÿè°¢ã€‚

è§£æï¼š
* **have in store**ï¼šè®¡åˆ’ä¸­ã€å³å°†åˆ°æ¥ ğŸ”¥
* **the big day**ï¼šå¤§æ—¥å­

---

## ğŸ“š æ®µè½å°ç»“

è¿™æ˜¯ **Deepgram** CEO **Scott** å…³äº C è½®èèµ„çš„å®Œæ•´è®¿è°ˆã€‚**Deepgram** å®Œæˆäº† 1.3 äº¿ç¾å…ƒçš„èèµ„ï¼Œä¼°å€¼è¾¾åˆ° 13 äº¿ç¾å…ƒï¼Œç”± **ABP** é¢†æŠ•ã€‚èèµ„èƒŒæ™¯æ˜¯è¯­éŸ³ AI æ­£åœ¨èµ°å‘ä¸»æµï¼Œæˆ˜ç•¥æŠ•èµ„è€…ä¸»åŠ¨æ‰¾ä¸Šé—¨ã€‚èµ„é‡‘å°†ç”¨äºï¼šæ‰©å±•æ ¸å¿ƒäº§å“ã€æ”¯æŒ 100 ç§è¯­è¨€ã€è¿›è¡Œæˆ˜ç•¥æ”¶è´­ã€å¼€å‘ **Neuroplex** æ¶æ„ã€‚

è®¿è°ˆçš„ååŠéƒ¨åˆ†æ·±å…¥è®¨è®ºäº† **Neuroplex** çš„æŠ€æœ¯æ„¿æ™¯ï¼šå—ç”Ÿç‰©å­¦å¯å‘çš„æ¨¡å—åŒ–æ¶æ„ï¼Œæ¨¡ä»¿äººè„‘å¤„ç†æ„ŸçŸ¥ä¿¡æ¯çš„æ–¹å¼ã€‚ä¸å½“å‰çš„"é»‘ç›’"è¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹ä¸åŒï¼Œ**Neuroplex** æ˜¯å¯æ£€æŸ¥ã€å¯è°ƒè¯•ã€å¯æ·»åŠ æŠ¤æ çš„ã€‚**Scott** è¿˜æ‰¹è¯„äº†å½“å‰ AI è¡Œä¸š"æ›´å¤§æ›´å¤š"çš„ä¸»æµå™äº‹ï¼Œè®¤ä¸ºæ¨¡å—åŒ–æ–¹æ³•å¯ä»¥å°†ç®—åŠ›éœ€æ±‚é™ä½ 100 å€ï¼Œæ˜¯æ›´å¯æŒç»­çš„å‘å±•è·¯å¾„ã€‚

**Deepgram** è¿˜å°†åœ¨æ—§é‡‘å±±å¼€è®¾åä½œä¸­å¿ƒå­¦ä¹ ä¸­å¿ƒï¼Œå±•ç¤ºä¸‹ä¸€ä»£è¯­éŸ³æŠ€æœ¯ã€‚

### ğŸ”¥ æ ¸å¿ƒè¯æ±‡è¡¨

| è¯æ±‡/çŸ­è¯­ | å«ä¹‰ |
|---------|------|
| **series C** | C è½®èèµ„ |
| **valuation** | ä¼°å€¼ |
| **led by** | ç”±...é¢†æŠ• |
| **go mainstream** | æˆä¸ºä¸»æµ |
| **strategic investors** | æˆ˜ç•¥æŠ•èµ„è€… |
| **pitch** | æ¨é”€ã€æ¨ä»‹ |
| **cash flow positive** | æ­£å‘ç°é‡‘æµ |
| **go public** | ä¸Šå¸‚ |
| **undervalued** | è¢«ä½ä¼°çš„ |
| **batch mode / real-time** | æ‰¹å¤„ç†æ¨¡å¼ / å®æ—¶ |
| **compute** | ç®—åŠ› |
| **first principles** | ç¬¬ä¸€æ€§åŸç† |
| **low latency / high throughput** | ä½å»¶è¿Ÿ / é«˜ååé‡ |
| **sustainable** | å¯æŒç»­çš„ |
| **three nines / four nines** | 99.9% / 99.99% å¯ç”¨æ€§ |
| **failover mechanisms** | æ•…éšœè½¬ç§»æœºåˆ¶ |
| **guardrails** | æŠ¤æ ï¼ˆå®‰å…¨é™åˆ¶ï¼‰ |
| **compound** | å¤åˆã€ç´¯ç§¯ |
| **transcription** | è½¬å½•ï¼ˆè¯­éŸ³è½¬æ–‡å­—ï¼‰ |
| **rich embedding** | ä¸°å¯Œçš„åµŒå…¥å‘é‡ |
| **modular architecture** | æ¨¡å—åŒ–æ¶æ„ |
| **silicon brain** | ç¡…åŸºå¤§è„‘ï¼ˆAI ç³»ç»Ÿï¼‰ |
| **speech to speech model** | è¯­éŸ³å¯¹è¯­éŸ³æ¨¡å‹ |
| **B2B adoption** | ä¼ä¸šé‡‡ç”¨ç‡ |
| **parallel systems** | å¹¶è¡Œç³»ç»Ÿ |
| **reinvent the wheel** | é‡æ–°å‘æ˜è½®å­ |
| **band-aid** | åˆ›å¯è´´ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰ |
| **componentized approach** | æ¨¡å—åŒ–æ–¹æ³• |
| **heuristics** | å¯å‘å¼æ–¹æ³• |
| **ARR** | å¹´åº¦ç»å¸¸æ€§æ”¶å…¥ |
| **bubble** | æ³¡æ²«ï¼ˆç»æµæœ¯è¯­ï¼‰ |
